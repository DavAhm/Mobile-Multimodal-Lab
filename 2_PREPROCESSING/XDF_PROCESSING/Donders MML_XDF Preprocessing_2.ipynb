{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f4587d",
   "metadata": {},
   "source": [
    "# Donders MML: XDF processing\n",
    "The script processes all data files sotred in an XDF format. \n",
    "Steps: \n",
    "1. Import libraries necessary for processing audio, video and data files \n",
    "    a. See requirements.txt to conda install all the necessary packages. \n",
    "    \n",
    "2. Identify XDF files within a specified directory or its subdirectories.\n",
    "\n",
    "3. ... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceca857",
   "metadata": {},
   "source": [
    "## 0. Import all the necessary packages to work with XDF, Audio and Video files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f88e2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything was imported succesfully\n"
     ]
    }
   ],
   "source": [
    "import os  # Importing the os module which provides functions for interacting with the operating system\n",
    "import pyxdf  # Importing pyxdf, a Python library for reading XDF files\n",
    "import glob  # Importing the glob module which helps in finding files/directories with specific patterns\n",
    "import pandas as pd  # Importing pandas library (abbreviated as pd), which is used for data manipulation and analysis\n",
    "import numpy as np  # Importing numpy library (abbreviated as np), which is used for numerical computations\n",
    "import wave  # Importing wave module for reading and writing WAV files (usually audio files) \n",
    "import struct  # Importing struct module which provides functions to convert between Python values and C structs\n",
    "import math  # Importing math module which provides mathematical functions\n",
    "import random  # Importing random module for generating random numbers\n",
    "from scipy.io import wavfile  # Importing wavfile module from scipy.io (a library built on numpy), for reading and writing WAV files\n",
    "import noisereduce as nr  # Importing noisereduce module for noise reduction in audio signals\n",
    "import json  # Importing json module for working with JSON data\n",
    "import cv2  # Importing OpenCV library for computer vision tasks\n",
    "from moviepy.editor import (  # Importing various classes and functions from moviepy.editor module\n",
    "                            VideoFileClip,  # Class for working with video files\n",
    "                            AudioFileClip,  # Class for working with audio files\n",
    "                            CompositeAudioClip)  # Class for composing audio clip\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip # video  clipping fucntion \n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip # alternative video clipping function\n",
    "import matplotlib.pyplot as plt  # Importing pyplot library to create figures and plot data \n",
    "from matplotlib.widgets import Slider  # \n",
    "import tkinter # GUI toolkit to open and save files\n",
    "from tkinter import filedialog # GUI toolkit to open and save files\n",
    "\n",
    "print(\"Everything was imported succesfully\") #as terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb71e5f-010b-44c3-8ce2-850514916a35",
   "metadata": {},
   "source": [
    "## 1. Define the Relevant Paths, Variables & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecb3769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input folder = C:\\Users\\ahmar\\OneDrive\\Documents\\GitHub\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\data_raw\n",
      "Output folder = C:\\Users\\ahmar\\OneDrive\\Documents\\GitHub\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\data_processed\n",
      "Function \"to_audio\" created sucesfully\n"
     ]
    }
   ],
   "source": [
    "# PATHS\n",
    "\n",
    "experiment_to_process = './data_raw/'  # input folder with the raw XDF files \n",
    "outputfolder = './data_processed/'  # output folder where the raw extracted data will be saved \n",
    "\n",
    "print(\"Input folder =\", os.path.abspath(experiment_to_process))\n",
    "print(\"Output folder =\", os.path.abspath(dataprocessfolder))\n",
    "\n",
    "\n",
    "#VARIABLES \n",
    "noise_reducelevel = 1.5  #This can be changed accordingly \n",
    "\n",
    "\n",
    "# FUNCTIONS\n",
    "# AUDIO: Creating a function named \"to_audio\" tht writes audio data (input) and transforms into a WAV file (output). \n",
    "def to_audio(fileloc, timeseriestype, samplerate = 16000, channels = 1):   \n",
    "    \"\"\"\n",
    "    This function - named \"to_audio\" - writes audio data to a WAV file.\n",
    "    It accepts the following parameters:\n",
    "    - fileloc (str): Location to save the audio file.\n",
    "    - timeseriestype (list): Audio data to be written into the file.\n",
    "    - samplerate (int, optional): Sampling rate of the audio data. Defaults to 16000.\n",
    "    - channels (int, optional): Number of audio channels (mono or stereo). Defaults to 1 (mono)\n",
    "    \"\"\"\n",
    "    if 'Mic' in timeseriestype:  #Condition check that the timeseriestype belongs to the microphone.\n",
    "            \n",
    "        obj = wave.open(fileloc,'w')        # Opens audio file using the wave.open() function write mode ('w'). Assigns data it to the variable obj.\n",
    "        obj.setnchannels(channels)          # Sets the number of channels in the audio file using obj.setnchannels(channels). Deafault 1 channel (mono).\n",
    "        obj.setsampwidth(2)                 # Sets the sample width in bytes using obj.setsampwidth(2). The value '2' indicates 16-bit audio.\n",
    "        obj.setframerate(float(samplerate)) # sets the frame rate of the audio file using obj.setframerate(float(samplerate)), where samplerate is provided as a parameter.\n",
    "            \n",
    "        for i in timeseries:                      # Loop to iterate over each time-point in the temeseries stream\n",
    "            data = struct.pack('<h', int(i[0]))   # Converts the first value of the timeseries to an integer and packs it into a binary string (struck.pack()) according to the '<h' fromat (i.e., short integer (16 bits) in little-endian byte order)   \n",
    "            obj.writeframesraw( data )            # Writes the packed binary data into an audio file using the wave function writeframesraw() from the wave library \n",
    "        obj.close()                               # Closes the audio file \n",
    "\n",
    "print(\"Function \\\"to_audio\\\" created sucesfully\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac3587c",
   "metadata": {},
   "source": [
    "## 2. Identifying XDF files in Input Folder or any Subfolder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9fd9537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have idenified the following XDF files: ['./data_raw/T1_experiment.xdf']\n"
     ]
    }
   ],
   "source": [
    "xdf_files = []  # Initialize an empty list to store paths of XDF files\n",
    "\n",
    "# Traverse through the directory and its subdirectories to find XDF files\n",
    "for root, dirs, files in os.walk(experiment_to_process):  # 1st loop iterating over the results returned by os.walk().\n",
    "    \n",
    "    for file in files:                                    # 2nd loop iterating through each file in the current directory\n",
    "        \n",
    "        if file.endswith(\".xdf\"):                         # checking if the file has and XDF extension \n",
    "            \n",
    "             xdf_files.append(os.path.join(root, file))   # if the file is an XDF file, append its full path to the xdf_files list\n",
    "            \n",
    "print('We have idenified the following XDF files: ' + str(xdf_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd34ee1-0a3c-4fff-aba6-2213040dc729",
   "metadata": {},
   "source": [
    "## 2a. Alternatively, the user can select their own XDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4f83bf-1184-46c1-941f-accfe5dfbd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected the following XDF file: C:/Users/ahmar/OneDrive/Documents/GitHub/Mobile-Multimodal-Lab/2_PREPROCESSING/XDF_PROCESSING/data_raw/T1_experiment.xdf\n"
     ]
    }
   ],
   "source": [
    "root = tkinter.Tk()\n",
    "root.attributes('-topmost',True)\n",
    "root.iconify()\n",
    "\n",
    "xdf_files = filedialog.askopenfilename(title=\"Select an XDF file\", filetypes=[(\"XDF Files\", \"*.xdf\")])\n",
    "\n",
    "root.destroy()\n",
    "\n",
    "print ('You have selected the following XDF file: ' + str(xdf_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a32516",
   "metadata": {},
   "source": [
    "# 3. Main Loop that Plots and Extracts each data stream from each XDF and saves as CVS or WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98c8f08c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading xdf file: ./data_raw/T1_experiment.xdf\n",
      "working on stream: AudioEvents  with a channel count of 1\n",
      " and a sampling rate of 0\n",
      "working on stream: MyWebcamFrameStream_2  with a channel count of 1\n",
      " and a sampling rate of 500\n",
      "working on stream: MyWebcamFrameStream_1  with a channel count of 1\n",
      " and a sampling rate of 500\n",
      "working on stream: OpenSignals  with a channel count of 5\n",
      " and a sampling rate of 1000\n",
      "working on stream: OpenSignals  with a channel count of 5\n",
      " and a sampling rate of 1000\n",
      "working on stream: Mic  with a channel count of 1\n",
      " and a sampling rate of 16000\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\ahmar\\\\OneDrive\\\\Documents\\\\GitHub\\\\Mobile-Multimodal-Lab\\\\2_PREPROCESSING\\\\XDF_PROCESSING\\\\data_processed\\\\T1_experiment_Mic_nominal_srate16000.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 59\u001b[0m\n\u001b[0;32m     57\u001b[0m wavloc \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(outputfolder \u001b[38;5;241m+\u001b[39m fnam \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m timeseriestype \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_nominal_srate\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(samplerate) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Define the location to save the initial audio file\u001b[39;00m\n\u001b[0;32m     58\u001b[0m to_audio(wavloc, timeseries)  \u001b[38;5;66;03m# Convert the time series data to an audio file and save it at the defined location\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m rate, data \u001b[38;5;241m=\u001b[39m wavfile\u001b[38;5;241m.\u001b[39mread(wavloc)  \u001b[38;5;66;03m# Load the audio data from the saved WAV file\u001b[39;00m\n\u001b[0;32m     60\u001b[0m reduced_noise \u001b[38;5;241m=\u001b[39m nr\u001b[38;5;241m.\u001b[39mreduce_noise(y\u001b[38;5;241m=\u001b[39mdata, sr\u001b[38;5;241m=\u001b[39mrate, n_std_thresh_stationary\u001b[38;5;241m=\u001b[39mnoise_reducelevel, stationary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)    \u001b[38;5;66;03m# Perform noise reduction based on the noise_reducelevel \u001b[39;00m\n\u001b[0;32m     61\u001b[0m wavloc2 \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(outputfolder \u001b[38;5;241m+\u001b[39m fnam \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m timeseriestype \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_nominal_srate\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(samplerate) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_denoised.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Define the location to save the noise-reduced audio file\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\multimodallab\\Lib\\site-packages\\scipy\\io\\wavfile.py:647\u001b[0m, in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    645\u001b[0m     mmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 647\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     file_size, is_big_endian \u001b[38;5;241m=\u001b[39m _read_riff_chunk(fid)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ahmar\\\\OneDrive\\\\Documents\\\\GitHub\\\\Mobile-Multimodal-Lab\\\\2_PREPROCESSING\\\\XDF_PROCESSING\\\\data_processed\\\\T1_experiment_Mic_nominal_srate16000.wav'"
     ]
    }
   ],
   "source": [
    "\n",
    "for xdf_file in xdf_files:               # Iterate over each path in the list \"xdf_files\". \n",
    "\n",
    "    print('loading xdf file: ' + xdf_file )\n",
    "\n",
    "    streams, header = pyxdf.load_xdf(xdf_file)    # Loading steams and header information from each XDF file usign the load_xdf function from the pyxdf library. \n",
    "    fnam = os.path.basename(xdf_file)[:-4]        # Extract the file name from the path and assings it to fnam, whilst removing the '.xdf' extension (i.e., the last 4 characters in the string)\n",
    "    \n",
    "    # Navigating through each stream and saving it as a csv, or additinoally as a .wav file if audio\n",
    "       \n",
    "    stream_count = {}   # Dictionary to keep track of the count of each stream type\n",
    "    for stream in streams:                        # Iterate over each steam in the loaded steam for each XDF file .\n",
    "        timeseriestype = stream['info']['name'][0]                       # Extracts information (info and 1st name) for each steams (dictionary structure) and assigns it to timeseriestype (e.g., Mic). \n",
    "        samplerate = round(float(stream['info']['nominal_srate'][0]))    # Extracts the rounded sampling rate (nominal_srate) and assings it to samplerate \n",
    "        channelcount = stream['info']['channel_count'][0]                # Extracts the number of channel for each steams and assigns it to channelcount \n",
    "\n",
    "        # Increment the count for this stream type\n",
    "        if timeseriestype in stream_count:\n",
    "            stream_count[timeseriestype] += 1\n",
    "        else:\n",
    "            stream_count[timeseriestype] = 1\n",
    "        \n",
    "        count = stream_count[timeseriestype]  # Get the current count for the stream type\n",
    "        \n",
    "        print('working on stream: ' + timeseriestype + '  with a channel count of ' + str(channelcount) +'\\n and a sampling rate of ' + str(samplerate))\n",
    "        \n",
    "        timevec = stream['time_stamps']            # Extract the time_stamps (i.e.,LSL TIMESTAMPS) from the \"stream\" dictionary and assigns it to the variable timevec\n",
    "        timeseries = stream['time_series']         # Extract the time_series (i.e., DATA) from the \"stream\" dictionary and \n",
    "\n",
    "        ## -------- PLOTTING the Data Stream -----------\n",
    "        #plt.figure(figsize=(10, 6))  # Adjust the figure size as needed\n",
    "        # Convert timeseries to a numpy array if it is not already\n",
    "       # timeseries = np.array(timeseries)\n",
    "        #for i in range(int(channelcount)):\n",
    "         #   plt.plot(timevec, timeseries[:, i], label='Channel ' + str(i + 1))\n",
    "       # plt.title(timeseriestype + 'Stream')\n",
    "        #plt.xlabel('Time')\n",
    "        #plt.ylabel('Amplitude')\n",
    "        #plt.legend()\n",
    "        #plt.grid(True)\n",
    "        #plt.show()\n",
    "        # -------------------------------------------------\n",
    "\n",
    "\n",
    "        # We save each stream of the XDF file as a CSV (if it doesn't exist yet) \n",
    "        timevec = stream['time_stamps']                                            # Extract the time_stamps (i.e.,LSL TIMESTAMPS) from the \"stream\" dictionary and assigns it to the variable timevec\n",
    "        timeseries = stream['time_series']                                         # Extract the time_series (i.e., DATA) from the \"stream\" dictionary and \n",
    "        matrix_aux = np.vstack([np.transpose(timevec),np.transpose(timeseries)])   # Create matrix_aux by concatenating the transposed timevec and timeseries\n",
    "        matrix     = np.transpose(matrix_aux)                                      # Create new matrix by tranposing matrix_aux\n",
    "        df_lab = pd.DataFrame(matrix)                                              # Converts the numerical array into a DataFrame called df_lab\n",
    "        if count == 1: \n",
    "            df_lab.to_csv(outputfolder + fnam + '_' + timeseriestype + '_nominal_srate' + str(samplerate)  + '.csv',index=False)  \n",
    "        else: \n",
    "            df_lab.to_csv(outputfolder + fnam + '_' + timeseriestype + '_nominal_srate' + str(samplerate) + '_' + str(count) + '.csv',index=False)     #Saving the df_lab as CSV file named [fnam]_[timeseriestype]_[nomilar_srate#].cvs\n",
    "       \n",
    "\n",
    "        if \"Mic\" in timeseriestype:  # Check if the data stream is from a microphone\n",
    "            wavloc = os.path.abspath(outputfolder + fnam + '_' + timeseriestype + '_nominal_srate' + str(samplerate) + '.wav')  # Define the location to save the initial audio file\n",
    "            to_audio(wavloc, timeseries)  # Convert the time series data to an audio file and save it at the defined location\n",
    "            rate, data = wavfile.read(wavloc)  # Load the audio data from the saved WAV file\n",
    "            reduced_noise = nr.reduce_noise(y=data, sr=rate, n_std_thresh_stationary=noise_reducelevel, stationary=True)    # Perform noise reduction based on the noise_reducelevel \n",
    "            wavloc2 = os.path.abspath(outputfolder + fnam + '_' + timeseriestype + '_nominal_srate' + str(samplerate) + '_denoised.wav')  # Define the location to save the noise-reduced audio file\n",
    "            wavfile.write(wavloc2, rate, reduced_noise)  # Save the noise-reduced audio data as a new WAV file at the defined location\n",
    "\n",
    "pint(\"Done! You can now look into your folder: \" + outputfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889186dc-4248-4fa3-9a18-3d61abfc6f10",
   "metadata": {},
   "source": [
    "## 4. Cutting the Videos according to the Start and End of LSL Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fea48c-e33e-4f0a-988a-a13f06b25d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T1_experiment_AudioEvents_nominal_srate0.csv\n",
      "T1_experiment_Mic_nominal_srate16000.csv\n",
      "T1_experiment_MyWebcamFrameStream_1_nominal_srate500.csv\n",
      "Now processing file: T1_experiment_MyWebcamFrameStream_1_nominal_srate500.csv\n",
      "T1_P1_exp_2024-04-23_output_compr.avi\n",
      "Now processing file: T1_P1_exp_2024-04-23_output_compr.avi\n",
      "frame rate: 60.0\n",
      "original fps: 54.96\n",
      "Looping over the frames\n"
     ]
    }
   ],
   "source": [
    "videofolder = './video/'\n",
    "\n",
    "for file in os.listdir(os.path.abspath('./data_processed/')):\n",
    "    print(file)\n",
    "    if 'MyWebcamFrameStream' in file:\n",
    "        print('Now processing file: ' + file)\n",
    "        filepath = os.path.join(os.path.abspath('./data_processed/'), file)\n",
    "\n",
    "        # Loading the CSV file \n",
    "        trialdata = pd.read_csv(filepath)  # Reads the CSV file at the constructed path into a DataFrame called trialdata\n",
    "        \n",
    "        begin_time = trialdata['0'].min()  # Extracts the minimum value from the '0' column in the trialdata DataFrame, which represents the begin time of the trial.\n",
    "        begin_frame = int(trialdata['1'].min()) # Extracts the minimum value from the 'frame' column in the trialdata DataFrame, converts it to an integer, and assigns it to begin_frame\n",
    "\n",
    "        end_time = trialdata['0'].max() \n",
    "        end_frame = int(trialdata['1'].max())\n",
    "\n",
    "        tot_frames = end_frame - begin_frame  # Total number of frames from start to finish recording.\n",
    "        frames = range(begin_frame, end_frame)  # Get all the frames in trial\n",
    "\n",
    "        # Loading the videos \n",
    "        for video in os.listdir(os.path.abspath(videofolder)):\n",
    "            print(video)\n",
    "            if 'P1' in video:\n",
    "                print('Now processing file: ' + video)\n",
    "                video_filepath = os.path.join(os.path.abspath(videofolder), video)\n",
    "                capture = cv2.VideoCapture(video_filepath)\n",
    "\n",
    "                # Meta Data about the Video \n",
    "                frameWidth = capture.get(cv2.CAP_PROP_FRAME_WIDTH)  # Check frame width\n",
    "                frameHeight = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)  # Check frame height\n",
    "                frate = capture.get(cv2.CAP_PROP_FPS)\n",
    "                print('frame rate: ' + str(frate))\n",
    "                originalfps = round((tot_frames / (end_time - begin_time)), 3)\n",
    "                print('original fps: ' + str(originalfps))\n",
    "\n",
    "                # Start Writing the Video \n",
    "                fourcc = cv2.VideoWriter_fourcc(*'M', 'J', 'P', 'G')  # For different video formats you could use e.g., *'XVID'\n",
    "                vidloc = os.path.join(videofolder, f'{video.split(\".\")[0]}_cut.mp4')  # Location to save the new video\n",
    "                out = cv2.VideoWriter(vidloc, fourcc, fps=originalfps, frameSize=(int(frameWidth), int(frameHeight)))\n",
    "                frame_count = 0\n",
    "\n",
    "                print('Looping over the frames')\n",
    "                while capture.isOpened():\n",
    "                    # Read the next frame\n",
    "                    ret, frame = capture.read()\n",
    "                    if ret:\n",
    "                        # Increment the frame count\n",
    "                        frame_count += 1\n",
    "                        if frame_count in frames:\n",
    "                            out.write(frame)\n",
    "                        if frame_count > end_frame:\n",
    "                            break\n",
    "\n",
    "                capture.release()\n",
    "                out.release()\n",
    "                print(f'Video saved to {vidloc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd35add-78d9-40b2-b773-632b8732e7ba",
   "metadata": {},
   "source": [
    "# 5. Concatenate (cut) Videos with Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d705c5c7-5143-4185-ae4b-aaf1ebcb42e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "wavloc = os.path.join(os.path.abspath('./data_processed/')\n",
    "\n",
    "if not os.path.exists(wavloc):\n",
    "    print(f\"Directory not found: {wavloc}\")\n",
    "\n",
    "\n",
    "# loop over Audio files\n",
    "for file in os.listdir(wavloc):\n",
    "    print(file)\n",
    "    if 'Mic_nominal_srate16000_denoised' in file:\n",
    "        print('Now processing file '+file)\n",
    "        sessionIndex = file.split('_')[0]   # this is session number\n",
    "        trialIndex = file.split('_')[2] # this is trial number\n",
    "        #load in the audio\n",
    "        print('Loading the audio')\n",
    "        audio_path = os.path.join(wavloc, file)\n",
    "        if not os.path.exists(audio_path):\n",
    "            print(f\"Audio file not found: {audio_path}\")\n",
    "        # input the video with ffmpg\n",
    "        input_audio = ffmpeg.input(audio_path)\n",
    "        print(input_audio)\n",
    "        #load in the video with matchich trialIndex and SessionIndex\n",
    "        print('Loading the video')\n",
    "        video_path = os.path.join(trialfolder, f\"{sessionIndex}_trial_{trialIndex}_video_raw.mp4\")\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Video file not found: {video_path}\")\n",
    "        input_video = ffmpeg.input(video_path)\n",
    "        print(input_video)\n",
    "\n",
    "\n",
    "          #combine the audio and video\n",
    "        print('Combining audio and video')\n",
    "        output_path = os.path.abspath(os.path.join(trialfolder, f\"{sessionIndex}_trial_{trialIndex}_final.mp4\"))\n",
    "        ffmpeg.concat(input_video, input_audio, v=1, a=1).output(output_path).run(overwrite_output=True)\n",
    "\n",
    "\n",
    "        #save it\n",
    "        print('Saving the video')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "393caa11-0dd9-4a2d-9467-825bbdbd6281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T1_P1_exp_2024-04-23_output_compr.avi',\n",
       " 'T1_P2_exp_2024-04-23_output_compr.avi']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.path.abspath(videofolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad653e5-3395-4464-afc7-eb9d773050f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
