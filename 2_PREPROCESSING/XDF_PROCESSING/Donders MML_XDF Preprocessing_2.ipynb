{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f4587d",
   "metadata": {},
   "source": [
    "# Donders MML: XDF processing\n",
    "The script processes all data files sotred in an XDF format. \n",
    "Steps: \n",
    "1. Import libraries necessary for processing audio, video and data files \n",
    "    a. See requirements.txt to conda install all the necessary packages. \n",
    "    \n",
    "2. Identify XDF files within a specified directory or its subdirectories.\n",
    "\n",
    "3. ... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceca857",
   "metadata": {},
   "source": [
    "## 0. Import all the necessary packages to work with XDF, Audio and Video files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f88e2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything was imported succesfully\n"
     ]
    }
   ],
   "source": [
    "import os  # Importing the os module which provides functions for interacting with the operating system\n",
    "import pyxdf  # Importing pyxdf, a Python library for reading XDF files\n",
    "import glob  # Importing the glob module which helps in finding files/directories with specific patterns\n",
    "import pandas as pd  # Importing pandas library (abbreviated as pd), which is used for data manipulation and analysis\n",
    "import numpy as np  # Importing numpy library (abbreviated as np), which is used for numerical computations\n",
    "import wave  # Importing wave module for reading and writing WAV files (usually audio files) \n",
    "import struct  # Importing struct module which provides functions to convert between Python values and C structs\n",
    "import math  # Importing math module which provides mathematical functions\n",
    "import random  # Importing random module for generating random numbers\n",
    "from scipy.io import wavfile  # Importing wavfile module from scipy.io (a library built on numpy), for reading and writing WAV files\n",
    "import noisereduce as nr  # Importing noisereduce module for noise reduction in audio signals\n",
    "import json  # Importing json module for working with JSON data\n",
    "import cv2  # Importing OpenCV library for computer vision tasks\n",
    "from moviepy.editor import (  # Importing various classes and functions from moviepy.editor module\n",
    "                            VideoFileClip,  # Class for working with video files\n",
    "                            AudioFileClip,  # Class for working with audio files\n",
    "                            CompositeAudioClip)  # Class for composing audio clip\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip # video  clipping fucntion \n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip # alternative video clipping function\n",
    "import matplotlib.pyplot as plt  # Importing pyplot library to create figures and plot data \n",
    "from matplotlib.widgets import Slider  \n",
    "import tkinter # GUI toolkit to open and save files\n",
    "from tkinter import filedialog # GUI toolkit to open and save files\n",
    "import subprocess \n",
    "#import ffmpeg     # Question about this\n",
    "# import xdf\n",
    "\n",
    "print(\"Everything was imported succesfully\") #as terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb71e5f-010b-44c3-8ce2-850514916a35",
   "metadata": {},
   "source": [
    "## 1. Define the Relevant Paths, Variables & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecb3769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input folder = F:\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\data_raw\n",
      "Output folder = F:\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\data_processed\n",
      "Function \"to_audio\" created sucesfully\n",
      "Function \"frame_to_time\" created sucesfully\n",
      "Function \"save_xdf\" created sucesfully\n",
      "Function \"rename_streams\" created sucesfully\n",
      "Function \"clip_nonmarker_streams\" created successfully\n",
      "Function \"get_events\" created sucesfully\n"
     ]
    }
   ],
   "source": [
    "# ------------ PATHS -----------------------------------------------------\n",
    "input_folder = './data_raw/'  # input folder with the raw XDF files (relative path) \n",
    "output_folder = './data_processed/'  # output folder where the raw extracted data will be saved (relative path) \n",
    "\n",
    "print(\"Input folder =\", os.path.abspath(input_folder))\n",
    "print(\"Output folder =\", os.path.abspath(output_folder))\n",
    "\n",
    "\n",
    "# ------------ VARIABLES ----------------------------------------------\n",
    "noise_reducelevel = 1.5  #This can be changed accordingly \n",
    "\n",
    "\n",
    "# Dictionary to map file extensions to codecs\n",
    "extension_to_codec = {\n",
    "    '.mp4': 'libx264',\n",
    "    '.avi': 'libxvid',\n",
    "    '.mov': 'libx264',\n",
    "    '.mkv': 'libx264',\n",
    "    '.flv': 'flv',\n",
    "    # Add more mappings as needed\n",
    "                    }\n",
    "\n",
    "\n",
    "# IF NEEDED: Create a dictionary mapping from old stream names to new stream names (# Edit and add more mappings as needed.) \n",
    "     # (This dictionary mapping is based both of the stream_names and stream_types because in our case we have 2 streams with the same name (but different types)) \n",
    "rename_dict = {\n",
    "    ('MyWebcamFrameStream_2', 'frameNR'): 'Video_P2',\n",
    "    ('MyWebcamFrameStream_1', 'frameNR'): 'Video_P1',\n",
    "    ('Mic', 'voice'): 'Mic_P1',\n",
    "    ('Mic_004', 'voice'): 'Mic_P2',\n",
    "    ('OpenSignals', '00:07:80:8C:06:6A'): 'PLUX_P2',\n",
    "    ('OpenSignals', '00:07:80:D8:A8:81'): 'PLUX_P1'\n",
    "}\n",
    "\n",
    "\n",
    "# -------------FUNCTIONS------------------------------------------------------------------------------------\n",
    "# AUDIO: Creating a function named \"to_audio\" tht writes audio data (input) and transforms into a WAV file (output). \n",
    "def to_audio(fileloc, timeseries_name, samplerate = 16000, channels = 1):   \n",
    "    \"\"\"\n",
    "    This function - named \"to_audio\" - writes audio data to a WAV file.\n",
    "    It accepts the following parameters:\n",
    "    - fileloc (str): Location to save the audio file.\n",
    "    - timeseriestype (list): Audio data to be written into the file.\n",
    "    - samplerate (int, optional): Sampling rate of the audio data. Defaults to 16000.\n",
    "    - channels (int, optional): Number of audio channels (mono or stereo). Defaults to 1 (mono)\n",
    "    \"\"\"\n",
    "    if 'Mic' in timeseries_name:  #Condition check that the timeseriestype belongs to the microphone.\n",
    "            \n",
    "        obj = wave.open(fileloc,'w')        # Opens audio file using the wave.open() function write mode ('w'). Assigns data it to the variable obj.\n",
    "        obj.setnchannels(channels)          # Sets the number of channels in the audio file using obj.setnchannels(channels). Deafault 1 channel (mono).\n",
    "        obj.setsampwidth(2)                 # Sets the sample width in bytes using obj.setsampwidth(2). The value '2' indicates 16-bit audio.\n",
    "        obj.setframerate(float(samplerate)) # sets the frame rate of the audio file using obj.setframerate(float(samplerate)), where samplerate is provided as a parameter.\n",
    "            \n",
    "        for i in timeseries:                      # Loop to iterate over each time-point in the temeseries stream\n",
    "            data = struct.pack('<h', int(i[0]))   # Converts the first value of the timeseries to an integer and packs it into a binary string (struck.pack()) according to the '<h' fromat (i.e., short integer (16 bits) in little-endian byte order)   \n",
    "            obj.writeframesraw( data )            # Writes the packed binary data into an audio file using the wave function writeframesraw() from the wave library \n",
    "        obj.close()                               # Closes the audio file \n",
    "\n",
    "print(\"Function \\\"to_audio\\\" created sucesfully\") \n",
    "\n",
    "\n",
    "# VIDEO: Creating a function named frame_to_time to convert frame number to time format \n",
    "def frame_to_time(frame, fps):\n",
    "    \"\"\"\n",
    "    frame_to_time converts a given frame number to a time format (HH:MM:SS.SS) based on the frames per second (fps).\n",
    "    Arguments:\n",
    "        frame (int): The frame number to be converted.\n",
    "        fps (float): The frames per second of the video.\n",
    "    Returns:\n",
    "        str: The time format as a string in the format \"HH:MM:SS.SS\".\n",
    "    \"\"\"\n",
    "    seconds = frame / fps\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = seconds % 60\n",
    "    return f\"{hours:02}:{minutes:02}:{seconds:.2f}\"\n",
    "\n",
    "print(\"Function \\\"frame_to_time\\\" created sucesfully\") \n",
    "\n",
    "\n",
    "# XDF Save \n",
    "def save_xdf(filename, streams, header):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pyxdf.write_header(f, header)\n",
    "        for stream in streams:\n",
    "            pyxdf.write_stream_header(f, stream['info'])\n",
    "            pyxdf.write_stream_data(f, stream['time_stamps'], stream['time_series'])\n",
    "\n",
    "print(\"Function \\\"save_xdf\\\" created sucesfully\") \n",
    "\n",
    "\n",
    "# Renaming XDF Stream (if necessary)\n",
    "def rename_streams(streams, rename_dict):\n",
    "    \"\"\"\n",
    "    Function rename_stream renames any streams based on the rename dictionary (if name found in remane_dict)\n",
    "        Parameters:\n",
    "    stream_name (str): The current name of the stream.\n",
    "    stream_type (str): The type of the stream.\n",
    "    rename_dict (dict): A dictionary mapping old stream names and types to new stream names.\n",
    "        Returns:\n",
    "    str: The new stream name if found in rename_dict, otherwise the original stream name.\n",
    "    \"\"\"\n",
    "    for stream in streams:\n",
    "        stream_name = stream['info']['name'][0]\n",
    "        stream_type = stream['info']['type'][0]\n",
    "\n",
    "        if (stream_name, stream_type) in rename_dict:\n",
    "            new_name = rename_dict[(stream_name, stream_type)]\n",
    "            print(f'Renaming stream {stream_name} ({stream_type}) to {new_name}')\n",
    "            stream['info']['name'][0] = new_name  # Rename the stream\n",
    "    return streams\n",
    "\n",
    "print(\"Function \\\"rename_streams\\\" created sucesfully\") \n",
    "\n",
    "\n",
    "# Function to clip the streams\n",
    "def clip_nonmarker_streams(streams):\n",
    "    \"\"\"\n",
    "    Function clip_nonmarker_streams cuts the start and end of all streams that are not \"Markers\" type in an XDF file based on the shortest stream.\n",
    "    \n",
    "    Input: \n",
    "        streams: list of streams to be clipped latest_start_time and earliest_end_time of all streams except Markers ones\n",
    "    Output: \n",
    "        clipped streams based on the \n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter out marker streams for calculating the latest start and earliest end times\n",
    "    non_marker_streams = [stream for stream in streams if stream['info']['type'][0] != 'Markers']\n",
    "\n",
    "    for i in non_marker_streams:\n",
    "        name_i = i['info']['name'][0]\n",
    "        print(str(name_i))\n",
    "    \n",
    "    # Find the latest start time across all non-marker streams\n",
    "    begintimes = [stream['time_stamps'][0] for stream in non_marker_streams]\n",
    "    latest_start_time = max(begintimes)  # Get the first timestamp of each non-marker stream and find the maximum (latest start time)\n",
    "    print('begin times per stream: ' + str(begintimes))\n",
    "    print(' latest_start_time' + str(latest_start_time))\n",
    "\n",
    "    # Find the earliest end time across all non-marker streams\n",
    "    endtimes = [stream['time_stamps'][-1] for stream in non_marker_streams]\n",
    "    earliest_end_time = min(endtimes)  # Get the last timestamp of each non-marker stream and find the minimum (earliest end time)\n",
    "    print('end times per stream: ' + str(endtimes))\n",
    "    print(' earliest_end_time' + str(earliest_end_time))\n",
    "\n",
    "    clipped_streams = []  # Initialize an empty list to store the clipped streams\n",
    "\n",
    "    for stream in streams:\n",
    "        time_stamps = np.array(stream['time_stamps'])  # Convert the timestamps to a NumPy array\n",
    "        time_series = np.array(stream['time_series'])  # Convert the time series data to a NumPy array\n",
    "\n",
    "        # Find the index of the closest timestamp to the latest start time\n",
    "        start_idx = np.searchsorted(time_stamps, latest_start_time, side='left')  # Get the index where the latest start time would fit\n",
    "        # Ensure the index is within the valid range\n",
    "        start_idx = max(0, min(start_idx, len(time_stamps) - 1))\n",
    "\n",
    "        # Find the index of the closest timestamp to the earliest end time\n",
    "        end_idx = np.searchsorted(time_stamps, earliest_end_time, side='right')  # Get the index where the earliest end time would fit\n",
    "        # Ensure the index is within the valid range\n",
    "        end_idx = max(0, min(end_idx, len(time_stamps)))\n",
    "\n",
    "        print(f\"Clipping stream {stream['info']['name'][0]}:\")\n",
    "        print(f\" start_idx: {start_idx}, end_idx: {end_idx}\")\n",
    "        print(f\" clipped_time_stamps: {time_stamps[start_idx:end_idx]}\")\n",
    "\n",
    "        # Clip the timestamps array to the range between the found indices\n",
    "        clipped_time_stamps = time_stamps[start_idx:end_idx]  # Select the time stamps within the clipped range\n",
    "        # Clip the time series data array to the same range\n",
    "        clipped_time_series = time_series[start_idx:end_idx]  # Select the time series data within the clipped range\n",
    "\n",
    "        # Create a copy of the original stream dictionary\n",
    "        clipped_stream = stream.copy()  # Copy the stream dictionary\n",
    "        # Replace the timestamps and time series data with the clipped versions\n",
    "        clipped_stream['time_stamps'] = clipped_time_stamps  # Update the timestamps with the clipped data\n",
    "        clipped_stream['time_series'] = clipped_time_series  # Update the time series with the clipped data\n",
    "\n",
    "        clipped_streams.append(clipped_stream)  # Add the clipped stream to the list\n",
    "\n",
    "    return clipped_streams  # Return the list of clipped streams\n",
    "\n",
    "print(\"Function \\\"clip_nonmarker_streams\\\" created successfully\")\n",
    "\n",
    "\n",
    "# Function to extract specified events (with correspodning LSL times) from XDF stream (useful for plotting)\n",
    "def get_events(stream, event_names):\n",
    "    \"\"\"\n",
    "    Extracts events and corresponding LSL times from the given stream that match any of the event_names.\n",
    "\n",
    "    Parameters:\n",
    "    stream (dict): The stream containing time stamps and event data.\n",
    "    event_names (list of str): List of event name substrings to look for in the events.\n",
    "\n",
    "    Returns:\n",
    "    np.array: An array where each row contains a timestamp and the full event name.\n",
    "    \"\"\"\n",
    "    events = []  # Initialize an empty list to store matching events\n",
    "\n",
    "    # Check if the stream type is \"Markers\"\n",
    "    if stream['info']['type'][0] != \"Markers\":\n",
    "        raise ValueError(f\"ERROR: The stream provided ({stream['info']['name'][0]}) is not a Marker stream\")\n",
    "\n",
    "    # Iterate over the time stamps and corresponding events in the stream\n",
    "    for timestamp, event in zip(stream['time_stamps'], stream['time_series']):\n",
    "        # Check if any of the specified event names are in the current event\n",
    "        for name in event_names:\n",
    "            if name in event[0]:\n",
    "                # If a match is found, append the timestamp and full event name to the list\n",
    "                events.append([timestamp, event[0]])\n",
    "\n",
    "    # Convert the list of events to a NumPy array and return it\n",
    "    return np.array(events)\n",
    "\n",
    "print(\"Function \\\"get_events\\\" created sucesfully\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac3587c",
   "metadata": {},
   "source": [
    "## 2. Identifying XDF files in Input Folder or any Subfolder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd9537",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf_files = []  # Initialize an empty list to store paths of XDF files\n",
    "\n",
    "# Traverse through the directory and its subdirectories to find XDF files\n",
    "for root, dirs, files in os.walk(input_folder):  # 1st loop iterating over the results returned by os.walk().\n",
    "    \n",
    "    for file in files:                                    # 2nd loop iterating through each file in the current directory\n",
    "        \n",
    "        if file.endswith(\".xdf\"):                         # checking if the file has and XDF extension \n",
    "            \n",
    "             xdf_files.append(os.path.join(root, file))   # if the file is an XDF file, append its full path to the xdf_files list\n",
    "            \n",
    "print('We have idenified the following XDF files: ' + str(xdf_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd34ee1-0a3c-4fff-aba6-2213040dc729",
   "metadata": {},
   "source": [
    "## 2a. Alternatively, the user can select their own XDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4f83bf-1184-46c1-941f-accfe5dfbd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected the following XDF files: ['F:/Mobile-Multimodal-Lab/2_PREPROCESSING/XDF_PROCESSING/data_raw/T1_experiment.xdf']\n"
     ]
    }
   ],
   "source": [
    "import tkinter # GUI toolkit to open and save files\n",
    "from tkinter import filedialog # GUI toolkit to open and save files\n",
    "\n",
    "root = tkinter.Tk()\n",
    "root.attributes('-topmost',True)\n",
    "root.iconify()\n",
    "\n",
    "xdf_files = filedialog.askopenfilename(title=\"Select an XDF file\", filetypes=[(\"XDF Files\", \"*.xdf\")], multiple = 'True')\n",
    "\n",
    "root.destroy()\n",
    "\n",
    "# Convert the tuple returned by askopenfilenames() to a list\n",
    "xdf_files = list(xdf_files)\n",
    "\n",
    "print('You have selected the following XDF files: ' + str(xdf_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9c679-7d1c-4c5b-8962-c5f1ea6d871c",
   "metadata": {},
   "source": [
    "# 3. (NEW) Main Loop that Extracts & RENAMES each data stream from each XDF and saves it as CVS or WAV files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df87847-8651-4e9e-a681-a48534cdd25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading xdf file: F:/Mobile-Multimodal-Lab/2_PREPROCESSING/XDF_PROCESSING/data_raw/T1_experiment.xdf\n",
      "Renaming stream MyWebcamFrameStream_2 (frameNR) to Video_P2\n",
      "Renaming stream MyWebcamFrameStream_1 (frameNR) to Video_P1\n",
      "Renaming stream OpenSignals (00:07:80:8C:06:6A) to PLUX_P2\n",
      "Renaming stream OpenSignals (00:07:80:D8:A8:81) to PLUX_P1\n",
      "Renaming stream Mic (voice) to Mic_P1\n",
      "Renaming stream Mic_004 (voice) to Mic_P2\n",
      "Video_P2\n",
      "Video_P1\n",
      "PLUX_P2\n",
      "PLUX_P1\n",
      "Mic_P1\n",
      "Mic_P2\n",
      "begin times per stream: [6340.566187627696, 6340.957448231612, 6341.679350981336, 6341.682920201526, 6341.760356983385, 6341.8376445060285]\n",
      " latest_start_time6341.8376445060285\n",
      "end times per stream: [7330.334929689854, 7328.912870295722, 7330.7007262467, 7330.704584839529, 7330.838791492892, 7330.845650206309]\n",
      " earliest_end_time7328.912870295722\n",
      "Clipping stream AudioEvents:\n",
      " start_idx: 0, end_idx: 100\n",
      " clipped_time_stamps: [6366.91126373 6370.37102452 6377.58866336 6384.8060832  6397.01303619\n",
      " 6399.22176473 6402.43000206 6409.6484457  6416.87078723 6429.07781402\n",
      " 6431.28512796 6434.49581029 6441.7220197  6448.94247234 6461.15011992\n",
      " 6463.35761037 6466.56780469 6473.78893183 6481.00536667 6493.21119146\n",
      " 6495.41819151 6498.62608764 6505.84211348 6513.05828512 6525.2686486\n",
      " 6555.02660483 6558.24006625 6565.45957748 6572.67781132 6584.8900322\n",
      " 6587.10308523 6590.31534915 6597.53825158 6604.75744981 6616.965001\n",
      " 6619.17509264 6622.38166047 6629.59912121 6636.81911645 6649.03375671\n",
      " 6651.24171036 6654.44919149 6661.67238012 6668.89483384 6681.10214463\n",
      " 6683.31079667 6686.5202161  6693.73823144 6700.95576048 6713.16261177\n",
      " 6722.85153789 6726.06398481 6733.28000215 6740.4933359  6752.70001939\n",
      " 6754.91161493 6758.12261845 6765.34253138 6772.55600764 6784.76868551\n",
      " 6786.97708235 6790.18299259 6797.40327052 6804.62355595 6816.82772565\n",
      " 6819.03629119 6822.24112853 6829.45880277 6836.67687881 6848.89254588\n",
      " 6851.09638853 6854.30023887 6861.51672691 6868.73403725 6880.93803135\n",
      " 6888.44453466 6891.65525229 6898.87813211 6906.09814005 6918.30594093\n",
      " 6920.51148348 6923.72101461 6930.93988295 6938.15611659 6950.36526157\n",
      " 6952.57019503 6955.78009735 6963.00364727 6970.22288431 6982.4306522\n",
      " 6984.64183683 6987.84966756 6995.07084529 7002.29022563 7014.49551252\n",
      " 7016.70404817 7019.9096556  7027.13197803 7034.34969447 7046.55299557]\n",
      "Clipping stream Video_P2:\n",
      " start_idx: 613, end_idx: 476264\n",
      " clipped_time_stamps: [6341.8382906  6341.84036581 6341.84244101 ... 7328.90718606 7328.90926127\n",
      " 7328.91133648]\n",
      "Clipping stream Video_P1:\n",
      " start_idx: 428, end_idx: 480373\n",
      " clipped_time_stamps: [6341.83769296 6341.83974961 6341.84180625 ... 7328.908757   7328.91081365\n",
      " 7328.9128703 ]\n",
      "Clipping stream PLUX_P2:\n",
      " start_idx: 159, end_idx: 987459\n",
      " clipped_time_stamps: [6341.83831472 6341.83931449 6341.84031426 ... 7328.91013473 7328.9111345\n",
      " 7328.91213428]\n",
      "Clipping stream PLUX_P1:\n",
      " start_idx: 155, end_idx: 987455\n",
      " clipped_time_stamps: [6341.83788489 6341.83888467 6341.83988444 ... 7328.90999371 7328.91099349\n",
      " 7328.91199326]\n",
      "Clipping stream Mic_P1:\n",
      " start_idx: 1237, end_idx: 15795182\n",
      " clipped_time_stamps: [6341.83766585 6341.83772835 6341.83779085 ... 7328.91269443 7328.91275693\n",
      " 7328.91281942]\n",
      "Clipping stream Mic_P2:\n",
      " start_idx: 0, end_idx: 15793936\n",
      " clipped_time_stamps: [6341.83764451 6341.837707   6341.8377695  ... 7328.91273973 7328.91280223\n",
      " 7328.91286473]\n",
      "working on stream: AudioEvents  with a channel count of: 1 labelled: ['Channel 1'] and a sampling rate of 0\n",
      "start time: 6366.911263726508\n",
      "end time: 7046.5529955671\n",
      "Saving: T1_experiment_AudioEvents\n",
      "working on stream: Video_P2  with a channel count of: 1 labelled: ['Channel 1'] and a sampling rate of 500\n",
      "start time: 6341.838290596534\n",
      "end time: 7328.911336481661\n",
      "Saving: T1_experiment_Video_P2\n",
      "working on stream: Video_P1  with a channel count of: 1 labelled: ['Channel 1'] and a sampling rate of 500\n",
      "start time: 6341.837692959954\n",
      "end time: 7328.912870295722\n",
      "Saving: T1_experiment_Video_P1\n",
      "working on stream: PLUX_P2  with a channel count of: 5 labelled: ['nSeq', 'ECG0', 'EMG1', 'EMG2', 'RIP3'] and a sampling rate of 1000\n",
      "start time: 6341.838314717053\n",
      "end time: 7328.912134276899\n",
      "Saving: T1_experiment_PLUX_P2\n",
      "working on stream: PLUX_P1  with a channel count of: 5 labelled: ['nSeq', 'ECG0', 'EMG1', 'EMG2', 'RESPIRATION3'] and a sampling rate of 1000\n",
      "start time: 6341.837884894892\n",
      "end time: 7328.911993257552\n",
      "Saving: T1_experiment_PLUX_P1\n",
      "working on stream: Mic_P1  with a channel count of: 1 labelled: ['Channel 1'] and a sampling rate of 16000\n",
      "start time: 6341.837665853478\n",
      "end time: 7328.912819423625\n",
      "Saving: T1_experiment_Mic_P1\n",
      "working on stream: Mic_P2  with a channel count of: 1 labelled: ['Channel 1'] and a sampling rate of 16000\n",
      "start time: 6341.8376445060285\n",
      "end time: 7328.912864725015\n",
      "Saving: T1_experiment_Mic_P2\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './data_processed/T1_experiment_Mic_P2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[38;5;66;03m# Saving \u001b[39;00m\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaving: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m fnam \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m timeseries_name) \n\u001b[1;32m---> 51\u001b[0m         \u001b[43mdf_lab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfnam\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtimeseries_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \n\u001b[0;32m     54\u001b[0m         \u001b[38;5;66;03m# if \"Mic\" in timeseries_name:  # Check if the data stream is from a microphone\u001b[39;00m\n\u001b[0;32m     55\u001b[0m         \u001b[38;5;66;03m#     wavloc = os.path.abspath(output_folder + fnam + '_' + timeseries_name  + '.wav')  # Define the location to save the initial audio file\u001b[39;00m\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;66;03m#     to_audio(wavloc, timeseries_name)  # Convert the time series data to an audio file and save it at the defined location\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;66;03m#     wavloc2 = os.path.abspath(output_folder + fnam + '_' + timeseries_name + '_denoised.wav')  # Define the location to save the noise-reduced audio file\u001b[39;00m\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;66;03m#     wavfile.write(wavloc2, rate, reduced_noise)  # Save the noise-reduced audio data as a new WAV file at the defined location\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone with extracting all the streams! You can now look into your folder: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m output_folder)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\multimodallab\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\multimodallab\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\multimodallab\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\multimodallab\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\multimodallab\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './data_processed/T1_experiment_Mic_P2.csv'"
     ]
    }
   ],
   "source": [
    "output_folder = './data_processed/'  # output_folder for the CVS and WAV files \n",
    "\n",
    "for xdf_file in xdf_files:               # Iterate over each path in the list \"xdf_files\". \n",
    "\n",
    "    print('loading xdf file: ' + xdf_file )\n",
    "\n",
    "    streams, header = pyxdf.load_xdf(xdf_file)    # Loading steams and header information from each XDF file usign the load_xdf function from the pyxdf library. \n",
    "    fnam = os.path.basename(xdf_file)[:-4]        # Extract the file name from the path and assings it to fnam, whilst removing the '.xdf' extension (i.e., the last 4 characters in the string)\n",
    "       \n",
    "    # Renaming streams using the rename_dict and rename_function (if names match dictionary)\n",
    "    streams = rename_streams(streams, rename_dict)\n",
    "\n",
    "    # Clipping the streams based on the latest_start_time and earliest_end_time of (any of the) streams in the xdf file. \n",
    "    streams = clip_nonmarker_streams(streams)\n",
    "\n",
    "    # Navigating through each stream and extracting the relevant information (e.g., name, sample rate, data, time, etc.) \n",
    "    for stream in streams:                        # Iterate over each steam in the loaded steam for each XDF file .\n",
    "        timeseries_name = stream['info']['name'][0]                    # Extracts name of each steams (dictionary structure) and assigns it to timeseries_name (e.g., Mic). \n",
    "        timeseries_type = stream['info']['type'][0]\n",
    "        timevec = stream['time_stamps']                                # Extract the time_stamps (i.e.,LSL TIMESTAMPS) from the \"stream\" dictionary and assigns it to the variable timevec\n",
    "        timeseries = stream['time_series']                              # Extract the time_series (i.e., DATA) from the \"stream\" dictionary and \n",
    "        samplerate = round(float(stream['info']['nominal_srate'][0]))    # Extracts the rounded sampling rate (nominal_srate) and assings it to samplerate \n",
    "        channelcount = int(stream['info']['channel_count'][0])               # Extracts the number of channel for each steams and assigns it to channelcount (as an integer)\n",
    "\n",
    "        # Extract channel labels (this step is a bit more complex because of the XDF file configuration)\n",
    "        channel_labels = []  # Initialize an empty list to store channel labels\n",
    "        \n",
    "        # Check if there is more than one channel and if the 'desc' field is present in the stream's info\n",
    "        if channelcount > 1 and stream['info']['desc'] is not None:\n",
    "            try:\n",
    "                channels_info = stream['info']['desc'][0]['channels'][0]['channel']  # Attempt to extract channel information from the stream's description\n",
    "                channel_labels = [channel['label'][0] for channel in channels_info]  # Create a list of channel labels by extracting the 'label' field from each channel's info\n",
    "            except (KeyError, IndexError):\n",
    "                channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]  # If there is any issue with extracting channel labels, create default labels\n",
    "        else:\n",
    "            channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]  # If there is only one channel or the 'desc' field is not present, create default labels\n",
    "        \n",
    "        print('working on stream: ' + timeseries_name + '  with a channel count of: ' + str(channelcount) + ' labelled: ' + str(channel_labels) + ' and a sampling rate of ' + str(samplerate))        \n",
    "\n",
    "        # Saving each stream of the XDF file as a CSV (if it doesn't exist yet) \n",
    "        matrix_aux = np.vstack([np.transpose(timevec),np.transpose(timeseries)])   # Create matrix_aux by concatenating the transposed timevec and timeseries\n",
    "        matrix     = np.transpose(matrix_aux)                                      # Create new matrix by tranposing matrix_aux\n",
    "        column_names = [\"LSL_Time\"] + [f\"{timeseries_name}_{label}\" for label in channel_labels]  # Create column names for the matrix. The first column is named \"LSL_Time\" (i.e., timevec), The subsequent columns are named using the format {timeseries_name}_{label} for each channel label. \n",
    "        df_lab = pd.DataFrame(matrix, columns = column_names)                                     # Create a DataFrame df_lab with the combined data and the appropriate column names.\n",
    "\n",
    "        print('start time: ' + str(min(timevec)))\n",
    "        print('end time: ' + str(max(timevec)))\n",
    "        \n",
    "        # Saving \n",
    "        print('Saving: ' + fnam + '_' + timeseries_name) \n",
    "        df_lab.to_csv(output_folder + fnam + '_' + timeseries_name + '.csv',index=False)  \n",
    "      \n",
    "\n",
    "        # if \"Mic\" in timeseries_name:  # Check if the data stream is from a microphone\n",
    "        #     wavloc = os.path.abspath(output_folder + fnam + '_' + timeseries_name  + '.wav')  # Define the location to save the initial audio file\n",
    "        #     to_audio(wavloc, timeseries_name)  # Convert the time series data to an audio file and save it at the defined location\n",
    "        #     rate, data = wavfile.read(wavloc)  # Load the audio data from the saved WAV file\n",
    "        #     reduced_noise = nr.reduce_noise(y=data, sr=rate, n_std_thresh_stationary=noise_reducelevel, stationary=True)    # Perform noise reduction based on the noise_reducelevel \n",
    "        #     wavloc2 = os.path.abspath(output_folder + fnam + '_' + timeseries_name + '_denoised.wav')  # Define the location to save the noise-reduced audio file\n",
    "        #     wavfile.write(wavloc2, rate, reduced_noise)  # Save the noise-reduced audio data as a new WAV file at the defined location\n",
    "\n",
    "print(\"Done with extracting all the streams! You can now look into your folder: \" + output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601313d8-f244-457a-ba37-2a6464f6a2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61a32516",
   "metadata": {},
   "source": [
    "# 3. Main Loop that Extracts each data stream from each XDF file and saves as CVS or WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8f08c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_folder = './data_processed/'  # input folder with the raw XDF files (relative path) \n",
    "event_names = ['_StartParticipantSinging', '_EndParticipantSinging']\n",
    "\n",
    "for xdf_file in xdf_files:               # Iterate over each path in the list \"xdf_files\". \n",
    "\n",
    "    print('loading xdf file: ' + xdf_file )\n",
    "\n",
    "    streams, header = pyxdf.load_xdf(xdf_file)    # Loading steams and header information from each XDF file usign the load_xdf function from the pyxdf library. \n",
    "    fnam = os.path.basename(xdf_file)[:-4]        # Extract the file name from the path and assings it to fnam, whilst removing the '.xdf' extension (i.e., the last 4 characters in the string)\n",
    "       \n",
    "    stream_count = {}   # Dictionary to keep track of multiple streams with the same name (this can happen in cases of multiple people) \n",
    "\n",
    "    # Navigating through each stream and extracting the relevant information (e.g., name, sample rate, data, time, etc.) \n",
    "    for stream in streams:                        # Iterate over each steam in the loaded steam for each XDF file .\n",
    "        timeseries_name = stream['info']['name'][0]                    # Extracts name of each steams (dictionary structure) and assigns it to timeseriestype (e.g., Mic). \n",
    "        timevec = stream['time_stamps']                                # Extract the time_stamps (i.e.,LSL TIMESTAMPS) from the \"stream\" dictionary and assigns it to the variable timevec\n",
    "        timeseries = stream['time_series']                              # Extract the time_series (i.e., DATA) from the \"stream\" dictionary and \n",
    "        samplerate = round(float(stream['info']['nominal_srate'][0]))    # Extracts the rounded sampling rate (nominal_srate) and assings it to samplerate \n",
    "        channelcount = int(stream['info']['channel_count'][0])               # Extracts the number of channel for each steams and assigns it to channelcount (as an integer)\n",
    "\n",
    "        # Extract channel labels\n",
    "        channel_labels = []\n",
    "        if channelcount > 1 and stream['info']['desc'] is not None:\n",
    "            try:\n",
    "                channels_info = stream['info']['desc'][0]['channels'][0]['channel']\n",
    "                channel_labels = [channel['label'][0] for channel in channels_info]\n",
    "            except (KeyError, IndexError):\n",
    "                # If there is any issue with extracting channel labels, create default labels\n",
    "                channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]\n",
    "        else:\n",
    "            # If channelcount is 1 and/or'desc' is None, create default labels\n",
    "            channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]\n",
    "       \n",
    "        # Incrementing the count if the name of two (or more) streams are the same. \n",
    "        if timeseries_name in stream_count:\n",
    "            stream_count[timeseries_name] += 1\n",
    "        else:\n",
    "            stream_count[timeseries_name] = 1 \n",
    "        count = stream_count[timeseries_name]  # Get the current count for the stream type\n",
    "        \n",
    "        print('working on stream: ' + timeseries_name + '  with a channel count of: ' + str(channelcount) + ' labelled: ' + str(channel_labels) + ' and a sampling rate of ' + str(samplerate))        \n",
    "\n",
    "        # Saving each stream of the XDF file as a CSV (if it doesn't exist yet) \n",
    "        matrix_aux = np.vstack([np.transpose(timevec),np.transpose(timeseries)])   # Create matrix_aux by concatenating the transposed timevec and timeseries\n",
    "        matrix     = np.transpose(matrix_aux)                                      # Create new matrix by tranposing matrix_aux\n",
    "        column_names = [\"LSL_Time\"] + [f\"{timeseries_name}_{label}\" for label in channel_labels]  # Create column names for the matrix. The first column is named \"LSL_Time\" (i.e., timevec), The subsequent columns are named using the format {timeseries_name}_{label} for each channel label. \n",
    "        df_lab = pd.DataFrame(matrix, columns = column_names)                                     # Create a DataFrame df_lab with the combined data and the appropriate column names.\n",
    "        if count == 1: # Saving without adding count to the file name\n",
    "            df_lab.to_csv(output_folder + fnam + '_' + timeseries_name + '_nominal_srate' + str(samplerate)  + '.csv',index=False)  \n",
    "        else:         # Saving by adding count ot the file name (because of multiple streams with same name) \n",
    "            df_lab.to_csv(output_folder + fnam + '_' + timeseries_name + '_nominal_srate' + str(samplerate) + '_' + str(count) + '.csv',index=False)     #Saving the df_lab as CSV file named [fnam]_[timeseriestype]_[nomilar_srate#].cvs\n",
    "       \n",
    "\n",
    "        if \"Mic\" in timeseries_name:  # Check if the data stream is from a microphone\n",
    "            wavloc = os.path.abspath(output_folder + fnam + '_' + timeseries_name + '_nominal_srate' + str(samplerate) + '.wav')  # Define the location to save the initial audio file\n",
    "            to_audio(wavloc, timeseries_name)  # Convert the time series data to an audio file and save it at the defined location\n",
    "            rate, data = wavfile.read(wavloc)  # Load the audio data from the saved WAV file\n",
    "            reduced_noise = nr.reduce_noise(y=data, sr=rate, n_std_thresh_stationary=noise_reducelevel, stationary=True)    # Perform noise reduction based on the noise_reducelevel \n",
    "            wavloc2 = os.path.abspath(output_folder + fnam + '_' + timeseries_name + '_nominal_srate' + str(samplerate) + '_denoised.wav')  # Define the location to save the noise-reduced audio file\n",
    "            wavfile.write(wavloc2, rate, reduced_noise)  # Save the noise-reduced audio data as a new WAV file at the defined location\n",
    "\n",
    "print(\"Done with extracting all the streams! You can now look into your folder: \" + output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aab416-ccba-4bfd-9152-184b1918145b",
   "metadata": {},
   "source": [
    "## 4. Plotting Each XDF and Each Stream (Quality Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74810836-9beb-4d55-8ba3-4820b1ce5b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selector_buttons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d41211-a5a5-4c23-b6d3-8ee71333055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "event_names = ['_StartParticipantSinging', '_EndParticipantSinging']\n",
    "\n",
    "\n",
    "# Navigating through each stream and extracting the relevant information (e.g., name, sample rate, data, time, etc.)\n",
    "for stream in streams:  # Iterate over each steam in the loaded steam for each XDF file.\n",
    "    timeseries_name = stream['info']['name'][0]  # Extracts name of each steams (dictionary structure) and assigns it to timeseries_name (e.g., Mic).\n",
    "    timeseries_type = stream['info']['type'][0]  # Extracts type of each steams (dictionary structure) and assigns it to timeseries_type (e.g., Markers).\n",
    "    timevec = stream['time_stamps']  # Extract the time_stamps (i.e.,LSL TIMESTAMPS) from the \"stream\" dictionary and assigns it to the variable timevec\n",
    "    timeseries = stream['time_series']  # Extract the time_series (i.e., DATA) from the \"stream\" dictionary and\n",
    "    samplerate = round(float(stream['info']['nominal_srate'][0]))  # Extracts the rounded sampling rate (nominal_srate) and assigns it to samplerate\n",
    "    channelcount = int(stream['info']['channel_count'][0])  # Extracts the number of channel for each steams and assigns it to channelcount (as an integer)\n",
    "\n",
    "    # Extract channel labels (this step is a bit more complex because of the XDF file configuration)\n",
    "    channel_labels = []  # Initialize an empty list to store channel labels\n",
    "    # Check if there is more than one channel and if the 'desc' field is present in the stream's info\n",
    "    if channelcount > 1 and stream['info']['desc'] is not None:\n",
    "        try:\n",
    "            channels_info = stream['info']['desc'][0]['channels'][0]['channel']  # Attempt to extract channel information from the stream's description\n",
    "            channel_labels = [channel['label'][0] for channel in channels_info]  # Create a list of channel labels by extracting the 'label' field from each channel's info\n",
    "        except (KeyError, IndexError):\n",
    "            channel_labels = [f\"Channel {i + 1}\" for i in range(channelcount)]  # If there is any issue with extracting channel labels, create default labels\n",
    "    else:\n",
    "        channel_labels = [f\"Channel {i + 1}\" for i in range(channelcount)]  # If there is only one channel or the 'desc' field is not present, create default labels\n",
    "\n",
    "    print('working on stream: ' + timeseries_name + '  with a channel count of: ' + str(channelcount) + ' labelled: ' + str(channel_labels) + ' and a sampling rate of ' + str(samplerate))\n",
    "\n",
    "    # Extracting Relevant Events from Marker Stream that will be used as Selectors in the Plots\n",
    "    if timeseries_type == 'Markers':\n",
    "        audio_events = get_events(stream, event_names)  # Using the get_events function to extract events and corresponding LSL times from Marker stream\n",
    "\n",
    "        # Create selector buttons based on audio events\n",
    "        selector_buttons = []\n",
    "        for i in range(0, len(audio_events), 2):\n",
    "            start_event = audio_events[i]\n",
    "            end_event = audio_events[i + 1]\n",
    "            condition_name = start_event[1].split('_StartParticipantSinging')[0]\n",
    "            selector_buttons.append(dict(label=condition_name,\n",
    "                                         method=\"relayout\",\n",
    "                                         args=[{\"xaxis.range\": [float(start_event[0]), float(end_event[0])]}]))\n",
    "\n",
    "        continue  # Skips plotting for Markers stream\n",
    "\n",
    "    # PLOTTING\n",
    "    timeseries = np.array(timeseries)  # Ensure timeseries is a NumPy array\n",
    "\n",
    "    # Plotting subplots in case of multiple channels\n",
    "    if channelcount > 1:\n",
    "        fig = make_subplots(rows=channelcount, cols=1, shared_xaxes=True, vertical_spacing=0.02, subplot_titles=channel_labels)\n",
    "\n",
    "        for i in range(channelcount):\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=timevec,\n",
    "                y=timeseries[:, i],\n",
    "                mode='lines',\n",
    "                name=channel_labels[i]\n",
    "            ), row=i + 1, col=1)\n",
    "\n",
    "        # Update x-axis settings for the last subplot\n",
    "        fig.update_xaxes(\n",
    "            rangeslider=dict(visible=True),\n",
    "            type=\"linear\",\n",
    "            row=channelcount, col=1\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title_text=fnam + '_' + timeseries_name + ' Streams',\n",
    "            height=150 * channelcount + 150,\n",
    "            yaxis_title='Amplitude',\n",
    "            updatemenus=[dict(type=\"buttons\", buttons=selector_buttons, direction=\"down\", showactive=True)]\n",
    "        )\n",
    "        fig.show()\n",
    "\n",
    "    else:\n",
    "        # Plotting single channel data stream\n",
    "        fig = go.Figure()\n",
    "\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=timevec,\n",
    "            y=timeseries[:, 0],\n",
    "            mode='lines',\n",
    "            name=channel_labels[0]\n",
    "        ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title_text=fnam + '_' + timeseries_name + ' Streams',\n",
    "            xaxis=dict(\n",
    "                rangeselector=dict(buttons=selector_buttons),\n",
    "                rangeslider=dict(visible=True),\n",
    "                type=\"linear\"\n",
    "            ),\n",
    "            yaxis_title='Amplitude',\n",
    "            updatemenus=[dict(type=\"buttons\", buttons=selector_buttons, direction=\"down\", showactive=True)]\n",
    "        )\n",
    "\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d14f75b-6907-4213-bd3d-687347aeabd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "event_names = ['_StartParticipantSinging', '_EndParticipantSinging']\n",
    "\n",
    "\n",
    "for xdf_file in xdf_files:               # Iterate over each path in the list \"xdf_files\". \n",
    "\n",
    "    print('loading xdf file: ' + xdf_file )\n",
    "\n",
    "    streams, header = pyxdf.load_xdf(xdf_file)    # Loading steams and header information from each XDF file usign the load_xdf function from the pyxdf library. \n",
    "    fnam = os.path.basename(xdf_file)[:-4]        # Extract the file name from the path and assings it to fnam, whilst removing the '.xdf' extension (i.e., the last 4 characters in the string)\n",
    "       \n",
    "    # Renaming streams using the rename_dict and rename_function (if names match dictionary)\n",
    "    streams = rename_streams(streams, rename_dict)\n",
    "\n",
    "    # Navigating through each stream and extracting the relevant information (e.g., name, sample rate, data, time, etc.) \n",
    "    for stream in streams:                        # Iterate over each steam in the loaded steam for each XDF file .\n",
    "        timeseries_name = stream['info']['name'][0]                    # Extracts name of each steams (dictionary structure) and assigns it to timeseries_name (e.g., Mic). \n",
    "        timeseries_type = stream['info']['type'][0]                     # Extracts type of each steams (dictionary structure) and assigns it to timeseries_type (e.g., Markers). \n",
    "        timevec = stream['time_stamps']                                # Extract the time_stamps (i.e.,LSL TIMESTAMPS) from the \"stream\" dictionary and assigns it to the variable timevec\n",
    "        timeseries = stream['time_series']                             # Extract the time_series (i.e., DATA) from the \"stream\" dictionary and \n",
    "        samplerate = round(float(stream['info']['nominal_srate'][0]))  # Extracts the rounded sampling rate (nominal_srate) and assings it to samplerate \n",
    "        channelcount = int(stream['info']['channel_count'][0])         # Extracts the number of channel for each steams and assigns it to channelcount (as an integer)\n",
    "\n",
    "        # Extract channel labels (this step is a bit more complex because of the XDF file configuration)\n",
    "        channel_labels = []  # Initialize an empty list to store channel labels\n",
    "        # Check if there is more than one channel and if the 'desc' field is present in the stream's info\n",
    "        if channelcount > 1 and stream['info']['desc'] is not None:\n",
    "            try:\n",
    "                channels_info = stream['info']['desc'][0]['channels'][0]['channel']  # Attempt to extract channel information from the stream's description\n",
    "                channel_labels = [channel['label'][0] for channel in channels_info]  # Create a list of channel labels by extracting the 'label' field from each channel's info\n",
    "            except (KeyError, IndexError):\n",
    "                channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]  # If there is any issue with extracting channel labels, create default labels\n",
    "        else:\n",
    "            channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]  # If there is only one channel or the 'desc' field is not present, create default labels\n",
    "\n",
    "        \n",
    "        print('working on stream: ' + timeseries_name + '  with a channel count of: ' + str(channelcount) + ' labelled: ' + str(channel_labels) + ' and a sampling rate of ' + str(samplerate)) \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Extracting Relevant Events from Marker Steam that will be used as Selectors in the Plots \n",
    "        if timeseries_type == 'Markers':\n",
    "            audio_events = get_events(stream, event_names)  #Using the get_events function to extracts events and corresponding LSL times from Marker stream\n",
    "\n",
    "             # Create selector buttons based on audio events\n",
    "            selector_buttons = []\n",
    "            for i in range(0, len(audio_events), 2):\n",
    "                start_event = audio_events[i]\n",
    "                end_event = audio_events[i + 1]\n",
    "                condition_name = start_event[1].split('_StartParticipantSinging')[0]\n",
    "                selector_buttons.append(dict(label=condition_name,\n",
    "                                             method=\"relayout\",\n",
    "                                             args=[{\"xaxis.range\": [float(start_event[0]), float(end_event[0])]}]))\n",
    "                        \n",
    "            continue    # Skips plotting for Markers stream \n",
    "            \n",
    "        # PLOTTING \n",
    "        timeseries = np.array(timeseries)   # Ensure timeseries is a NumPy array\n",
    "        \n",
    "         # Plotting subplots in case of multiple channels\n",
    "        if channelcount > 1:\n",
    "            fig = make_subplots(rows=channelcount, cols=1, shared_xaxes=True, vertical_spacing=0.02, subplot_titles=channel_labels)\n",
    "        \n",
    "            for i in range(channelcount):\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=timevec, \n",
    "                    y=timeseries[:, i],\n",
    "                    mode='lines',\n",
    "                    name=channel_labels[i]\n",
    "                ), row=i+1, col=1)\n",
    "        \n",
    "            # Update x-axis settings for the last subplot\n",
    "            fig.update_xaxes(\n",
    "                rangeslider=dict(visible=True),\n",
    "                type=\"linear\",\n",
    "                row=channelcount, col=1\n",
    "            )\n",
    "\n",
    "            fig.update_layout(\n",
    "                title_text=fnam + '_' + timeseries_name + ' Streams',\n",
    "                height=150 * channelcount + 150,\n",
    "                yaxis_title='Amplitude',\n",
    "                updatemenus=[dict(buttons=selector_buttons, direction=\"down\", showactive=True)]\n",
    "            )\n",
    "\n",
    "            fig.show()\n",
    "            \n",
    "        else:\n",
    "            # Plotting single channel data stream\n",
    "            fig = go.Figure()\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=timevec,\n",
    "                y=timeseries[:, 0],\n",
    "                mode='lines',\n",
    "                name=channel_labels[0]\n",
    "            ))\n",
    "\n",
    "            fig.update_layout(\n",
    "                title_text=fnam + '_' + timeseries_name + ' Streams',\n",
    "                xaxis=dict(\n",
    "                    rangeselector=dict(buttons=selector_buttons),\n",
    "                    rangeslider=dict(visible=True),\n",
    "                    type=\"linear\"\n",
    "                ),\n",
    "                yaxis_title='Amplitude',\n",
    "                updatemenus=[dict(buttons=selector_buttons, direction=\"down\", showactive=True)]\n",
    "            )\n",
    "\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b41447-93b3-4604-b800-8e53e73656db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selector_buttons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80c993-9b8b-4283-b7cf-76b073b33679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "event_names = ['_StartParticipantSinging', '_EndParticipantSinging']\n",
    "\n",
    "\n",
    "for xdf_file in xdf_files:               # Iterate over each path in the list \"xdf_files\". \n",
    "\n",
    "    print('loading xdf file: ' + xdf_file )\n",
    "\n",
    "    streams, header = pyxdf.load_xdf(xdf_file)    # Loading steams and header information from each XDF file usign the load_xdf function from the pyxdf library. \n",
    "    fnam = os.path.basename(xdf_file)[:-4]        # Extract the file name from the path and assings it to fnam, whilst removing the '.xdf' extension (i.e., the last 4 characters in the string)\n",
    "       \n",
    "    # Renaming streams using the rename_dict and rename_function (if names match dictionary)\n",
    "    streams = rename_streams(streams, rename_dict)\n",
    "\n",
    "    # Navigating through each stream and extracting the relevant information (e.g., name, sample rate, data, time, etc.) \n",
    "    for stream in streams:                        # Iterate over each steam in the loaded steam for each XDF file .\n",
    "        timeseries_name = stream['info']['name'][0]                    # Extracts name of each steams (dictionary structure) and assigns it to timeseries_name (e.g., Mic). \n",
    "        timeseries_type = stream['info']['type'][0]                     # Extracts type of each steams (dictionary structure) and assigns it to timeseries_type (e.g., Markers). \n",
    "        timevec = stream['time_stamps']                                # Extract the time_stamps (i.e.,LSL TIMESTAMPS) from the \"stream\" dictionary and assigns it to the variable timevec\n",
    "        timeseries = stream['time_series']                             # Extract the time_series (i.e., DATA) from the \"stream\" dictionary and \n",
    "        samplerate = round(float(stream['info']['nominal_srate'][0]))  # Extracts the rounded sampling rate (nominal_srate) and assings it to samplerate \n",
    "        channelcount = int(stream['info']['channel_count'][0])         # Extracts the number of channel for each steams and assigns it to channelcount (as an integer)\n",
    "\n",
    "        # Extract channel labels (this step is a bit more complex because of the XDF file configuration)\n",
    "        channel_labels = []  # Initialize an empty list to store channel labels\n",
    "        # Check if there is more than one channel and if the 'desc' field is present in the stream's info\n",
    "        if channelcount > 1 and stream['info']['desc'] is not None:\n",
    "            try:\n",
    "                channels_info = stream['info']['desc'][0]['channels'][0]['channel']  # Attempt to extract channel information from the stream's description\n",
    "                channel_labels = [channel['label'][0] for channel in channels_info]  # Create a list of channel labels by extracting the 'label' field from each channel's info\n",
    "            except (KeyError, IndexError):\n",
    "                channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]  # If there is any issue with extracting channel labels, create default labels\n",
    "        else:\n",
    "            channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]  # If there is only one channel or the 'desc' field is not present, create default labels\n",
    "\n",
    "        \n",
    "        print('working on stream: ' + timeseries_name + '  with a channel count of: ' + str(channelcount) + ' labelled: ' + str(channel_labels) + ' and a sampling rate of ' + str(samplerate)) \n",
    "        \n",
    "        \n",
    "        \n",
    "        # Extracting Relevant Events from Marker Steam that will be used as Selectors in the Plots \n",
    "        if timeseries_type == 'Markers':\n",
    "            audio_events_steam = get_events(stream, event_names)  #Using the get_events function to extracts events and corresponding LSL times from Marker stream\n",
    "\n",
    "            continue    # Skips plotting for Markers stream \n",
    "            \n",
    "        # PLOTTING \n",
    "        timeseries = np.array(timeseries)   # Ensure timeseries is a NumPy array\n",
    "        \n",
    "        # Plotting subplots in case of multiple streams \n",
    "        if channelcount > 1:\n",
    "            fig = make_subplots(rows=channelcount, cols=1, shared_xaxes=True, vertical_spacing=0.02, subplot_titles=channel_labels)\n",
    "        \n",
    "            for i in range(channelcount):\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=timevec, \n",
    "                    y=timeseries[:, i],\n",
    "                    mode='lines',\n",
    "                    name=channel_labels[i]\n",
    "                ), row=i+1, col=1)\n",
    "        \n",
    "                fig.update_yaxes(title_text=channel_labels[i], row=i+1, col=1)\n",
    "        \n",
    "            # Update x-axis settings for all subplots\n",
    "            fig.update_layout(\n",
    "                title_text=fnam + '_' + timeseries_name + ' Streams',\n",
    "                height=300 * channelcount,\n",
    "                xaxis=dict(\n",
    "                    rangeselector=dict(\n",
    "                        buttons=list([\n",
    "                            dict(count=1,\n",
    "                                 label=\"1m\",\n",
    "                                 step=\"minute\",\n",
    "                                 stepmode=\"backward\"),\n",
    "                            dict(count=10,\n",
    "                                 label=\"10m\",\n",
    "                                 step=\"minute\",\n",
    "                                 stepmode=\"backward\"),\n",
    "                            dict(step=\"all\")\n",
    "                        ])\n",
    "                    ),\n",
    "                    rangeslider=dict(\n",
    "                        visible=True\n",
    "                    ),\n",
    "                    type=\"linear\"\n",
    "                ),\n",
    "                yaxis_title='Amplitude'\n",
    "            )\n",
    "        \n",
    "            fig.show()\n",
    "                    \n",
    "        else:\n",
    "            # Plotting single channel data stream\n",
    "            fig = go.Figure()\n",
    "            timeseries = np.array(timeseries)  # Ensure timeseries is a NumPy array\n",
    "        \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=timevec,\n",
    "                y=timeseries[:, 0],\n",
    "                mode='lines',\n",
    "                name=channel_labels[0]\n",
    "            ))\n",
    "        \n",
    "            fig.update_layout(\n",
    "                title_text=fnam + '_' + timeseries_name + ' Streams',\n",
    "                xaxis=dict(\n",
    "                    rangeselector=dict(\n",
    "                        buttons=list([\n",
    "                            dict(count=1,\n",
    "                                 label=\"1m\",\n",
    "                                 step=\"minute\",\n",
    "                                 stepmode=\"backward\"),\n",
    "                            dict(count=10,\n",
    "                                 label=\"10m\",\n",
    "                                 step=\"minute\",\n",
    "                                 stepmode=\"backward\"),\n",
    "                            dict(step=\"all\")\n",
    "                        ])\n",
    "                    ),\n",
    "                    rangeslider=dict(\n",
    "                        visible=True\n",
    "                    ),\n",
    "                    type=\"linear\"\n",
    "                ),\n",
    "                yaxis_title='Amplitude'\n",
    "            )\n",
    "        \n",
    "            fig.show()\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb25f25-6416-42e7-9861-cfbfb11a32ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "                     # fig.show()\n",
    "        \n",
    "            #     # Update x-axis settings for the last subplot\n",
    "            #     if i == channelcount-1:\n",
    "            #         fig.update_xaxes(\n",
    "            #             rangeselector=dict(\n",
    "            #                 buttons=list([\n",
    "            #                     dict(count=1,\n",
    "            #                          label=\"1m\",\n",
    "            #                          step=\"minute\",\n",
    "            #                          stepmode=\"backward\"),\n",
    "            #                     dict(count=10,\n",
    "            #                          label=\"10m\",\n",
    "            #                          step=\"minute\",\n",
    "            #                          stepmode=\"backward\"),\n",
    "            #                     dict(step=\"all\")\n",
    "            #                 ])\n",
    "            #             ),\n",
    "            #             rangeslider=dict(\n",
    "            #                 visible=True\n",
    "            #             ),\n",
    "            #             type=\"linear\",\n",
    "            #             row=i+1, col=1\n",
    "                        )\n",
    "\n",
    "            # Plotting Events (i.e., triggers) \n",
    "        # if stream['info']['channel_format'][0] == 'string':\n",
    "        #     plt.figure(figsize=(12, 6))\n",
    "        #     y_pos = np.arange(len(timevec))  # Create a y-position for each event to avoid overlap\n",
    "        #     plt.scatter(timevec, [1] * len(timevec), marker='o')\n",
    "        #     for i, event in enumerate(timeseries):\n",
    "        #         plt.text(timevec[i], 1.01, event[0], rotation=45, ha='right', va='bottom', fontsize=6)\n",
    "        #     plt.title(fnam + '_' + timeseries_type + ' Events')\n",
    "        #     plt.xlabel('Time')\n",
    "        #     plt.yticks([])\n",
    "        #     plt.grid(True)\n",
    "        #     plt.show()\n",
    "\n",
    "\n",
    "        #     else:\n",
    "        #     # Plotting data streams with Plotly subplots if multiple channels\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            # # Plotting data streams with subplots and sliders\n",
    "            # fig, axs = plt.subplots(channelcount, 1, figsize=(12, 6 * channelcount), sharex=True)\n",
    "            # timeseries = np.array(timeseries)\n",
    "            # if channelcount == 1:\n",
    "            #     axs = [axs]  # Ensure axs is always a list\n",
    "\n",
    "            # for i in range(channelcount):\n",
    "            #     axs[i].plot(timevec, timeseries[:, i], label=channel_labels[i])\n",
    "            #     axs[i].set_title(f'{channel_labels[i]}')\n",
    "            #     axs[i].set_ylabel('Amplitude')\n",
    "            #     axs[i].grid(True)\n",
    "            #     axs[i].legend()\n",
    "\n",
    "            # axs[-1].set_xlabel('Time')\n",
    "\n",
    "            # # Adding slider for each subplot\n",
    "            # sliders = []\n",
    "            # axcolor = 'lightgoldenrodyellow'\n",
    "            # for i in range(channelcount):\n",
    "            #     ax_slider = plt.axes([0.25, 0.02 + i * 0.04, 0.65, 0.03], facecolor=axcolor)\n",
    "            #     slider = Slider(ax_slider, 'Range', timevec[0], timevec[-1], valinit=timevec[-1])\n",
    "            #     sliders.append(slider)\n",
    "\n",
    "            #     def update(val, ax=axs[i], slider=slider):\n",
    "            #         pos = slider.val\n",
    "            #         ax.set_xlim(timevec[0], pos)\n",
    "            #         fig.canvas.draw_idle()\n",
    "\n",
    "            #     slider.on_changed(update)\n",
    "\n",
    "            # plt.tight_layout()\n",
    "            # plt.show()\n",
    "             \n",
    "        # else:\n",
    "        #         # Plotting data streams \n",
    "        #     plt.figure(figsize=(12, 6))  # Adjust the figure size as needed\n",
    "        #     timeseries = np.array(timeseries)\n",
    "        #     for i in range(channelcount):\n",
    "        #         plt.plot(timevec, timeseries[:, i], label=channel_labels[i])\n",
    "        #     plt.title(fnam + '_' + timeseries_type + ' Streams')\n",
    "        #     plt.xlabel('Time')\n",
    "        #     plt.ylabel('Amplitude')\n",
    "        #     plt.legend()\n",
    "        #     plt.grid(True)\n",
    "        #     plt.show()\n",
    "        ## -------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4807487c-cb0c-4b18-acb8-702f0a1e6b21",
   "metadata": {},
   "source": [
    "Add a plotting/quality check passage to see each stream and each channel \n",
    "\n",
    "For Opensignals, maybe add subpanels to change the y axis. \n",
    "    subplots with total height of bigger plot. \n",
    "\n",
    "    Envision box plotly (selecting, smoothing and deriving measures) --> Use the slider range as well \n",
    "\n",
    "Naming the files. \n",
    "    In the lab setup, we will publish the scripts that stream the data to Lab recorder. \n",
    "    Each stream should be named accordingly \n",
    "    For now, we can change the actual stream names in the xdf file manually by using pyXDF (the same names will be used). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49683b68-6380-4a4b-916c-717ee799f219",
   "metadata": {},
   "source": [
    "Creating saving xdf folders for each session. Name of files will be Session_X_P_X_streamname\n",
    "\n",
    "\n",
    "\n",
    "Downsampling the videos \n",
    "\n",
    "go into timevec (original fps is about 200 with LSL)\n",
    "indent every 1/5 and extract the timevec (LSL time) and timeseries data \n",
    "Put into a new matrix\n",
    "Go into the video with this new matrix and "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889186dc-4248-4fa3-9a18-3d61abfc6f10",
   "metadata": {},
   "source": [
    "## 4. Clipping videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "829065cc-f797-4d62-a961-705e23d4fa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Video_P1 for P1: T1_experiment_Video_P1.csv\n",
      "This is the file path: F:\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\data_processed\\T1_experiment_Video_P1.csv\n",
      "loading the csv file  T1_experiment_Video_P1.csvcontaining LSL times and frames numbers  \n",
      "Downsampling the LSL times and frame numbers to 50fps. This might take some time\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39be5ed69761410298161bfe16fa6a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downsampling LSL times and frames:   0%|          | 0/49354 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading video: T1_P1_exp_2024-04-23_output_compr.avi\n",
      "Now extracting metadata from video: T1_P1_exp_2024-04-23_output_compr.avi\n",
      "video_tot_frames: 60451\n",
      "Video frames per second: 60.0\n",
      "Now re-writing the video T1_P1_exp_2024-04-23_output_compr.avi based on the donwsampled LSL times and frames\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rewriting Video Progress:   0%|                                           | 0/60451 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as ./video_cut/cut_P1.avi\n",
      "Processing Video_P2 for P2: T1_experiment_Video_P2.csv\n",
      "This is the file path: F:\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\data_processed\\T1_experiment_Video_P2.csv\n",
      "loading the csv file  T1_experiment_Video_P2.csvcontaining LSL times and frames numbers  \n",
      "Downsampling the LSL times and frame numbers to 50fps. This might take some time\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5753b1c6035344d392d3774a1c5399d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downsampling LSL times and frames:   0%|          | 0/49354 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now loading video: T1_P2_exp_2024-04-23_output_compr.avi\n",
      "Now extracting metadata from video: T1_P2_exp_2024-04-23_output_compr.avi\n",
      "video_tot_frames: 67550\n",
      "Video frames per second: 60.0\n",
      "Now re-writing the video T1_P2_exp_2024-04-23_output_compr.avi based on the donwsampled LSL times and frames\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rewriting Video Progress:   0%|                                           | 0/67550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as ./video_cut/cut_P2.avi\n",
      "Done with cutting all videos! You can now look into your folder: ./video_cut/\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "input_video_folder = './video_raw/'    # this folder should only contain the videos you want to process. \n",
    "output_video_folder = './video_cut/'\n",
    "input_file_folder = './data_processed/'\n",
    "\n",
    "# List of participant file pairs\n",
    "participants_files = [\n",
    "    ('Video_P1', 'P1'),\n",
    "    ('Video_P2', 'P2')\n",
    "]\n",
    "\n",
    "# Loading the relevant CSV files (called here ') that contain the LSL_time stamps and corresponding video frames\n",
    "for participant_frame, participant_video in participants_files:\n",
    "    \n",
    "    # Loading the relevant CSV files for each participant\n",
    "    for file in os.listdir(os.path.abspath(input_file_folder)):\n",
    "        \n",
    "        if participant_frame in file:  # Check for the corresponding participant\n",
    "            \n",
    "            print(f'Processing {participant_frame} for {participant_video}: {file}')\n",
    "            \n",
    "            file_path = os.path.join(os.path.abspath(input_file_folder), file)\n",
    "            print(f'This is the file path: {file_path}')\n",
    "\n",
    "            print('loading the csv file  ' + str(file) + 'containing LSL times and frames numbers  ' ) \n",
    "\n",
    "            # Loading the CSV file\n",
    "            file_data = pd.read_csv(file_path) # Reads the CSV file at the constructed path into a DataFrame called file_data \n",
    "\n",
    "           \n",
    "           #-----------  Downsampling----------------\n",
    "            print('Downsampling the LSL times and frame numbers to 50fps. This might take some time')\n",
    "        \n",
    "            downsampled_data = file_data.copy()    #creating a copy to work with. \n",
    "           \n",
    "            # Resample to 50 fps (every 20ms)\n",
    "            resampled_time = np.arange(downsampled_data.iloc[:, 0].min(), downsampled_data.iloc[:, 0].max(), 1/50)\n",
    "\n",
    "            # Initialize the progress bar\n",
    "            pbar = tqdm(total=len(resampled_time), desc=\"Downsampling LSL times and frames\")\n",
    "\n",
    "            #Looping over the LSL_times to find the closest time and frame index \n",
    "            resampled_frames = []\n",
    "            for time in resampled_time:\n",
    "                closest_index = (downsampled_data.iloc[:, 0] - time).abs().idxmin()\n",
    "                resampled_frames.append(downsampled_data.iloc[closest_index, 1])\n",
    "                pbar.update(1)  # Update the progress bar\n",
    "\n",
    "             # Convert resampled frames to a DataFrame  (useful for further processing)\n",
    "            resampled_data = pd.DataFrame({\n",
    "                'LSL_time': resampled_time,\n",
    "                'Video_Frames': resampled_frames\n",
    "            })\n",
    "\n",
    "            print(\"length of original video LSL csv: \" + len(file_data))\n",
    "            print(\"length of resampled video LSL csv: \" + len(resampled_data))\n",
    "\n",
    "            print(\"min value resampled: \" + resampled_data.iloc[:, 1].min())\n",
    "            print(\"max value resampled\" + resampled_data.iloc[:, 1].max())\n",
    "\n",
    "            print(\"2 nd value resampled: \" + resampled_data.iloc[:, 1].min())\n",
    "            print(\"end to last value resampled\" + resampled_data.iloc[:, 1].max())\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "                  \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            # Loading the original videos corresponding to the CSV files that will be cut according to resampled_data\n",
    "            for video in os.listdir(os.path.abspath(input_video_folder)):\n",
    "                \n",
    "                if participant_video in video:  # Check for the corresponding participant  \n",
    "                    \n",
    "                    print('Now loading video: ' + video)\n",
    "                    \n",
    "                    video_filepath = os.path.join(os.path.abspath(input_video_folder), video)\n",
    "                    capture = cv2.VideoCapture(video_filepath)  \n",
    "                \n",
    "                    # Extracting relevant meta-data about the video using CV2\n",
    "                    print('Now extracting metadata from video: ' + video)\n",
    "                    \n",
    "                    video_frame_width  = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))  \n",
    "                    video_frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))  \n",
    "                    video_frame_rate   = capture.get(cv2.CAP_PROP_FPS)\n",
    "                    video_tot_frames   = int(capture.get(cv2.CAP_PROP_FRAME_COUNT)) \n",
    "                    \n",
    "                    print('video_tot_frames: ' +  str(video_tot_frames))\n",
    "                    print('Video frames per second: ' + str(video_frame_rate))\n",
    "            \n",
    "            \n",
    "                     # ------------  Downsampling Videos -----------------\n",
    "                    print('Now re-writing the video ' + video + ' based on the donwsampled LSL times and frames')\n",
    "            \n",
    "                    # Prepare to write the new video\n",
    "                    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Specify the codec for the AVI format. 'XVID' is commonly used for AVI files.\n",
    "                    output_filepath = os.path.join(output_video_folder, f'cut_{participant_video}.avi')  # Set the path for the output video file with an AVI extension.\n",
    "                    out = cv2.VideoWriter(output_filepath, fourcc, 50, (video_frame_width, video_frame_height))  # Initialize the VideoWriter object to write frames to a new video file.\n",
    "\n",
    "                    # Read and write the resampled frames\n",
    "                    frame_count = 0  # Initialize a counter for the current frame being processed\n",
    "                    with tqdm(total=video_tot_frames, desc=\"Rewriting Video Progress\", leave=False, ncols=100) as pbar:\n",
    "                        while capture.isOpened():\n",
    "                            # Read the next frame\n",
    "                            ret, frame = capture.read()\n",
    "                            if ret:\n",
    "                                # Increment the frame count\n",
    "                                frame_count += 1 \n",
    "                                pbar.update(1)  # Update the progress bar\n",
    "                                \n",
    "                                if frame_count in resampled_frames:\n",
    "                                    #cv2.imshow('frame',frame)\n",
    "                                    #cv2.waitKey(1000/30)\n",
    "                                    out.write(frame)\n",
    "                                pbar.update(1)  # Update the progress bar\n",
    "                            else:\n",
    "                                break\n",
    "            \n",
    "                    \n",
    "                    capture.release()\n",
    "                    out.release()\n",
    "                    \n",
    "                    print(f'Video saved as {output_filepath}')\n",
    "            \n",
    "print(\"Done with cutting all videos! You can now look into your folder: \" + output_video_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e0f6d3-786d-4352-8559-636ef74d8b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a413dc03-1363-4302-a4a6-070c9f3b5e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3895f6-9079-4af8-b888-22043ea4b63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325db20-274e-4570-86d0-e2551f844a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting relevant information from this CSV file \n",
    "LSL_begin_time = resampled_data.iloc[:,0].min()       # Extracts the minimum value from the first column in the resampled_data (i.e., the first LSL_timestamps). \n",
    "LSL_begin_frame = int(resampled_data.iloc[:,1].min())  # Extracts the minimum value from the second column in the resampled_data (i.e., the first video frame)\n",
    "LSL_end_time = resampled_data.iloc[:,0].max()          # Extracts the maximum value from the first column in the resampled_data (i.e., the last LSL_timestamps).\n",
    "LSL_end_frame = int(resampled_data.iloc[:,1].max())    # Extracts the maximum value from the second column in the file_data (i.e., the last video frame).\n",
    "\n",
    "LSL_tot_frames = LSL_end_frame - LSL_begin_frame    # Total number of frames from start to finish recording.\n",
    "LSL_frames = range(LSL_begin_frame, LSL_end_frame)  # Sequence of all frames numbered from the start to the end. \n",
    "\n",
    "LSL_fps = round((LSL_tot_frames / (LSL_end_time - LSL_begin_time)), 3)\n",
    "\n",
    "print(len(resampled_time))\n",
    "print(len(file_data))\n",
    "\n",
    "print(LSL_begin_time)\n",
    "print(LSL_begin_frame)\n",
    "print(LSL_end_frame)\n",
    "print(LSL_end_frame)\n",
    "print(LSL_fps)\n",
    "\n",
    "print(resampled_time)\n",
    "# print(resampled_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0d266-ee15-4a21-b475-7c1011114393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "input_video_folder = './video_raw/'    # this folder should only contain the videos you want to process. \n",
    "output_video_folder = './video_cut_2/'\n",
    "input_file_folder = './data_processed/'\n",
    "\n",
    "# List of participant file pairs\n",
    "participants_files = [\n",
    "    ('Video_P1', 'P1'),\n",
    "    ('Video_P2', 'P2')\n",
    "]\n",
    "\n",
    "\n",
    "# Loading the original videos corresponding to the CSV files that will be cut according to resampled_data\n",
    "for video in os.listdir(os.path.abspath(input_video_folder)):\n",
    "    \n",
    "    if participant_video in video:  # Check for the corresponding participant  \n",
    "        \n",
    "        print('Now loading video: ' + video)\n",
    "        \n",
    "        video_filepath = os.path.join(os.path.abspath(input_video_folder), video)\n",
    "        capture = cv2.VideoCapture(video_filepath)  \n",
    "    \n",
    "        # Extracting relevant meta-data about the video using CV2\n",
    "        print('Now extracting metadata from video: ' + video)\n",
    "        \n",
    "        video_frame_width  = int(capture.get(cv2.CAP_PROP_FRAME_WIDTH))  \n",
    "        video_frame_height = int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))  \n",
    "        video_frame_rate   = capture.get(cv2.CAP_PROP_FPS)\n",
    "        video_tot_frames   = int(capture.get(cv2.CAP_PROP_FRAME_COUNT)) \n",
    "        \n",
    "        print('video_tot_frames: ' +  str(video_tot_frames))\n",
    "        print('Video frames per second: ' + str(video_frame_rate))\n",
    "\n",
    "\n",
    "         # ------------  Downsampling Videos -----------------\n",
    "        print('Now re-writing the video ' + video + ' based on the donwsampled LSL times and frames')\n",
    "\n",
    "        # Prepare to write the new video\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Specify the codec for the AVI format. 'XVID' is commonly used for AVI files.\n",
    "        output_filepath = os.path.join(output_video_folder, f'cut_{participant_video}.avi')  # Set the path for the output video file with an AVI extension.\n",
    "        out = cv2.VideoWriter(output_filepath, fourcc, 50, (video_frame_width, video_frame_height))  # Initialize the VideoWriter object to write frames to a new video file.\n",
    "        \n",
    "        # Read and write the resampled frames\n",
    "        frame_count = 0  # Initialize a counter for the current frame being processed.\n",
    "        with tqdm(total=video_tot_frames, desc=\"Processing Video Frames\") as pbar:\n",
    "            while capture.isOpened():\n",
    "                # Read the next frame\n",
    "                ret, frame = capture.read()\n",
    "                if ret:\n",
    "                    # Increment the frame count\n",
    "                    frame_count += 1 \n",
    "                    if frame_count in resampled_frames:\n",
    "                        #cv2.imshow('frame',frame)\n",
    "                        #cv2.waitKey(1000/30)\n",
    "                        out.write(frame)\n",
    "                    pbar.update(1)  # Update the progress bar\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        \n",
    "        capture.release()\n",
    "        out.release()\n",
    "        print(f'Video saved as {output_filepath}')\n",
    "\n",
    "print(\"Done with cutting all videos! You can now look into your folder: \" + output_video_folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        #     if frame_count > video_tot_frames:\n",
    "        #         capture.release()\n",
    "        #         out.release() \n",
    "        \n",
    "        # capture.release()\n",
    "        # out.release()\n",
    "        # print(f'Video saved as {output_filepath}')\n",
    "\n",
    "        # # Prepare to write the new video\n",
    "        # fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Specify the codec for the AVI format. 'XVID' is commonly used for AVI files.\n",
    "        # output_filepath = os.path.join(output_video_folder, f'cut_{participant_video}.avi')  # Set the path for the output video file with an AVI extension.\n",
    "        # out = cv2.VideoWriter(output_filepath, fourcc, 50, (video_frame_width, video_frame_height))  # Initialize the VideoWriter object to write frames to a new video file.\n",
    "        \n",
    "        # # Read and write the resampled frames\n",
    "        # current_frame = 0  # Initialize a counter for the current frame being processed.\n",
    "        # for frame_idx in resampled_frames:  # Loop through each frame index in the resampled frames list.\n",
    "        #     capture.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)  # Set the video capture to the position of the desired frame index.\n",
    "        #     ret, frame = capture.read()  # Read the frame at the current position.\n",
    "        #     if not ret:  # If the frame is not read correctly (e.g., end of the video), break the loop.\n",
    "        #         print(f'Frame at index {frame_idx} could not be read.')\n",
    "        #         break\n",
    "        #     out.write(frame)  # Write the read frame to the new video file.\n",
    "        #     current_frame += 1  # Increment the frame counter.          \n",
    "\n",
    "        #  while capture.isOpened():\n",
    "        #                 # Read the next frame\n",
    "        #     ret, frame = capture.read()\n",
    "        #     if ret:\n",
    "        #          # Increment the frame count\n",
    "        #         frame_count += 1 \n",
    "        #         if frame_count in resampled_frames:\n",
    "        #             #cv2.imshow('frame',frame)\n",
    "        #             #cv2.waitKey(1000/30)\n",
    "        #             out.write(frame)\n",
    "        #     if frame > video_tot_frames:\n",
    "        #         capture.release()\n",
    "        #         out.release() \n",
    "        \n",
    "        # capture.release()\n",
    "        # out.release()\n",
    "        # print(f'Video saved as {output_filepath}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68ba44d-d1f8-45de-bc19-458541bcb84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4975c794-9acf-4f6d-9199-5f5a9556a763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdd6f26-276c-4834-8082-8ebd9e160e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247571c7-2592-4a94-ba32-871fa53cecfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "             # Loading the original videos corresponding to the CSV files that will be cut according to resampled_data\n",
    "            for video in os.listdir(os.path.abspath(input_video_folder)):\n",
    "                \n",
    "                if participant_video in video:  # Check for the corresponding participant  \n",
    "                    \n",
    "                    print('Now loading video: ' + video)\n",
    "                    \n",
    "                    video_filepath = os.path.join(os.path.abspath(input_video_folder), video)\n",
    "                    capture = cv2.VideoCapture(video_filepath)  \n",
    "                \n",
    "                    # Extracting relevant meta-data about the video using CV2\n",
    "                    print('Now extracting metadata from video: ' + video)\n",
    "                    \n",
    "                    video_frame_width  = capture.get(cv2.CAP_PROP_FRAME_WIDTH)  \n",
    "                    video_frame_height = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)  \n",
    "                    video_frame_rate   = capture.get(cv2.CAP_PROP_FPS)\n",
    "                    video_tot_frames   = int(capture.get(cv2.CAP_PROP_FRAME_COUNT)) \n",
    "                    capture.release()\n",
    "                    print('video_tot_frames: ' +  str(video_tot_frames))\n",
    "                    print('Video frames per second: ' + str(video_frame_rate))\n",
    "\n",
    "\n",
    "                     # ------------  Downsampling Videos -----------------\n",
    "                    print('Now re-writing the video ' + video + ' based on the donwsampled LSL times and frames')\n",
    "\n",
    "                    # Prepare to write the new video\n",
    "                    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Specify the codec for the AVI format. 'XVID' is commonly used for AVI files.\n",
    "                    output_filepath = os.path.join(output_video_folder, f'cut_{participant_video}.avi')  # Set the path for the output video file with an AVI extension.\n",
    "                    out = cv2.VideoWriter(output_filepath, fourcc, 50, (video_frame_width, video_frame_height))  # Initialize the VideoWriter object to write frames to a new video file.\n",
    "                    \n",
    "                    # Read and write the resampled frames\n",
    "                    current_frame = 0  # Initialize a counter for the current frame being processed.\n",
    "                    for frame_idx in resampled_frames:  # Loop through each frame index in the resampled frames list.\n",
    "                        capture.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)  # Set the video capture to the position of the desired frame index.\n",
    "                        ret, frame = capture.read()  # Read the frame at the current position.\n",
    "                        if not ret:  # If the frame is not read correctly (e.g., end of the video), break the loop.\n",
    "                            break\n",
    "                        out.write(frame)  # Write the read frame to the new video file.\n",
    "                        current_frame += 1  # Increment the frame counter.\n",
    "\n",
    "                    capture.release()\n",
    "                    out.release()\n",
    "                    print(f'Video saved as {output_filepath}')\n",
    "\n",
    "            \n",
    "\n",
    "                          \n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "            # Extracting relevant information from this resampled_data\n",
    "            LSL_begin_time = resampled_data.iloc[:,0].min()       # Extracts the minimum value from the first column in the resampled_data (i.e., the first LSL_timestamps). \n",
    "            LSL_begin_frame = int(resampled_data.iloc[:,1].min())  # Extracts the minimum value from the second column in the resampled_data (i.e., the first video frame)\n",
    "            LSL_end_time = resampled_data.iloc[:,0].max()          # Extracts the maximum value from the first column in the resampled_data (i.e., the last LSL_timestamps).\n",
    "            LSL_end_frame = int(resampled_data.iloc[:,1].max())    # Extracts the maximum value from the second column in the file_data (i.e., the last video frame).\n",
    "\n",
    "            LSL_tot_frames = LSL_end_frame - LSL_begin_frame    # Total number of frames from start to finish recording.\n",
    "            LSL_frames = range(LSL_begin_frame, LSL_end_frame)  # Sequence of all frames numbered from the start to the end. \n",
    "            \n",
    "            LSL_fps = round((LSL_tot_frames / (LSL_end_time - LSL_begin_time)), 3)\n",
    "                           \n",
    "\n",
    "            # Loading the original videos corresponding to the CSV files that will be cut according to LSL start and ends\n",
    "            for video in os.listdir(os.path.abspath(input_video_folder)):\n",
    "                \n",
    "                if participant_video in video:  # Check for the corresponding participant  \n",
    "                    \n",
    "                    print('Now processing video: ' + video)\n",
    "                    \n",
    "                    video_filepath = os.path.join(os.path.abspath(input_video_folder), video)\n",
    "                    capture = cv2.VideoCapture(video_filepath)  \n",
    "                \n",
    "                    # Extracting relevant meta-data about the video using CV2\n",
    "                    video_frame_width  = capture.get(cv2.CAP_PROP_FRAME_WIDTH)  \n",
    "                    video_frame_height = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)  \n",
    "                    video_frame_rate   = capture.get(cv2.CAP_PROP_FPS)\n",
    "                    video_tot_frames   = int(capture.get(cv2.CAP_PROP_FRAME_COUNT)) \n",
    "                    capture.release()\n",
    "                    print('video_tot_frames: ' +  str(video_tot_frames))\n",
    "                    print('Video frames per second: ' + str(video_frame_rate))\n",
    "        \n",
    "                    # Cutting video Using ffmpeg \n",
    "                    # Converting the LSL frames to the video time format to find start_cut and end_cut for the video\n",
    "                    start_cut_time = frame_to_time(LSL_begin_frame, video_frame_rate)\n",
    "                    end_cut_time = frame_to_time(LSL_end_frame, video_frame_rate)\n",
    "        \n",
    "                    print('Now cutting the video...')\n",
    "        \n",
    "                    # Determine the file extension and codec\n",
    "                    file_extension = os.path.splitext(video)[1].lower()\n",
    "                    codec = extension_to_codec.get(file_extension, 'libx264')  # Default to libx264 if not found\n",
    "        \n",
    "                    # Construct output file path with the same extension\n",
    "                    output_filename = f'cut_{os.path.splitext(video)[0]}{file_extension}'\n",
    "                    output_filepath = os.path.join(output_video_folder, output_filename)\n",
    "        \n",
    "                    # Use ffmpeg to cut the video\n",
    "                    ffmpeg_command = [\n",
    "                        'ffmpeg',\n",
    "                        '-y',                  # Add -y flag to overwrite any existing files with the same name\n",
    "                        '-i', video_filepath,\n",
    "                        '-ss', start_cut_time,  # start time\n",
    "                        '-to', end_cut_time,    # end time\n",
    "                        '-c', 'copy',           # copy codec (no re-encoding)\n",
    "                        output_filepath]\n",
    "                    \n",
    "                    # Execute the command\n",
    "                    subprocess.run(ffmpeg_command, check=True)\n",
    "        \n",
    "                    print(f'Video saved as {output_filepath}')\n",
    "            \n",
    "\n",
    "print(\"Done with cutting all videos! You can now look into your folder: \" + output_video_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3738df-2cb7-40ff-99cb-e0b7b4050bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d3904c-20f2-46ac-8d2d-3421f85af4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fea48c-e33e-4f0a-988a-a13f06b25d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_folder = './video_raw/'    #this folder should only contain the videos you want to process. \n",
    "output_video_folder = './video_cut/'\n",
    "input_file_folder = './data_processed/'\n",
    "\n",
    "# List of participant file pairs       #--------------- SOULD WE DO THIS ANOTHER WAY? MAYBE SAVING THE VSC FILES WITH A CONSISTENT NAME? ---- \n",
    "participants_files = [\n",
    "    ('Video_P1', 'P1'),\n",
    "    ('Video_P2', 'P2')\n",
    "]\n",
    "\n",
    "\n",
    "# Loading the relevant CVS files (called here ') that contain the LSL_time stamps and correspnding video frames\n",
    "for participant_frame, participant_video in participants_files:\n",
    "    \n",
    "    # Loading the relevant CSV files for each participant\n",
    "    for file in os.listdir(os.path.abspath(input_file_folder)):\n",
    "        \n",
    "        if participant_frame in file:  # Check for the corresponding participant\n",
    "            \n",
    "            print(f'Processing {participant_frame} for {participant_video}: {file}')\n",
    "            \n",
    "            file_path = os.path.join(os.path.abspath(input_file_folder), file)\n",
    "            print(f'This is the file path: {file_path}')\n",
    "\n",
    "            # Loading the CSV file\n",
    "            file_data = pd.read_csv(file_path) # Reads the CSV file at the constructed path into a DataFrame called file_data        \n",
    "\n",
    "            # Resample to 50 fps (every 20ms)\n",
    "            resampled_time = pd.date_range(start=file_data.iloc[:, 0].min(), end=file_data.iloc[:, 0].max(), freq='20ms')\n",
    "\n",
    "            resampled_frames = []\n",
    "            for time in resampled_time:\n",
    "                closest_index = (file_data.iloc[:, 0] - time).abs().idxmin()\n",
    "                resampled_frames.append(file_data.iloc[closest_index, 1])\n",
    "\n",
    "            # Extracting relevant information from this CSV file \n",
    "            LSL_begin_time = file_data.iloc[:,0].min()       # Extracts the minimum value from the first column in the file_data (i.e., the first LSL_timestamps). \n",
    "            LSL_begin_frame = int(file_data.iloc[:,1].min())  # Extracts the minimum value from the second column in the file_data (i.e., the first video frame)\n",
    "            LSL_end_time = file_data.iloc[:,0].max()          # Extracts the maximum value from the first column in the file_data (i.e., the last LSL_timestamps).\n",
    "            LSL_end_frame = int(file_data.iloc[:,1].max())    # Extracts the maximum value from the second column in the file_data (i.e., the last video frame).\n",
    "\n",
    "            # print(LSL_begin_time )\n",
    "            # print(LSL_begin_frame)\n",
    "            # print(LSL_end_time)\n",
    "            # print(LSL_end_frame)\n",
    "\n",
    "            \n",
    "\n",
    "            LSL_tot_frames = LSL_end_frame - LSL_begin_frame    # Total number of frames from start to finish recording.\n",
    "            LSL_frames = range(LSL_begin_frame , LSL_end_frame)  # Sequence of all frames numbered from the start to the end. \n",
    "            'Add comment about Theoretical understanding of frame numbers and LSL fps streaming' \n",
    "            \n",
    "            LSL_fps = round((LSL_tot_frames / (LSL_end_time - LSL_begin_time)), 3)\n",
    "\n",
    "            0/0\n",
    "            \n",
    "            new_range = (LSL_begin_time : 1/50 : LSL_end_time) \n",
    "            print(new_range) \n",
    "\n",
    "            framelist = []\n",
    "            for i in new_range: \n",
    "                index_time = which.min(file_data.iloc[:,0]%%i)\n",
    "                index_frame = file_data.iloc[index_time:1]\n",
    "                framelist.append(index_frame) \n",
    "                \n",
    "            print('LSL_tot_frames: ' + str(LSL_tot_frames))\n",
    "            print('LSL frames per second: ' + str(LSL_fps))\n",
    "            'Is this LSL_fps variable??' \n",
    "\n",
    "\n",
    "            0/0\n",
    "            # ----------------------------------------\n",
    "            # Loading the original videos corresponding to the CSV files that will be cut according to LSL start and ends\n",
    "            for video in os.listdir(os.path.abspath(input_video_folder)):\n",
    "                \n",
    "                if participant_video in video:  # Check for the corresponding participant  \n",
    "                    \n",
    "                    print('Now processing video: ' + video)\n",
    "                    \n",
    "                    video_filepath = os.path.join(os.path.abspath(input_video_folder), video)\n",
    "                    capture = cv2.VideoCapture(video_filepath)  \n",
    "                \n",
    "                    # Extracting relevant meta-data about the video using CV2\n",
    "                    video_frame_width  = capture.get(cv2.CAP_PROP_FRAME_WIDTH)  \n",
    "                    video_frame_height = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)  \n",
    "                    video_frame_rate   = capture.get(cv2.CAP_PROP_FPS)\n",
    "                    video_tot_frames   = int(capture.get(cv2.CAP_PROP_FRAME_COUNT)) \n",
    "                    capture.release()\n",
    "                    print('video_tot_frames: ' +  str(video_tot_frames))\n",
    "                    print('Video frames per second: ' + str(video_frame_rate))\n",
    "        \n",
    "        \n",
    "                    ## ---------- Cutting video Using ffmpeg \n",
    "                    # Converting the LSL frames to the video time format to find start_cut and end_cut for the video\n",
    "                    start_cut_time = frame_to_time(LSL_begin_frame, video_frame_rate)\n",
    "                    end_cut_time = frame_to_time(LSL_end_frame, video_frame_rate)\n",
    "        \n",
    "                    print('Now cutting the video...')\n",
    "        \n",
    "                    # Determine the file extension and codec\n",
    "                    file_extension = os.path.splitext(video)[1].lower()\n",
    "                    codec = extension_to_codec.get(file_extension, 'libx264')  # Default to libx264 if not found\n",
    "        \n",
    "                    # Construct output file path with the same extension\n",
    "                    output_filename = f'cut_{os.path.splitext(video)[0]}{file_extension}'\n",
    "                    output_filepath = os.path.join(output_video_folder, output_filename)\n",
    "        \n",
    "                    # Use ffmpeg to cut the video\n",
    "                    ffmpeg_command = [\n",
    "                        'ffmpeg',\n",
    "                        '-y',                  # Add -y flag to overwrite any existing files with the same name\n",
    "                        '-i', video_filepath,\n",
    "                        '-ss', start_cut_time,  # start time\n",
    "                        '-to', end_cut_time,    # end time\n",
    "                        '-c', 'copy',           # copy codec (no re-encoding)\n",
    "                        output_filepath]\n",
    "                    \n",
    "        \n",
    "                    # Execute the command\n",
    "                    subprocess.run(ffmpeg_command, check=True)\n",
    "        \n",
    "                    print(f'Video saved as {output_filepath}')\n",
    "            \n",
    "\n",
    "print(\"Done with cutting all videos! You can now look into your folder: \" + output_video_folder)\n",
    "\n",
    "\n",
    "\n",
    "            ## -------------- Usign moviepy does not work!! Why??\n",
    "            \n",
    "            # # Extract video frame rate using moviepy\n",
    "            # video_clip = VideoFileClip(video_filepath)\n",
    "            # video_frame_rate = video_clip.fps\n",
    "            # print('Video frames per second: ' + str(video_frame_rate))\n",
    "            \n",
    "\n",
    "            # # Converting the LSL frames to the video time format to find start_cut and end_cut for the video \n",
    "            # start_cut_time = LSL_begin_frame / video_frame_rate\n",
    "            # end_cut_time   = LSL_end_frame / video_frame_rate\n",
    "\n",
    "            # print('Now cutting the video...') \n",
    "\n",
    "            # # Determine the file extension and codec\n",
    "            # file_extension = os.path.splitext(video)[1].lower()\n",
    "            # codec = extension_to_codec.get(file_extension)\n",
    "\n",
    "            # if codec is None:\n",
    "            #     print(f\"Unsupported file extension: {file_extension}. Skipping file.\")\n",
    "            #     continue\n",
    "\n",
    "            # # Cut and save the video using MoviePy\n",
    "            # cut_clip = video_clip.subclip(start_cut_time, end_cut_time)\n",
    "\n",
    "            # # Construct output file path with the same extension\n",
    "            # output_filename = f'cut_{os.path.splitext(video)[0]}{file_extension}'\n",
    "            # output_filepath = os.path.join(output_video_folder, output_filename)\n",
    "\n",
    "            # # Save the cut video with the determined codec in specified location\n",
    "            # cut_clip.write_videofile(output_filepath, codec=codec)\n",
    "\n",
    "            # print(f'Video saved as {output_filepath}')\n",
    "\n",
    "\n",
    "            # # -------------- This other way does not work either \n",
    "\n",
    "        #     # Translating the start and end time points to cut the video by multiplying the duration of each video frame by the \n",
    "        #     video_start_frametime_LSL =  np.round((1/int(frate)) * int(begin_frame), 3)\n",
    "        #     video_end_frametime_LSL = np.round((1/int(frate)) * int(end_frame), 3)\n",
    "\n",
    "\n",
    "        #     video_cut = VideoFileClip(video_filepath).cutout(video_start_frametime, video_end_frametime)\n",
    "        #     video_cut.write_videofile(videofolder + \"test.mp4\")\n",
    "\n",
    "\n",
    "\n",
    "        ## ---------------- This way takes a very long time \n",
    "\n",
    "        #   # Start Writing the Video \n",
    "            # fourcc = cv2.VideoWriter_fourcc(*'M', 'J', 'P', 'G')  # For different video formats you could use e.g., *'XVID'\n",
    "            # vidloc = os.path.join(videofolder, f'{video.split(\".\")[0]}_cut.mp4')  # Location to save the new video\n",
    "            # out = cv2.VideoWriter(vidloc, fourcc, fps=originalfps, frameSize=(int(frameWidth), int(frameHeight)))\n",
    "            # frame_count = 0\n",
    "\n",
    "            # print('Looping over the frames')\n",
    "        \n",
    "            # while capture.isOpened():\n",
    "            #     # Read the next frame\n",
    "            #     ret, frame = capture.read()\n",
    "            #     if ret:\n",
    "            #         # Increment the frame count\n",
    "            #         frame_count += 1\n",
    "            #         print(frame_count)\n",
    "            #         if frame_count in frames:\n",
    "            #             out.write(frame)\n",
    "            #         if frame_count > end_frame:\n",
    "            #             break\n",
    "\n",
    "            # capture.release()\n",
    "            # out.release()\n",
    "            # print(f'Video saved to {vidloc}')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd35add-78d9-40b2-b773-632b8732e7ba",
   "metadata": {},
   "source": [
    "# 5. Concatenate (cut) Videos with Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb1dc3-f58a-457b-9895-ef414b25150f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aab742c-a79d-4233-89a2-357972edb3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Navigating in the input audio folder: \n",
      "T1_experiment_AudioEvents.csv\n",
      "T1_experiment_Mic_P1.csv\n",
      "T1_experiment_Mic_P1.wav\n",
      "T1_experiment_Mic_P1_denoised.wav\n",
      "Now processing audio T1_experiment_Mic_P1_denoised.wav\n",
      "Loading the audio \n",
      "F:\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\data_processed\\T1_experiment_Mic_P1_denoised.wav\n",
      "Navigating in the input video folder: \n",
      "cut_P1.avi\n",
      "Now processing video file cut_P1.avi\n",
      "Loading the video \n",
      "F:\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\video_cut\\cut_P1.avi\n",
      "F:\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\audiovideo_sync\\P1_audiovideo_sync.avi\n",
      "Combining Audio and Video\n",
      "\n",
      "Video saved as F:\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\audiovideo_sync\\P1_audiovideo_sync.avi\n",
      "cut_P2.avi\n",
      "T1_experiment_Mic_P2.csv\n",
      "T1_experiment_Mic_P2.wav\n",
      "T1_experiment_Mic_P2_denoised.wav\n",
      "T1_experiment_PLUX_P1.csv\n",
      "T1_experiment_PLUX_P2.csv\n",
      "T1_experiment_Video_P1.csv\n",
      "T1_experiment_Video_P2.csv\n",
      "Navigating in the input audio folder: \n",
      "T1_experiment_AudioEvents.csv\n",
      "T1_experiment_Mic_P1.csv\n",
      "T1_experiment_Mic_P1.wav\n",
      "T1_experiment_Mic_P1_denoised.wav\n",
      "T1_experiment_Mic_P2.csv\n",
      "T1_experiment_Mic_P2.wav\n",
      "T1_experiment_Mic_P2_denoised.wav\n",
      "Now processing audio T1_experiment_Mic_P2_denoised.wav\n",
      "Loading the audio \n",
      "F:\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\data_processed\\T1_experiment_Mic_P2_denoised.wav\n",
      "Navigating in the input video folder: \n",
      "cut_P1.avi\n",
      "cut_P2.avi\n",
      "Now processing video file cut_P2.avi\n",
      "Loading the video \n",
      "F:\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\video_cut\\cut_P2.avi\n",
      "F:\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\audiovideo_sync\\P2_audiovideo_sync.avi\n",
      "Combining Audio and Video\n",
      "\n",
      "Video saved as F:\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\audiovideo_sync\\P2_audiovideo_sync.avi\n",
      "T1_experiment_PLUX_P1.csv\n",
      "T1_experiment_PLUX_P2.csv\n",
      "T1_experiment_Video_P1.csv\n",
      "T1_experiment_Video_P2.csv\n",
      "Done, you can now look into the folder. ./audiovideo_sync/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_audio_folder = './data_processed/' \n",
    "input_video_folder = './video_cut/'\n",
    "output_audiovideo = './audiovideo_sync/'\n",
    "\n",
    "# List of participant file pairs \n",
    "participants_files = [\n",
    "    ('Mic_P1_denoised', 'P1'),\n",
    "    ('Mic_P2_denoised', 'P2')\n",
    "]\n",
    "\n",
    "\n",
    "# loop over Audio files\n",
    "for participant_audio, participant_video in participants_files:\n",
    "    \n",
    "    print('Navigating in the input audio folder: ')\n",
    "    \n",
    "    for audio in os.listdir(os.path.abspath(input_audio_folder)):\n",
    "        print(audio)\n",
    "        \n",
    "        if participant_audio in audio:    #Participant Check \n",
    "            print('Now processing audio '+ audio)\n",
    "        \n",
    "            # Creating audio path \n",
    "            print('Loading the audio ')\n",
    "            audio_path = os.path.join(os.path.abspath(input_audio_folder), audio)\n",
    "            print(audio_path)\n",
    "        \n",
    "        \n",
    "            # Loop over video files to select relevant video \n",
    "            print('Navigating in the input video folder: ')\n",
    "            for video in os.listdir(os.path.abspath(input_video_folder)):\n",
    "                print(video) \n",
    "                \n",
    "                if participant_video in video:\n",
    "                    print('Now processing video file ' + video) \n",
    "        \n",
    "                    # Creating video path \n",
    "                    print('Loading the video ')\n",
    "                    video_path = os.path.join(os.path.abspath(input_video_folder), video)\n",
    "                    print(video_path)\n",
    "        \n",
    "        \n",
    "                    # --- Combining Audio and Video using ffmpeg \n",
    "                    output_path = os.path.abspath(os.path.join(output_audiovideo + str(participant_video) + '_audiovideo_sync.avi'))\n",
    "                    print(output_path)\n",
    "        \n",
    "                    # Construct the ffmpeg command\n",
    "                    ffmpeg_command = [\n",
    "                        'ffmpeg',\n",
    "                        '-y',             #override\n",
    "                        '-i', video_path,\n",
    "                        '-i', audio_path,\n",
    "                        '-c:v', 'copy',  # Copy the video codec\n",
    "                        '-c:a', 'aac',   # Encode audio to AAC\n",
    "                        '-strict', 'experimental',\n",
    "                        output_path\n",
    "                                    ]     \n",
    "                    \n",
    "                    # Run the ffmpeg command\n",
    "                    print('Combining Audio and Video')\n",
    "                    try:\n",
    "                        result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n",
    "                        print(result.stdout)\n",
    "                        print(f'Video saved as {output_path}')\n",
    "                    except subprocess.CalledProcessError as e:\n",
    "                        print(f\"Error combining audio and video {video_path} and {audio_path}: {e.stderr}\")\n",
    "                    \n",
    "print('Done, you can now look into the folder. ' + output_audiovideo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003a551-6ecd-4baf-8c29-9a96d77761f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "audio_path = os.path.join(os.path.abspath(input_audio_folder), file)\n",
    "                print(audio_path)\n",
    "        \n",
    "                \n",
    "                if not os.path.exists(audio_path):\n",
    "                    print(f\"Audio file not found: {audio_path}\" + '/n please check your foler to make sure the audio is there')\n",
    "                    \n",
    "                # input the video with ffmpg\n",
    "                input_audio = ffmpeg.input(audio_path)\n",
    "                print(input_audio)\n",
    "        \n",
    "                0/0\n",
    "\n",
    "#load in the video with matchich trialIndex and SessionIndex\n",
    "        print('Loading the video')\n",
    "        video_path = os.path.join(trialfolder, f\"{sessionIndex}_trial_{trialIndex}_video_raw.mp4\")\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Video file not found: {video_path}\")\n",
    "        input_video = ffmpeg.input(video_path)\n",
    "        print(input_video)\n",
    "        # get information about the vid_frate\n",
    "        #streamloc = trialfolder+sessionIndex+'_trial_'+ str(trialIndex) +'_'+'MyWebcamFrameStream_nominal_srate500'+'.csv'\n",
    "        #print(streamloc)\n",
    "        #streamdata = pd.read_csv(streamloc)\n",
    "        # get the begin and end frame\n",
    "        #begfr = streamdata['1'].min().astype(int)\n",
    "        #print(begfr)\n",
    "        #endfr = streamdata['1'].max().astype(int)\n",
    "        #print(endfr)\n",
    "        #totfr = endfr-begfr\n",
    "        #print(totfr)\n",
    "        #begin = streamdata['0'].min()\n",
    "        #print(begin)\n",
    "        #end = streamdata['0'].max()\n",
    "        #print(end)\n",
    "        # what is the original fps of the video\n",
    "        #origfps = round((totfr/(end-begin)),3)\n",
    "        # tranform it into real number\n",
    "        #origfps = float(origfps)\n",
    "        \n",
    "        #combine the audio and video\n",
    "        print('Combining audio and video')\n",
    "        output_path = os.path.abspath(os.path.join(trialfolder, f\"{sessionIndex}_trial_{trialIndex}_final.mp4\"))\n",
    "        ffmpeg.concat(input_video, input_audio, v=1, a=1).output(output_path).run(overwrite_output=True)\n",
    "        \n",
    "        #save it\n",
    "        print('Saving the video')\n",
    "        #print(origfps)\n",
    "        #print(type(origfps))\n",
    "        #print(trialIndex)\n",
    "        #print(sessionIndex)\n",
    "        # save the final video with audio\n",
    "        #final.write_videofile(trialfolder+sessionIndex+'_trial_'+ str(trialIndex) +'_'+'video_audio'+'.mp4', fps=origfps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705c5c7-5143-4185-ae4b-aaf1ebcb42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavloc = os.path.join(os.path.abspath('./data_processed/')\n",
    "\n",
    "if not os.path.exists(wavloc):\n",
    "    print(f\"Directory not found: {wavloc}\")\n",
    "\n",
    "\n",
    "# loop over Audio files\n",
    "for file in os.listdir(wavloc):\n",
    "    print(file)\n",
    "    if 'Mic_nominal_srate16000_denoised' in file:\n",
    "        print('Now processing file '+file)\n",
    "        sessionIndex = file.split('_')[0]   # this is session number\n",
    "        trialIndex = file.split('_')[2] # this is trial number\n",
    "        #load in the audio\n",
    "        print('Loading the audio')\n",
    "        audio_path = os.path.join(wavloc, file)\n",
    "        if not os.path.exists(audio_path):\n",
    "            print(f\"Audio file not found: {audio_path}\")\n",
    "        # input the video with ffmpg\n",
    "        input_audio = ffmpeg.input(audio_path)\n",
    "        print(input_audio)\n",
    "        #load in the video with matchich trialIndex and SessionIndex\n",
    "        print('Loading the video')\n",
    "        video_path = os.path.join(trialfolder, f\"{sessionIndex}_trial_{trialIndex}_video_raw.mp4\")\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Video file not found: {video_path}\")\n",
    "        input_video = ffmpeg.input(video_path)\n",
    "        print(input_video)\n",
    "\n",
    "\n",
    "          #combine the audio and video\n",
    "        print('Combining audio and video')\n",
    "        output_path = os.path.abspath(os.path.join(trialfolder, f\"{sessionIndex}_trial_{trialIndex}_final.mp4\"))\n",
    "        ffmpeg.concat(input_video, input_audio, v=1, a=1).output(output_path).run(overwrite_output=True)\n",
    "\n",
    "\n",
    "        #save it\n",
    "        print('Saving the video')\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393caa11-0dd9-4a2d-9467-825bbdbd6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.abspath(videofolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad653e5-3395-4464-afc7-eb9d773050f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wavloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80369bc7-4efd-4f37-afc2-d9b1da70e1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
