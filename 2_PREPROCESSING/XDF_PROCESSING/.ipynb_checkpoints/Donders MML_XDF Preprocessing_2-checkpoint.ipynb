{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f4587d",
   "metadata": {},
   "source": [
    "# Donders MML: XDF processing\n",
    "The script processes all data files sotred in an XDF format. \n",
    "Steps: \n",
    "1. Import libraries necessary for processing audio, video and data files \n",
    "    a. See requirements.txt to conda install all the necessary packages. \n",
    "    \n",
    "2. Identify XDF files within a specified directory or its subdirectories.\n",
    "\n",
    "3. ... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceca857",
   "metadata": {},
   "source": [
    "## 0. Import all the necessary packages to work with XDF, Audio and Video files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f88e2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything was imported succesfully\n"
     ]
    }
   ],
   "source": [
    "import os  # Importing the os module which provides functions for interacting with the operating system\n",
    "import pyxdf  # Importing pyxdf, a Python library for reading XDF files\n",
    "import glob  # Importing the glob module which helps in finding files/directories with specific patterns\n",
    "import pandas as pd  # Importing pandas library (abbreviated as pd), which is used for data manipulation and analysis\n",
    "import numpy as np  # Importing numpy library (abbreviated as np), which is used for numerical computations\n",
    "import wave  # Importing wave module for reading and writing WAV files (usually audio files) \n",
    "import struct  # Importing struct module which provides functions to convert between Python values and C structs\n",
    "import math  # Importing math module which provides mathematical functions\n",
    "import random  # Importing random module for generating random numbers\n",
    "from scipy.io import wavfile  # Importing wavfile module from scipy.io (a library built on numpy), for reading and writing WAV files\n",
    "import noisereduce as nr  # Importing noisereduce module for noise reduction in audio signals\n",
    "import json  # Importing json module for working with JSON data\n",
    "import cv2  # Importing OpenCV library for computer vision tasks\n",
    "from moviepy.editor import (  # Importing various classes and functions from moviepy.editor module\n",
    "                            VideoFileClip,  # Class for working with video files\n",
    "                            AudioFileClip,  # Class for working with audio files\n",
    "                            CompositeAudioClip)  # Class for composing audio clip\n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip # video  clipping fucntion \n",
    "from moviepy.video.io.VideoFileClip import VideoFileClip # alternative video clipping function\n",
    "import matplotlib.pyplot as plt  # Importing pyplot library to create figures and plot data \n",
    "from matplotlib.widgets import Slider  # \n",
    "import tkinter # GUI toolkit to open and save files\n",
    "from tkinter import filedialog # GUI toolkit to open and save files\n",
    "import subprocess \n",
    "#import ffmpeg     # Question about this\n",
    "# import xdf\n",
    "\n",
    "print(\"Everything was imported succesfully\") #as terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb71e5f-010b-44c3-8ce2-850514916a35",
   "metadata": {},
   "source": [
    "## 1. Define the Relevant Paths, Variables & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb3769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input folder = C:\\Users\\ahmar\\OneDrive\\Documents\\GitHub\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\data_raw\n",
      "Output folder = C:\\Users\\ahmar\\OneDrive\\Documents\\GitHub\\Mobile-Multimodal-Lab\\2_PREPROCESSING\\XDF_PROCESSING\\data_processed\n",
      "Function \"to_audio\" created sucesfully\n",
      "Function \"frame_to_time\" created sucesfully\n",
      "Function \"save_xdf\" created sucesfully\n",
      "Function \"get_events\" created sucesfully\n"
     ]
    }
   ],
   "source": [
    "# ------------ PATHS -----------------------------------------------------\n",
    "input_folder = './data_raw/'  # input folder with the raw XDF files (relative path) \n",
    "output_folder = './data_processed/'  # output folder where the raw extracted data will be saved (relative path) \n",
    "\n",
    "print(\"Input folder =\", os.path.abspath(input_folder))\n",
    "print(\"Output folder =\", os.path.abspath(output_folder))\n",
    "\n",
    "\n",
    "# ------------ VARIABLES ----------------------------------------------\n",
    "noise_reducelevel = 1.5  #This can be changed accordingly \n",
    "\n",
    "\n",
    "# Dictionary to map file extensions to codecs\n",
    "extension_to_codec = {\n",
    "    '.mp4': 'libx264',\n",
    "    '.avi': 'libxvid',\n",
    "    '.mov': 'libx264',\n",
    "    '.mkv': 'libx264',\n",
    "    '.flv': 'flv',\n",
    "    # Add more mappings as needed\n",
    "                    }\n",
    "\n",
    "\n",
    "# IF NEEDED: Create a dictionary mapping from old stream names to new stream names (# Edit and add more mappings as needed.) \n",
    "     # (This dictionary mapping is based both of the stream_names and stream_types because in our case we have 2 streams with the same name (but different types)) \n",
    "rename_dict = {\n",
    "    ('MyWebcamFrameStream_2', 'frameNR'): 'Video_P2',\n",
    "    ('MyWebcamFrameStream_1', 'frameNR'): 'Video_P1',\n",
    "    ('Mic', 'voice'): 'Mic_P1',\n",
    "    ('Mic_004', 'voice'): 'Mic_P2',\n",
    "    ('OpenSignals', '00:07:80:8C:06:6A'): 'PLUX_P2',\n",
    "    ('OpenSignals', '00:07:80:D8:A8:81'): 'PLUX_P1'\n",
    "}\n",
    "\n",
    "\n",
    "# -------------FUNCTIONS------------------------------------------------------------------------------------\n",
    "# AUDIO: Creating a function named \"to_audio\" tht writes audio data (input) and transforms into a WAV file (output). \n",
    "def to_audio(fileloc, timeseries_name, samplerate = 16000, channels = 1):   \n",
    "    \"\"\"\n",
    "    This function - named \"to_audio\" - writes audio data to a WAV file.\n",
    "    It accepts the following parameters:\n",
    "    - fileloc (str): Location to save the audio file.\n",
    "    - timeseriestype (list): Audio data to be written into the file.\n",
    "    - samplerate (int, optional): Sampling rate of the audio data. Defaults to 16000.\n",
    "    - channels (int, optional): Number of audio channels (mono or stereo). Defaults to 1 (mono)\n",
    "    \"\"\"\n",
    "    if 'Mic' in timeseries_name:  #Condition check that the timeseriestype belongs to the microphone.\n",
    "            \n",
    "        obj = wave.open(fileloc,'w')        # Opens audio file using the wave.open() function write mode ('w'). Assigns data it to the variable obj.\n",
    "        obj.setnchannels(channels)          # Sets the number of channels in the audio file using obj.setnchannels(channels). Deafault 1 channel (mono).\n",
    "        obj.setsampwidth(2)                 # Sets the sample width in bytes using obj.setsampwidth(2). The value '2' indicates 16-bit audio.\n",
    "        obj.setframerate(float(samplerate)) # sets the frame rate of the audio file using obj.setframerate(float(samplerate)), where samplerate is provided as a parameter.\n",
    "            \n",
    "        for i in timeseries:                      # Loop to iterate over each time-point in the temeseries stream\n",
    "            data = struct.pack('<h', int(i[0]))   # Converts the first value of the timeseries to an integer and packs it into a binary string (struck.pack()) according to the '<h' fromat (i.e., short integer (16 bits) in little-endian byte order)   \n",
    "            obj.writeframesraw( data )            # Writes the packed binary data into an audio file using the wave function writeframesraw() from the wave library \n",
    "        obj.close()                               # Closes the audio file \n",
    "\n",
    "print(\"Function \\\"to_audio\\\" created sucesfully\") \n",
    "\n",
    "\n",
    "# VIDEO: Creating a function named frame_to_time to convert frame number to time format \n",
    "def frame_to_time(frame, fps):\n",
    "    \"\"\"\n",
    "    frame_to_time converts a given frame number to a time format (HH:MM:SS.SS) based on the frames per second (fps).\n",
    "    Arguments:\n",
    "        frame (int): The frame number to be converted.\n",
    "        fps (float): The frames per second of the video.\n",
    "    Returns:\n",
    "        str: The time format as a string in the format \"HH:MM:SS.SS\".\n",
    "    \"\"\"\n",
    "    seconds = frame / fps\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = seconds % 60\n",
    "    return f\"{hours:02}:{minutes:02}:{seconds:.2f}\"\n",
    "\n",
    "print(\"Function \\\"frame_to_time\\\" created sucesfully\") \n",
    "\n",
    "\n",
    "# XDF Save \n",
    "def save_xdf(filename, streams, header):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pyxdf.write_header(f, header)\n",
    "        for stream in streams:\n",
    "            pyxdf.write_stream_header(f, stream['info'])\n",
    "            pyxdf.write_stream_data(f, stream['time_stamps'], stream['time_series'])\n",
    "\n",
    "print(\"Function \\\"save_xdf\\\" created sucesfully\") \n",
    "\n",
    "\n",
    "# Function to extract specified events (with correspodning LSL times) from XDF stream (useful for plotting)\n",
    "def get_events(stream, event_names):\n",
    "    \"\"\"\n",
    "    Extracts events and corresponding LSL times from the given stream that match any of the event_names.\n",
    "\n",
    "    Parameters:\n",
    "    stream (dict): The stream containing time stamps and event data.\n",
    "    event_names (list of str): List of event name substrings to look for in the events.\n",
    "\n",
    "    Returns:\n",
    "    np.array: An array where each row contains a timestamp and the full event name.\n",
    "    \"\"\"\n",
    "    events = []  # Initialize an empty list to store matching events\n",
    "\n",
    "    # Check if the stream type is \"Markers\"\n",
    "    if stream['info']['type'][0] != \"Markers\":\n",
    "        raise ValueError(f\"ERROR: The stream provided ({stream['info']['name'][0]}) is not a Marker stream\")\n",
    "\n",
    "    # Iterate over the time stamps and corresponding events in the stream\n",
    "    for timestamp, event in zip(stream['time_stamps'], stream['time_series']):\n",
    "        # Check if any of the specified event names are in the current event\n",
    "        for name in event_names:\n",
    "            if name in event[0]:\n",
    "                # If a match is found, append the timestamp and full event name to the list\n",
    "                events.append([timestamp, event[0]])\n",
    "\n",
    "    # Convert the list of events to a NumPy array and return it\n",
    "    return np.array(events)\n",
    "\n",
    "print(\"Function \\\"get_events\\\" created sucesfully\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac3587c",
   "metadata": {},
   "source": [
    "## 2. Identifying XDF files in Input Folder or any Subfolder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd9537",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf_files = []  # Initialize an empty list to store paths of XDF files\n",
    "\n",
    "# Traverse through the directory and its subdirectories to find XDF files\n",
    "for root, dirs, files in os.walk(input_folder):  # 1st loop iterating over the results returned by os.walk().\n",
    "    \n",
    "    for file in files:                                    # 2nd loop iterating through each file in the current directory\n",
    "        \n",
    "        if file.endswith(\".xdf\"):                         # checking if the file has and XDF extension \n",
    "            \n",
    "             xdf_files.append(os.path.join(root, file))   # if the file is an XDF file, append its full path to the xdf_files list\n",
    "            \n",
    "print('We have idenified the following XDF files: ' + str(xdf_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd34ee1-0a3c-4fff-aba6-2213040dc729",
   "metadata": {},
   "source": [
    "## 2a. Alternatively, the user can select their own XDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4f83bf-1184-46c1-941f-accfe5dfbd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected the following XDF files: ['C:/Users/ahmar/OneDrive/Documents/GitHub/Mobile-Multimodal-Lab/2_PREPROCESSING/XDF_PROCESSING/data_raw/T1_experiment.xdf']\n"
     ]
    }
   ],
   "source": [
    "root = tkinter.Tk()\n",
    "root.attributes('-topmost',True)\n",
    "root.iconify()\n",
    "\n",
    "xdf_files = filedialog.askopenfilename(title=\"Select an XDF file\", filetypes=[(\"XDF Files\", \"*.xdf\")], multiple = 'True')\n",
    "\n",
    "root.destroy()\n",
    "\n",
    "# Convert the tuple returned by askopenfilenames() to a list\n",
    "xdf_files = list(xdf_files)\n",
    "\n",
    "print('You have selected the following XDF files: ' + str(xdf_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb8eef-e6fa-4e4d-bede-091210897d23",
   "metadata": {},
   "source": [
    "### X. Renaming XDF Streams (Edit as needed & Skip if not needed!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678cd4dd-742e-41b6-a8ce-304b87c76b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section we remane the XDF streams within each XDF file and save the new files with the renamed streams in a different directory. Steps: \n",
    "# 1. Create a dictionary to map old names to new names.\n",
    "# 2. Iterate over each stream in the XDF file.\n",
    "# 3. Check if the stream name exists in the dictionary.\n",
    "# 4. If it exists, replace it with the new name.\n",
    "# 5. Saves the renamed.xdf in the specified output_folder \n",
    "\n",
    "output_folder = './data_raw_renamed/'  # input folder with the raw XDF files (relative path) \n",
    "\n",
    "\n",
    "# Create a dictionary mapping from old stream names to new stream names (# Edit and add more mappings as needed.) \n",
    "     # (This dictionary mapping is based both of the stream_names and stream_types because in our case we have 2 streams with the same name (but different types)) \n",
    "\n",
    "rename_dict = {\n",
    "    ('MyWebcamFrameStream_2', 'frameNR'): 'Video_P2',\n",
    "    ('MyWebcamFrameStream_1', 'frameNR'): 'Video_P1',\n",
    "    ('Mic', 'voice'): 'Mic_P1',\n",
    "    ('Mic_004', 'voice'): 'Mic_P2',\n",
    "    ('OpenSignals', '00:07:80:8C:06:6A'): 'PLUX_P2',\n",
    "    ('OpenSignals', '00:07:80:D8:A8:81'): 'PLUX_P1'\n",
    "}\n",
    "\n",
    "# Loading the XDF files: \n",
    "for xdf_file in xdf_files: \n",
    "    print('Loading XDF file: ' + xdf_file) \n",
    "\n",
    "    streams, header = pyxdf.load_xdf(xdf_file)  # Load streams and header information from each XDF file using the load_xdf function from the pyxdf library\n",
    "    fnam = os.path.basename(xdf_file)[:-4]  # Extract the file name from the path and assign it to fnam, while removing the '.xdf' extension\n",
    "\n",
    "\n",
    "    # Extracting \"Name\" and \"Type\" from the stream \"info\" \n",
    "    for stream in streams: \n",
    "        stream_name = stream['info']['name'][0] # Extract the name of each stream\n",
    "        stream_type = stream['info']['type'][0] # Extract the type of each stream\n",
    "\n",
    "        #Checking if the stream name and type against the dictonary. If it already exists, we replace it with the new name. \n",
    "        if (stream_name, stream_type) in rename_dict: \n",
    "            new_name = rename_dict[(stream_name, stream_type)]\n",
    "\n",
    "            print(f'Renaming stream {stream_name} ({stream_type}) to {new_name}')\n",
    "            stream['info']['name'][0] = new_name  # Rename the stream\n",
    "\n",
    "\n",
    "            ## !!! HAVING PROBLEMS WITH ACTUALLY SAVING THE XDF FILES. NO SAVE FUNCTION PROVIDED BY THE XDFPY LIBRARY \n",
    "    # # Saving the renamed.xdf in the specified output_folder \n",
    "    # output_file_path = os.path.join(output_folder, fnam + '_renamed.xdf')\n",
    "    # print(\"Saving the renamed xdf file using the save_xdf function\")\n",
    "    # save_xdf(output_file_path, streams, header)\n",
    "    \n",
    "    \n",
    "    # # pyxdf.save_xdf(output_file_path, streams, header)  ## AttributeError: module 'pyxdf' has no attribute 'save_xdf'\n",
    "    \n",
    "    \n",
    "    # print(f'Saved renamed XDF file to {output_file_path}')\n",
    "\n",
    "print(\"Done renaming streams in all XDF files!\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b9c679-7d1c-4c5b-8962-c5f1ea6d871c",
   "metadata": {},
   "source": [
    "# 3. (NEW) Main Loop that Extracts & RENAMES each data stream from each XDF and saves it as CVS or WAV files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6204b20-46bf-4c4d-9d9e-d55743d81982",
   "metadata": {},
   "source": [
    "Make a function out of the renaming old to new streams in XDF \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df87847-8651-4e9e-a681-a48534cdd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = './data_processed_2/'  # output_folder for the CVS and WAV files \n",
    "\n",
    "\n",
    "for xdf_file in xdf_files:               # Iterate over each path in the list \"xdf_files\". \n",
    "\n",
    "    print('loading xdf file: ' + xdf_file )\n",
    "\n",
    "    streams, header = pyxdf.load_xdf(xdf_file)    # Loading steams and header information from each XDF file usign the load_xdf function from the pyxdf library. \n",
    "    fnam = os.path.basename(xdf_file)[:-4]        # Extract the file name from the path and assings it to fnam, whilst removing the '.xdf' extension (i.e., the last 4 characters in the string)\n",
    "       \n",
    "    stream_count = {}   # Dictionary to keep track of multiple streams with the same name (this can happen in cases of multiple people) \n",
    "\n",
    "    # Navigating through each stream and extracting the relevant information (e.g., name, sample rate, data, time, etc.) \n",
    "    for stream in streams:                        # Iterate over each steam in the loaded steam for each XDF file .\n",
    "        timeseries_name = stream['info']['name'][0]                    # Extracts name of each steams (dictionary structure) and assigns it to timeseries_name (e.g., Mic). \n",
    "        timeseries_type = stream['info']['type'][0]\n",
    "\n",
    "        # Replacing old stream name with new one if it already exists in the raname_dict. \n",
    "        if (timeseries_name, timeseries_type) in rename_dict: \n",
    "            new_name = rename_dict[(timeseries_name, timeseries_type)]\n",
    "\n",
    "            print(f'Renaming stream {timeseries_name} ({timeseries_type}) to {new_name}')\n",
    "            stream['info']['name'][0] = new_name  # Rename the stream in the XDF file \n",
    "            \n",
    "            timeseries_name = stream['info']['name'][0]           #Overrinding old name with new name.  \n",
    "        \n",
    "        timevec = stream['time_stamps']                                # Extract the time_stamps (i.e.,LSL TIMESTAMPS) from the \"stream\" dictionary and assigns it to the variable timevec\n",
    "        timeseries = stream['time_series']                              # Extract the time_series (i.e., DATA) from the \"stream\" dictionary and \n",
    "        samplerate = round(float(stream['info']['nominal_srate'][0]))    # Extracts the rounded sampling rate (nominal_srate) and assings it to samplerate \n",
    "        channelcount = int(stream['info']['channel_count'][0])               # Extracts the number of channel for each steams and assigns it to channelcount (as an integer)\n",
    "\n",
    "        # Extract channel labels\n",
    "        channel_labels = []\n",
    "        if channelcount > 1 and stream['info']['desc'] is not None:\n",
    "            try:\n",
    "                channels_info = stream['info']['desc'][0]['channels'][0]['channel']\n",
    "                channel_labels = [channel['label'][0] for channel in channels_info]\n",
    "            except (KeyError, IndexError):\n",
    "                # If there is any issue with extracting channel labels, create default labels\n",
    "                channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]\n",
    "        else:\n",
    "            # If channelcount is 1 and/or'desc' is None, create default labels\n",
    "            channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]\n",
    "       \n",
    "        \n",
    "        print('working on stream: ' + timeseries_name + '  with a channel count of: ' + str(channelcount) + ' labelled: ' + str(channel_labels) + ' and a sampling rate of ' + str(samplerate))        \n",
    "\n",
    "        # Saving each stream of the XDF file as a CSV (if it doesn't exist yet) \n",
    "        matrix_aux = np.vstack([np.transpose(timevec),np.transpose(timeseries)])   # Create matrix_aux by concatenating the transposed timevec and timeseries\n",
    "        matrix     = np.transpose(matrix_aux)                                      # Create new matrix by tranposing matrix_aux\n",
    "        column_names = [\"LSL_Time\"] + [f\"{timeseries_name}_{label}\" for label in channel_labels]  # Create column names for the matrix. The first column is named \"LSL_Time\" (i.e., timevec), The subsequent columns are named using the format {timeseries_name}_{label} for each channel label. \n",
    "        df_lab = pd.DataFrame(matrix, columns = column_names)                                     # Create a DataFrame df_lab with the combined data and the appropriate column names.\n",
    "       \n",
    "        # Saving \n",
    "        print('Saving: ' + fnam + '_' + timeseries_name) \n",
    "        df_lab.to_csv(output_folder + fnam + '_' + timeseries_name + '.csv',index=False)  \n",
    "      \n",
    "\n",
    "        if \"Mic\" in timeseries_name:  # Check if the data stream is from a microphone\n",
    "            wavloc = os.path.abspath(output_folder + fnam + '_' + timeseries_name  + '.wav')  # Define the location to save the initial audio file\n",
    "            to_audio(wavloc, timeseries_name)  # Convert the time series data to an audio file and save it at the defined location\n",
    "            rate, data = wavfile.read(wavloc)  # Load the audio data from the saved WAV file\n",
    "            reduced_noise = nr.reduce_noise(y=data, sr=rate, n_std_thresh_stationary=noise_reducelevel, stationary=True)    # Perform noise reduction based on the noise_reducelevel \n",
    "            wavloc2 = os.path.abspath(output_folder + fnam + '_' + timeseries_name + '_denoised.wav')  # Define the location to save the noise-reduced audio file\n",
    "            wavfile.write(wavloc2, rate, reduced_noise)  # Save the noise-reduced audio data as a new WAV file at the defined location\n",
    "\n",
    "print(\"Done with extracting all the streams! You can now look into your folder: \" + output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a32516",
   "metadata": {},
   "source": [
    "# 3. Main Loop that Extracts each data stream from each XDF file and saves as CVS or WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8f08c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_folder = './data_processed/'  # input folder with the raw XDF files (relative path) \n",
    "event_names = ['_StartParticipantSinging', '_EndParticipantSinging']\n",
    "\n",
    "\n",
    "for xdf_file in xdf_files:               # Iterate over each path in the list \"xdf_files\". \n",
    "\n",
    "    print('loading xdf file: ' + xdf_file )\n",
    "\n",
    "    streams, header = pyxdf.load_xdf(xdf_file)    # Loading steams and header information from each XDF file usign the load_xdf function from the pyxdf library. \n",
    "    fnam = os.path.basename(xdf_file)[:-4]        # Extract the file name from the path and assings it to fnam, whilst removing the '.xdf' extension (i.e., the last 4 characters in the string)\n",
    "       \n",
    "    stream_count = {}   # Dictionary to keep track of multiple streams with the same name (this can happen in cases of multiple people) \n",
    "\n",
    "    # Navigating through each stream and extracting the relevant information (e.g., name, sample rate, data, time, etc.) \n",
    "    for stream in streams:                        # Iterate over each steam in the loaded steam for each XDF file .\n",
    "        timeseries_name = stream['info']['name'][0]                    # Extracts name of each steams (dictionary structure) and assigns it to timeseriestype (e.g., Mic). \n",
    "        timevec = stream['time_stamps']                                # Extract the time_stamps (i.e.,LSL TIMESTAMPS) from the \"stream\" dictionary and assigns it to the variable timevec\n",
    "        timeseries = stream['time_series']                              # Extract the time_series (i.e., DATA) from the \"stream\" dictionary and \n",
    "        samplerate = round(float(stream['info']['nominal_srate'][0]))    # Extracts the rounded sampling rate (nominal_srate) and assings it to samplerate \n",
    "        channelcount = int(stream['info']['channel_count'][0])               # Extracts the number of channel for each steams and assigns it to channelcount (as an integer)\n",
    "\n",
    "        # Extract channel labels\n",
    "        channel_labels = []\n",
    "        if channelcount > 1 and stream['info']['desc'] is not None:\n",
    "            try:\n",
    "                channels_info = stream['info']['desc'][0]['channels'][0]['channel']\n",
    "                channel_labels = [channel['label'][0] for channel in channels_info]\n",
    "            except (KeyError, IndexError):\n",
    "                # If there is any issue with extracting channel labels, create default labels\n",
    "                channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]\n",
    "        else:\n",
    "            # If channelcount is 1 and/or'desc' is None, create default labels\n",
    "            channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]\n",
    "       \n",
    "        # Incrementing the count if the name of two (or more) streams are the same. \n",
    "        if timeseries_name in stream_count:\n",
    "            stream_count[timeseries_name] += 1\n",
    "        else:\n",
    "            stream_count[timeseries_name] = 1 \n",
    "        count = stream_count[timeseries_name]  # Get the current count for the stream type\n",
    "        \n",
    "        print('working on stream: ' + timeseries_name + '  with a channel count of: ' + str(channelcount) + ' labelled: ' + str(channel_labels) + ' and a sampling rate of ' + str(samplerate))        \n",
    "\n",
    "        # Saving each stream of the XDF file as a CSV (if it doesn't exist yet) \n",
    "        matrix_aux = np.vstack([np.transpose(timevec),np.transpose(timeseries)])   # Create matrix_aux by concatenating the transposed timevec and timeseries\n",
    "        matrix     = np.transpose(matrix_aux)                                      # Create new matrix by tranposing matrix_aux\n",
    "        column_names = [\"LSL_Time\"] + [f\"{timeseries_name}_{label}\" for label in channel_labels]  # Create column names for the matrix. The first column is named \"LSL_Time\" (i.e., timevec), The subsequent columns are named using the format {timeseries_name}_{label} for each channel label. \n",
    "        df_lab = pd.DataFrame(matrix, columns = column_names)                                     # Create a DataFrame df_lab with the combined data and the appropriate column names.\n",
    "        if count == 1: # Saving without adding count to the file name\n",
    "            df_lab.to_csv(output_folder + fnam + '_' + timeseries_name + '_nominal_srate' + str(samplerate)  + '.csv',index=False)  \n",
    "        else:         # Saving by adding count ot the file name (because of multiple streams with same name) \n",
    "            df_lab.to_csv(output_folder + fnam + '_' + timeseries_name + '_nominal_srate' + str(samplerate) + '_' + str(count) + '.csv',index=False)     #Saving the df_lab as CSV file named [fnam]_[timeseriestype]_[nomilar_srate#].cvs\n",
    "       \n",
    "\n",
    "        if \"Mic\" in timeseries_name:  # Check if the data stream is from a microphone\n",
    "            wavloc = os.path.abspath(output_folder + fnam + '_' + timeseries_name + '_nominal_srate' + str(samplerate) + '.wav')  # Define the location to save the initial audio file\n",
    "            to_audio(wavloc, timeseries_name)  # Convert the time series data to an audio file and save it at the defined location\n",
    "            rate, data = wavfile.read(wavloc)  # Load the audio data from the saved WAV file\n",
    "            reduced_noise = nr.reduce_noise(y=data, sr=rate, n_std_thresh_stationary=noise_reducelevel, stationary=True)    # Perform noise reduction based on the noise_reducelevel \n",
    "            wavloc2 = os.path.abspath(output_folder + fnam + '_' + timeseries_name + '_nominal_srate' + str(samplerate) + '_denoised.wav')  # Define the location to save the noise-reduced audio file\n",
    "            wavfile.write(wavloc2, rate, reduced_noise)  # Save the noise-reduced audio data as a new WAV file at the defined location\n",
    "\n",
    "print(\"Done with extracting all the streams! You can now look into your folder: \" + output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aab416-ccba-4bfd-9152-184b1918145b",
   "metadata": {},
   "source": [
    "## 4. Plotting Each XDF and Each Stream (Quality Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80c993-9b8b-4283-b7cf-76b073b33679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "event_names = ['_StartParticipantSinging', '_EndParticipantSinging']\n",
    "\n",
    "\n",
    "for xdf_file in xdf_files:               # Iterate over each path in the list \"xdf_files\". \n",
    "\n",
    "    print('loading xdf file: ' + xdf_file )\n",
    "\n",
    "    streams, header = pyxdf.load_xdf(xdf_file)    # Loading steams and header information from each XDF file usign the load_xdf function from the pyxdf library. \n",
    "    fnam = os.path.basename(xdf_file)[:-4]        # Extract the file name from the path and assings it to fnam, whilst removing the '.xdf' extension (i.e., the last 4 characters in the string)\n",
    "\n",
    "    # Navigating through each stream and extracting the relevant information (e.g., name, sample rate, data, time, etc.) \n",
    "    print('Navigating through each stream: ') \n",
    "    for stream in streams:                        # Iterate over each steam in the loaded steam for each XDF file .\n",
    "        #Extracting information from the Stream dictionary \n",
    "        timeseries_name = stream['info']['name'][0]             # Extracts name of each steams (dictionary structure) and assigns it to timeseries_name (e.g., Mic).\n",
    "        timeseries_type = stream['info']['type'][0]             # Extracts type of each steams (dictionary structure) and assigns it to timeseries_type (e.g., Markers). \n",
    "\n",
    "        # Replacing old stream name with new one if it already exists in the raname_dict. \n",
    "        if (timeseries_name, timeseries_type) in rename_dict: \n",
    "            new_name = rename_dict[(timeseries_name, timeseries_type)]\n",
    "\n",
    "            print(f'Renaming stream {timeseries_name} ({timeseries_type}) to {new_name}')\n",
    "            stream['info']['name'][0] = new_name  # Rename the stream in the XDF file \n",
    "            \n",
    "            timeseries_name = stream['info']['name'][0]           #Overrinding old name with new name.  \n",
    "            \n",
    "        #Extracting information from the Stream dictionary \n",
    "        timevec = stream['time_stamps']                                # Extract the time_stamps (i.e.,LSL TIMESTAMPS) from the \"stream\" dictionary and assigns it to the variable timevec\n",
    "        timeseries = np.array(stream['time_series'])                   # Extract the time_series (i.e., DATA) from the \"stream\" dictionary and \n",
    "        samplerate = round(float(stream['info']['nominal_srate'][0]))  # Extracts the rounded sampling rate (samplerate) and assings it to samplerate \n",
    "        channelcount = int(stream['info']['channel_count'][0])         # Extracts the number of channel for each steams and assigns it to channelcount (as an integer)\n",
    "\n",
    "        # Extract channel labels from the Stream dictionary \n",
    "        channel_labels = []\n",
    "        \n",
    "        if channelcount > 1 and stream['info']['desc'] is not None:\n",
    "            try:\n",
    "                channels_info = stream['info']['desc'][0]['channels'][0]['channel']\n",
    "                channel_labels = [channel['label'][0] for channel in channels_info]\n",
    "            except (KeyError, IndexError):\n",
    "                # If there is any issue with extracting channel labels, create default labels\n",
    "                channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]\n",
    "        else:\n",
    "            # If channelcount is 1 and/or'desc' is None, create default labels\n",
    "            channel_labels = [f\"Channel {i+1}\" for i in range(channelcount)]           \n",
    "\n",
    "\n",
    "        print('working on stream: ' + timeseries_name + '  with a channel count of: ' + str(channelcount) + ' labelled: ' + str(channel_labels) + '\\n and a sampling rate of ' + str(samplerate))        \n",
    "\n",
    "\n",
    "        # Extracting Relevant Events from Marker Steam that will used in the plotting \n",
    "        if timeseries_type == 'Markers':\n",
    "            audio_events_stream = get_events(stream, event_names)  #Using the get_events function to extracts events and corresponding LSL times from Marker stream\n",
    "\n",
    "            continue    # Skips plotting for Markers stream \n",
    "            \n",
    "     \n",
    "        \n",
    "        #--------------- PLOTTING -----------\n",
    "        timeseries = np.array(timeseries)   # Ensure timeseries is a NumPy array for plotting\n",
    "\n",
    "        # Plotting subplots in case of multiple streams \n",
    "        # PLOTTING \n",
    "        timeseries = np.array(timeseries)   # Ensure timeseries is a NumPy array\n",
    "\n",
    "        # Plotting subplots in case of multiple streams \n",
    "        if channelcount > 1:\n",
    "            fig = make_subplots(rows=channelcount, cols=1, shared_xaxes=True, vertical_spacing=0.01, subplot_titles=channel_labels)\n",
    "        \n",
    "            for i in range(channelcount):\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=timevec, \n",
    "                    y=timeseries[:, i],\n",
    "                    mode='lines',\n",
    "                    name=channel_labels[i]\n",
    "                ), row=i+1, col=1)\n",
    "        \n",
    "            # Update x-axis settings for all subplots\n",
    "            for i in range(channelcount):\n",
    "                fig.update_xaxes(\n",
    "                    rangeselector=dict(\n",
    "                        buttons=list([\n",
    "                            dict(count=1,\n",
    "                                 label=\"1m\",\n",
    "                                 step=\"minute\",\n",
    "                                 stepmode=\"backward\"),\n",
    "                            dict(count=10,\n",
    "                                 label=\"10m\",\n",
    "                                 step=\"minute\",\n",
    "                                 stepmode=\"backward\"),\n",
    "                            dict(step=\"all\")\n",
    "                        ])\n",
    "                    ),\n",
    "                    rangeslider=dict(\n",
    "                        visible=True\n",
    "                    ) if i == channelcount-1 else None,  # Apply range slider only to the last subplot\n",
    "                    type=\"linear\",\n",
    "                    row=i+1, col=1\n",
    "                )\n",
    "        \n",
    "            fig.update_layout(\n",
    "                title_text=fnam + '_' + timeseries_name + ' Streams',\n",
    "                height=200 * channelcount,\n",
    "                yaxis_title='Amplitude'\n",
    "            )\n",
    "        \n",
    "            fig.show()\n",
    "\n",
    "\n",
    "        else:\n",
    "            # Plotting single channel data stream\n",
    "            fig = go.Figure()\n",
    "            timeseries = np.array(timeseries)  # Ensure timeseries is a NumPy array\n",
    "\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=timevec,\n",
    "                y=timeseries[:, 0],\n",
    "                mode='lines',\n",
    "                name=channel_labels[0]\n",
    "            ))\n",
    "\n",
    "            fig.update_layout(\n",
    "                title_text=fnam + '_' + timeseries_name + ' Streams',\n",
    "                xaxis=dict(\n",
    "                    rangeselector=dict(\n",
    "                        buttons=list([\n",
    "                            dict(count=1,\n",
    "                                 label=\"1m\",\n",
    "                                 step=\"minute\",\n",
    "                                 stepmode=\"backward\"),\n",
    "                            dict(count=10,\n",
    "                                 label=\"10m\",\n",
    "                                 step=\"minute\",\n",
    "                                 stepmode=\"backward\"),\n",
    "                            dict(step=\"all\")\n",
    "                        ])\n",
    "                    ),\n",
    "                    rangeslider=dict(\n",
    "                        visible=True\n",
    "                    ),\n",
    "                    type=\"linear\"\n",
    "                ),\n",
    "                yaxis_title='Amplitude'\n",
    "            )\n",
    "\n",
    "            fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # Plotting Events (i.e., triggers) \n",
    "        # if stream['info']['channel_format'][0] == 'string':\n",
    "        #     plt.figure(figsize=(12, 6))\n",
    "        #     y_pos = np.arange(len(timevec))  # Create a y-position for each event to avoid overlap\n",
    "        #     plt.scatter(timevec, [1] * len(timevec), marker='o')\n",
    "        #     for i, event in enumerate(timeseries):\n",
    "        #         plt.text(timevec[i], 1.01, event[0], rotation=45, ha='right', va='bottom', fontsize=6)\n",
    "        #     plt.title(fnam + '_' + timeseries_type + ' Events')\n",
    "        #     plt.xlabel('Time')\n",
    "        #     plt.yticks([])\n",
    "        #     plt.grid(True)\n",
    "        #     plt.show()\n",
    "\n",
    "\n",
    "        #     else:\n",
    "        #     # Plotting data streams with Plotly subplots if multiple channels\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            # # Plotting data streams with subplots and sliders\n",
    "            # fig, axs = plt.subplots(channelcount, 1, figsize=(12, 6 * channelcount), sharex=True)\n",
    "            # timeseries = np.array(timeseries)\n",
    "            # if channelcount == 1:\n",
    "            #     axs = [axs]  # Ensure axs is always a list\n",
    "\n",
    "            # for i in range(channelcount):\n",
    "            #     axs[i].plot(timevec, timeseries[:, i], label=channel_labels[i])\n",
    "            #     axs[i].set_title(f'{channel_labels[i]}')\n",
    "            #     axs[i].set_ylabel('Amplitude')\n",
    "            #     axs[i].grid(True)\n",
    "            #     axs[i].legend()\n",
    "\n",
    "            # axs[-1].set_xlabel('Time')\n",
    "\n",
    "            # # Adding slider for each subplot\n",
    "            # sliders = []\n",
    "            # axcolor = 'lightgoldenrodyellow'\n",
    "            # for i in range(channelcount):\n",
    "            #     ax_slider = plt.axes([0.25, 0.02 + i * 0.04, 0.65, 0.03], facecolor=axcolor)\n",
    "            #     slider = Slider(ax_slider, 'Range', timevec[0], timevec[-1], valinit=timevec[-1])\n",
    "            #     sliders.append(slider)\n",
    "\n",
    "            #     def update(val, ax=axs[i], slider=slider):\n",
    "            #         pos = slider.val\n",
    "            #         ax.set_xlim(timevec[0], pos)\n",
    "            #         fig.canvas.draw_idle()\n",
    "\n",
    "            #     slider.on_changed(update)\n",
    "\n",
    "            # plt.tight_layout()\n",
    "            # plt.show()\n",
    "             \n",
    "        # else:\n",
    "        #         # Plotting data streams \n",
    "        #     plt.figure(figsize=(12, 6))  # Adjust the figure size as needed\n",
    "        #     timeseries = np.array(timeseries)\n",
    "        #     for i in range(channelcount):\n",
    "        #         plt.plot(timevec, timeseries[:, i], label=channel_labels[i])\n",
    "        #     plt.title(fnam + '_' + timeseries_type + ' Streams')\n",
    "        #     plt.xlabel('Time')\n",
    "        #     plt.ylabel('Amplitude')\n",
    "        #     plt.legend()\n",
    "        #     plt.grid(True)\n",
    "        #     plt.show()\n",
    "        ## -------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4807487c-cb0c-4b18-acb8-702f0a1e6b21",
   "metadata": {},
   "source": [
    "Add a plotting/quality check passage to see each stream and each channel \n",
    "\n",
    "For Opensignals, maybe add subpanels to change the y axis. \n",
    "    subplots with total height of bigger plot. \n",
    "\n",
    "    Envision box plotly (selecting, smoothing and deriving measures) --> Use the slider range as well \n",
    "\n",
    "Naming the files. \n",
    "    In the lab setup, we will publish the scripts that stream the data to Lab recorder. \n",
    "    Each stream should be named accordingly \n",
    "    For now, we can change the actual stream names in the xdf file manually by using pyXDF (the same names will be used). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49683b68-6380-4a4b-916c-717ee799f219",
   "metadata": {},
   "source": [
    "Creating saving xdf folders for each session. Name of files will be Session_X_P_X_streamname\n",
    "\n",
    "\n",
    "\n",
    "Downsampling the videos \n",
    "\n",
    "go into timevec (original fps is about 200 with LSL)\n",
    "indent every 1/5 and extract the timevec (LSL time) and timeseries data \n",
    "Put into a n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889186dc-4248-4fa3-9a18-3d61abfc6f10",
   "metadata": {},
   "source": [
    "## 4. Clipping videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fea48c-e33e-4f0a-988a-a13f06b25d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_folder = './video_raw/'    #this folder should only contain the videos you want to process. \n",
    "output_video_folder = './video_cut/'\n",
    "input_file_folder = './data_processed/'\n",
    "\n",
    "# List of participant file pairs       #--------------- SOULD WE DO THIS ANOTHER WAY? MAYBE SAVING THE VSC FILES WITH A CONSISTENT NAME? ---- \n",
    "participants_files = [\n",
    "    ('MyWebcamFrameStream_1', 'P1'),\n",
    "    ('MyWebcamFrameStream_2', 'P2')\n",
    "]\n",
    "\n",
    "\n",
    "# Loading the relevant CVS files (called here 'MyWebcamFrameStream_x') that contain the LSL_time stamps and correspnding video frames\n",
    "for participant_frame, participant_video in participants_files:\n",
    "    \n",
    "    # Loading the relevant CSV files for each participant\n",
    "    for file in os.listdir(os.path.abspath(input_file_folder)):\n",
    "        \n",
    "        if participant_frame in file:  # Check for the corresponding participant\n",
    "            \n",
    "            print(f'Processing {participant_frame} for {participant_video}: {file}')\n",
    "            \n",
    "            file_path = os.path.join(os.path.abspath(input_file_folder), file)\n",
    "            print(f'This is the file path: {file_path}')\n",
    "\n",
    "            # Loading the CSV file\n",
    "            file_data = pd.read_csv(file_path) # Reads the CSV file at the constructed path into a DataFrame called file_data        \n",
    "\n",
    "            # Extracting relevant information from this CSV file \n",
    "            LSL_begin_time = file_data.iloc[:,0].min()       # Extracts the minimum value from the first column in the file_data (i.e., the first LSL_timestamps). \n",
    "            LSL_begin_frame = int(file_data.iloc[:,1].min())  # Extracts the minimum value from the second column in the file_data (i.e., the first video frame)\n",
    "            LSL_end_time = file_data.iloc[:,0].max()          # Extracts the maximum value from the first column in the file_data (i.e., the last LSL_timestamps).\n",
    "            LSL_end_frame = int(file_data.iloc[:,1].max())    # Extracts the maximum value from the second column in the file_data (i.e., the last video frame).\n",
    "\n",
    "            # print(LSL_begin_time )\n",
    "            # print(LSL_begin_frame)\n",
    "            # print(LSL_end_time)\n",
    "            # print(LSL_end_frame)\n",
    "\n",
    "            LSL_tot_frames = LSL_end_frame - LSL_begin_frame    # Total number of frames from start to finish recording.\n",
    "            LSL_frames = range(LSL_begin_frame , LSL_end_frame)  # Sequence of all frames numbered from the start to the end. \n",
    "            'Add comment about Theoretical understanding of frame numbers and LSL fps streaming' \n",
    "            \n",
    "            LSL_fps = round((LSL_tot_frames / (LSL_end_time - LSL_begin_time)), 3)\n",
    "\n",
    "\n",
    "            new_range = (LSL_begin_time : 1/50 : LSL_end_time) \n",
    "            print(new_range) \n",
    "\n",
    "            framelist = []\n",
    "            for i in new_range: \n",
    "                index_time = which.min(file_data.iloc[:,0]%%i)\n",
    "                index_frame = file_data.iloc[index_time:1])\n",
    "                framelist.append(index_frame) \n",
    "                \n",
    "            print('LSL_tot_frames: ' + str(LSL_tot_frames))\n",
    "            print('LSL frames per second: ' + str(LSL_fps))\n",
    "            'Is this LSL_fps variable??' \n",
    "\n",
    "        \n",
    "            # ----------------------------------------\n",
    "            # Loading the original videos corresponding to the CSV files that will be cut according to LSL start and ends\n",
    "            for video in os.listdir(os.path.abspath(input_video_folder)):\n",
    "                \n",
    "                if participant_video in video:  # Check for the corresponding participant  \n",
    "                    \n",
    "                    print('Now processing video: ' + video)\n",
    "                    \n",
    "                    video_filepath = os.path.join(os.path.abspath(input_video_folder), video)\n",
    "                    capture = cv2.VideoCapture(video_filepath)  \n",
    "                \n",
    "                    # Extracting relevant meta-data about the video using CV2\n",
    "                    video_frame_width  = capture.get(cv2.CAP_PROP_FRAME_WIDTH)  \n",
    "                    video_frame_height = capture.get(cv2.CAP_PROP_FRAME_HEIGHT)  \n",
    "                    video_frame_rate   = capture.get(cv2.CAP_PROP_FPS)\n",
    "                    video_tot_frames   = int(capture.get(cv2.CAP_PROP_FRAME_COUNT)) \n",
    "                    capture.release()\n",
    "                    print('video_tot_frames: ' +  str(video_tot_frames))\n",
    "                    print('Video frames per second: ' + str(video_frame_rate))\n",
    "        \n",
    "        \n",
    "                    ## ---------- Cutting video Using ffmpeg \n",
    "                    # Converting the LSL frames to the video time format to find start_cut and end_cut for the video\n",
    "                    start_cut_time = frame_to_time(LSL_begin_frame, video_frame_rate)\n",
    "                    end_cut_time = frame_to_time(LSL_end_frame, video_frame_rate)\n",
    "        \n",
    "                    print('Now cutting the video...')\n",
    "        \n",
    "                    # Determine the file extension and codec\n",
    "                    file_extension = os.path.splitext(video)[1].lower()\n",
    "                    codec = extension_to_codec.get(file_extension, 'libx264')  # Default to libx264 if not found\n",
    "        \n",
    "                    # Construct output file path with the same extension\n",
    "                    output_filename = f'cut_{os.path.splitext(video)[0]}{file_extension}'\n",
    "                    output_filepath = os.path.join(output_video_folder, output_filename)\n",
    "        \n",
    "                    # Use ffmpeg to cut the video\n",
    "                    ffmpeg_command = [\n",
    "                        'ffmpeg',\n",
    "                        '-y',                  # Add -y flag to overwrite any existing files with the same name\n",
    "                        '-i', video_filepath,\n",
    "                        '-ss', start_cut_time,  # start time\n",
    "                        '-to', end_cut_time,    # end time\n",
    "                        '-c', 'copy',           # copy codec (no re-encoding)\n",
    "                        output_filepath\n",
    "                    ]\n",
    "        \n",
    "                    # Execute the command\n",
    "                    subprocess.run(ffmpeg_command, check=True)\n",
    "        \n",
    "                    print(f'Video saved as {output_filepath}')\n",
    "            \n",
    "\n",
    "print(\"Done with cutting all videos! You can now look into your folder: \" + output_video_folder)\n",
    "\n",
    "\n",
    "\n",
    "            ## -------------- Usign moviepy does not work!! Why??\n",
    "            \n",
    "            # # Extract video frame rate using moviepy\n",
    "            # video_clip = VideoFileClip(video_filepath)\n",
    "            # video_frame_rate = video_clip.fps\n",
    "            # print('Video frames per second: ' + str(video_frame_rate))\n",
    "            \n",
    "\n",
    "            # # Converting the LSL frames to the video time format to find start_cut and end_cut for the video \n",
    "            # start_cut_time = LSL_begin_frame / video_frame_rate\n",
    "            # end_cut_time   = LSL_end_frame / video_frame_rate\n",
    "\n",
    "            # print('Now cutting the video...') \n",
    "\n",
    "            # # Determine the file extension and codec\n",
    "            # file_extension = os.path.splitext(video)[1].lower()\n",
    "            # codec = extension_to_codec.get(file_extension)\n",
    "\n",
    "            # if codec is None:\n",
    "            #     print(f\"Unsupported file extension: {file_extension}. Skipping file.\")\n",
    "            #     continue\n",
    "\n",
    "            # # Cut and save the video using MoviePy\n",
    "            # cut_clip = video_clip.subclip(start_cut_time, end_cut_time)\n",
    "\n",
    "            # # Construct output file path with the same extension\n",
    "            # output_filename = f'cut_{os.path.splitext(video)[0]}{file_extension}'\n",
    "            # output_filepath = os.path.join(output_video_folder, output_filename)\n",
    "\n",
    "            # # Save the cut video with the determined codec in specified location\n",
    "            # cut_clip.write_videofile(output_filepath, codec=codec)\n",
    "\n",
    "            # print(f'Video saved as {output_filepath}')\n",
    "\n",
    "\n",
    "            # # -------------- This other way does not work either \n",
    "\n",
    "        #     # Translating the start and end time points to cut the video by multiplying the duration of each video frame by the \n",
    "        #     video_start_frametime_LSL =  np.round((1/int(frate)) * int(begin_frame), 3)\n",
    "        #     video_end_frametime_LSL = np.round((1/int(frate)) * int(end_frame), 3)\n",
    "\n",
    "\n",
    "        #     video_cut = VideoFileClip(video_filepath).cutout(video_start_frametime, video_end_frametime)\n",
    "        #     video_cut.write_videofile(videofolder + \"test.mp4\")\n",
    "\n",
    "\n",
    "\n",
    "        ## ---------------- This way takes a very long time \n",
    "\n",
    "        #   # Start Writing the Video \n",
    "            # fourcc = cv2.VideoWriter_fourcc(*'M', 'J', 'P', 'G')  # For different video formats you could use e.g., *'XVID'\n",
    "            # vidloc = os.path.join(videofolder, f'{video.split(\".\")[0]}_cut.mp4')  # Location to save the new video\n",
    "            # out = cv2.VideoWriter(vidloc, fourcc, fps=originalfps, frameSize=(int(frameWidth), int(frameHeight)))\n",
    "            # frame_count = 0\n",
    "\n",
    "            # print('Looping over the frames')\n",
    "        \n",
    "            # while capture.isOpened():\n",
    "            #     # Read the next frame\n",
    "            #     ret, frame = capture.read()\n",
    "            #     if ret:\n",
    "            #         # Increment the frame count\n",
    "            #         frame_count += 1\n",
    "            #         print(frame_count)\n",
    "            #         if frame_count in frames:\n",
    "            #             out.write(frame)\n",
    "            #         if frame_count > end_frame:\n",
    "            #             break\n",
    "\n",
    "            # capture.release()\n",
    "            # out.release()\n",
    "            # print(f'Video saved to {vidloc}')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd35add-78d9-40b2-b773-632b8732e7ba",
   "metadata": {},
   "source": [
    "# 5. Concatenate (cut) Videos with Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb1dc3-f58a-457b-9895-ef414b25150f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aab742c-a79d-4233-89a2-357972edb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_audio_folder = './data_processed/' \n",
    "input_video_folder = './video_cut/'\n",
    "output_audiovideo = './audiovideo_sync/'\n",
    "\n",
    "# List of participant file pairs       #--------------- SOULD WE DO THIS ANOTHER WAY? MAYBE SAVING THE VSC FILES WITH A CONSISTENT NAME? ---- \n",
    "participants_files = [\n",
    "    ('Mic_nominal_srate16000_denoised', 'P1'),\n",
    "    ('Mic_004_nominal_srate16000_denoised', 'P2')\n",
    "]\n",
    "\n",
    "\n",
    "# loop over Audio files\n",
    "for participant_audio, participant_video in participants_files:\n",
    "    \n",
    "    print('Navigating in the input audio folder: ')\n",
    "    \n",
    "    for audio in os.listdir(os.path.abspath(input_audio_folder)):\n",
    "        print(audio)\n",
    "        \n",
    "        if participant_audio in audio:    #Participant Check \n",
    "            print('Now processing audio '+ audio)\n",
    "        \n",
    "            # Creating audio path \n",
    "            print('Loading the audio ')\n",
    "            audio_path = os.path.join(os.path.abspath(input_audio_folder), audio)\n",
    "            print(audio_path)\n",
    "        \n",
    "        \n",
    "            # Loop over video files to select relevant video \n",
    "            print('Navigating in the input video folder: ')\n",
    "            for video in os.listdir(os.path.abspath(input_video_folder)):\n",
    "                print(video) \n",
    "                \n",
    "                if participant_video in video:\n",
    "                    print('Now processing video file ' + video) \n",
    "        \n",
    "                    # Creating video path \n",
    "                    print('Loading the video ')\n",
    "                    video_path = os.path.join(os.path.abspath(input_video_folder), video)\n",
    "                    print(video_path)\n",
    "        \n",
    "        \n",
    "                    # --- Combining Audio and Video using ffmpeg \n",
    "                    output_path = os.path.abspath(os.path.join(output_audiovideo + str(participant_video) + '_audiovideo_sync.avi'))\n",
    "                    print(output_path)\n",
    "        \n",
    "                    # Construct the ffmpeg command\n",
    "                    ffmpeg_command = [\n",
    "                        'ffmpeg',\n",
    "                        '-y',             #override\n",
    "                        '-i', video_path,\n",
    "                        '-i', audio_path,\n",
    "                        '-c:v', 'copy',  # Copy the video codec\n",
    "                        '-c:a', 'aac',   # Encode audio to AAC\n",
    "                        '-strict', 'experimental',\n",
    "                        output_path\n",
    "                                    ]     \n",
    "                    \n",
    "                    # Run the ffmpeg command\n",
    "                    print('Combining Audio and Video')\n",
    "                    try:\n",
    "                        result = subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)\n",
    "                        print(result.stdout)\n",
    "                        print(f'Video saved as {output_path}')\n",
    "                    except subprocess.CalledProcessError as e:\n",
    "                        print(f\"Error combining audio and video {video_path} and {audio_path}: {e.stderr}\")\n",
    "                    \n",
    "print('Done, you can now look into the folder. ' + output_audiovideo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a003a551-6ecd-4baf-8c29-9a96d77761f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "audio_path = os.path.join(os.path.abspath(input_audio_folder), file)\n",
    "                print(audio_path)\n",
    "        \n",
    "                \n",
    "                if not os.path.exists(audio_path):\n",
    "                    print(f\"Audio file not found: {audio_path}\" + '/n please check your foler to make sure the audio is there')\n",
    "                    \n",
    "                # input the video with ffmpg\n",
    "                input_audio = ffmpeg.input(audio_path)\n",
    "                print(input_audio)\n",
    "        \n",
    "                0/0\n",
    "\n",
    "#load in the video with matchich trialIndex and SessionIndex\n",
    "        print('Loading the video')\n",
    "        video_path = os.path.join(trialfolder, f\"{sessionIndex}_trial_{trialIndex}_video_raw.mp4\")\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Video file not found: {video_path}\")\n",
    "        input_video = ffmpeg.input(video_path)\n",
    "        print(input_video)\n",
    "        # get information about the vid_frate\n",
    "        #streamloc = trialfolder+sessionIndex+'_trial_'+ str(trialIndex) +'_'+'MyWebcamFrameStream_nominal_srate500'+'.csv'\n",
    "        #print(streamloc)\n",
    "        #streamdata = pd.read_csv(streamloc)\n",
    "        # get the begin and end frame\n",
    "        #begfr = streamdata['1'].min().astype(int)\n",
    "        #print(begfr)\n",
    "        #endfr = streamdata['1'].max().astype(int)\n",
    "        #print(endfr)\n",
    "        #totfr = endfr-begfr\n",
    "        #print(totfr)\n",
    "        #begin = streamdata['0'].min()\n",
    "        #print(begin)\n",
    "        #end = streamdata['0'].max()\n",
    "        #print(end)\n",
    "        # what is the original fps of the video\n",
    "        #origfps = round((totfr/(end-begin)),3)\n",
    "        # tranform it into real number\n",
    "        #origfps = float(origfps)\n",
    "        \n",
    "        #combine the audio and video\n",
    "        print('Combining audio and video')\n",
    "        output_path = os.path.abspath(os.path.join(trialfolder, f\"{sessionIndex}_trial_{trialIndex}_final.mp4\"))\n",
    "        ffmpeg.concat(input_video, input_audio, v=1, a=1).output(output_path).run(overwrite_output=True)\n",
    "        \n",
    "        #save it\n",
    "        print('Saving the video')\n",
    "        #print(origfps)\n",
    "        #print(type(origfps))\n",
    "        #print(trialIndex)\n",
    "        #print(sessionIndex)\n",
    "        # save the final video with audio\n",
    "        #final.write_videofile(trialfolder+sessionIndex+'_trial_'+ str(trialIndex) +'_'+'video_audio'+'.mp4', fps=origfps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705c5c7-5143-4185-ae4b-aaf1ebcb42e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavloc = os.path.join(os.path.abspath('./data_processed/')\n",
    "\n",
    "if not os.path.exists(wavloc):\n",
    "    print(f\"Directory not found: {wavloc}\")\n",
    "\n",
    "\n",
    "# loop over Audio files\n",
    "for file in os.listdir(wavloc):\n",
    "    print(file)\n",
    "    if 'Mic_nominal_srate16000_denoised' in file:\n",
    "        print('Now processing file '+file)\n",
    "        sessionIndex = file.split('_')[0]   # this is session number\n",
    "        trialIndex = file.split('_')[2] # this is trial number\n",
    "        #load in the audio\n",
    "        print('Loading the audio')\n",
    "        audio_path = os.path.join(wavloc, file)\n",
    "        if not os.path.exists(audio_path):\n",
    "            print(f\"Audio file not found: {audio_path}\")\n",
    "        # input the video with ffmpg\n",
    "        input_audio = ffmpeg.input(audio_path)\n",
    "        print(input_audio)\n",
    "        #load in the video with matchich trialIndex and SessionIndex\n",
    "        print('Loading the video')\n",
    "        video_path = os.path.join(trialfolder, f\"{sessionIndex}_trial_{trialIndex}_video_raw.mp4\")\n",
    "        if not os.path.exists(video_path):\n",
    "            print(f\"Video file not found: {video_path}\")\n",
    "        input_video = ffmpeg.input(video_path)\n",
    "        print(input_video)\n",
    "\n",
    "\n",
    "          #combine the audio and video\n",
    "        print('Combining audio and video')\n",
    "        output_path = os.path.abspath(os.path.join(trialfolder, f\"{sessionIndex}_trial_{trialIndex}_final.mp4\"))\n",
    "        ffmpeg.concat(input_video, input_audio, v=1, a=1).output(output_path).run(overwrite_output=True)\n",
    "\n",
    "\n",
    "        #save it\n",
    "        print('Saving the video')\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393caa11-0dd9-4a2d-9467-825bbdbd6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.abspath(videofolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad653e5-3395-4464-afc7-eb9d773050f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wavloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80369bc7-4efd-4f37-afc2-d9b1da70e1fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
