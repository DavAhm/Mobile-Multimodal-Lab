{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fc9c2240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from scipy import signal\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Ensure seaborn is set to use a white background\n",
    "\n",
    "\n",
    "# Your existing functions\n",
    "def compute_coherence(x, y, fs):\n",
    "    f, Cxy = signal.coherence(x, y, fs)\n",
    "    return f, Cxy\n",
    "\n",
    "def crosscorr(datax, datay, lag=0):\n",
    "    \"\"\" Lag-N cross correlation. Shift datax by N elements. \"\"\"\n",
    "    return datax.corr(datay.shift(lag))\n",
    "\n",
    "def compute_mutual_information(x: np.ndarray, y: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute mutual information between two time series using KDE.\n",
    "    \"\"\"\n",
    "    # Clean data\n",
    "    mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "    x = x[mask]\n",
    "    y = y[mask]\n",
    "    \n",
    "    if len(x) < 2 or len(y) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    # Standardize the data\n",
    "    x = (x - np.mean(x)) / np.std(x)\n",
    "    y = (y - np.mean(y)) / np.std(y)\n",
    "    \n",
    "    # Create KDE estimators\n",
    "    kde_joint = stats.gaussian_kde(np.vstack([x, y]))\n",
    "    kde_x = stats.gaussian_kde(x)\n",
    "    kde_y = stats.gaussian_kde(y)\n",
    "    \n",
    "    # Sample points for numerical integration\n",
    "    n_samples = 50\n",
    "    x_range = np.linspace(min(x) - 1, max(x) + 1, n_samples)\n",
    "    y_range = np.linspace(min(y) - 1, max(y) + 1, n_samples)\n",
    "    X, Y = np.meshgrid(x_range, y_range)\n",
    "    positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "    \n",
    "    # Evaluate densities\n",
    "    joint_density = kde_joint(positions).reshape(X.shape)\n",
    "    x_density = kde_x(X[0,:])\n",
    "    y_density = kde_y(Y[:,0])\n",
    "    X_density, Y_density = np.meshgrid(x_density, y_density)\n",
    "    \n",
    "    # Compute MI\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        mi_density = joint_density * np.log(joint_density / (X_density * Y_density))\n",
    "    mi = np.nansum(mi_density) * (x_range[1] - x_range[0]) * (y_range[1] - y_range[0])\n",
    "    \n",
    "    return max(0, mi)  # Ensure non-negative MI\n",
    "\n",
    "def compute_coupling_statistics(name, motion_ts, sound_ts, time):\n",
    "    \"\"\"Your existing coupling statistics function\"\"\"\n",
    "    # Ensure inputs are numpy arrays\n",
    "    motion_ts = np.array(motion_ts)\n",
    "    sound_ts = np.array(sound_ts)\n",
    "    time = np.array(time)\n",
    "\n",
    "    # Check if inputs are scalar (single values)\n",
    "    if motion_ts.ndim == 0 or sound_ts.ndim == 0 or time.ndim == 0:\n",
    "        return pd.DataFrame({\n",
    "            'scene': [name],\n",
    "            'lags': [np.nan],\n",
    "            'crosscorr': [np.nan],\n",
    "        }), np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    # Check if inputs have the same length\n",
    "    if len(motion_ts) != len(sound_ts) or len(motion_ts) != len(time):\n",
    "        raise ValueError(\"motion_ts, sound_ts, and time must have the same length\")\n",
    "\n",
    "    # normalize and center the data\n",
    "    motion_ts = (motion_ts - np.min(motion_ts)) / (np.max(motion_ts) - np.min(motion_ts))\n",
    "    motion_ts = motion_ts - np.mean(motion_ts)\n",
    "    sound_ts = (sound_ts - np.min(sound_ts)) / (np.max(sound_ts) - np.min(sound_ts))\n",
    "    sound_ts = sound_ts - np.mean(sound_ts)\n",
    "\n",
    "    # check if values are finite\n",
    "    if not np.all(np.isfinite(motion_ts)) or not np.all(np.isfinite(sound_ts)):\n",
    "        return pd.DataFrame({\n",
    "            'scene': [name],\n",
    "            'lags': [np.nan],\n",
    "            'crosscorr': [np.nan],\n",
    "        }), np.nan, np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    # Compute sampling frequency\n",
    "    fs = 1/np.mean(np.diff(time))\n",
    "\n",
    "    # compute the average mutual information\n",
    "    mi = []\n",
    "    lags = [-0.3, -0.2, -0.1, 0, 0.1, 0.2, 0.3]\n",
    "    fs = 1/np.mean(np.diff(time))\n",
    "    lags_samples = [int(lag * fs) for lag in lags]\n",
    "    \n",
    "    for lag in lags_samples:\n",
    "        if lag < 0:\n",
    "            motsub = motion_ts[:lag]\n",
    "            soundsub = sound_ts[-lag:]\n",
    "        elif lag > 0:\n",
    "            motsub = motion_ts[lag:]\n",
    "            soundsub = sound_ts[:-lag]\n",
    "        else:\n",
    "            motsub = motion_ts\n",
    "            soundsub = sound_ts\n",
    "            \n",
    "        # Add smoothing to capture temporal dependencies\n",
    "        window = int(0.1 * fs)  # 100ms window\n",
    "        if window > 1:\n",
    "            motsub = np.convolve(motsub, np.ones(window)/window, mode='valid')\n",
    "            soundsub = np.convolve(soundsub, np.ones(window)/window, mode='valid')\n",
    "        \n",
    "        mi_value = compute_mutual_information(motsub, soundsub)\n",
    "        mi.append(mi_value)\n",
    "    \n",
    "    max_mi = np.max(mi)\n",
    "    optimal_lag = lags[np.argmax(mi)]\n",
    "    \n",
    "    #################################################### Coherence\n",
    "    # Compute coherence\n",
    "    f, Cxy = compute_coherence(motion_ts, sound_ts, fs)\n",
    "\n",
    "    # keep all values lower than 10 Hz\n",
    "    mask = f < 10\n",
    "    Cxy = Cxy[mask]\n",
    "    f = f[mask]\n",
    "\n",
    "    # maximum coherence\n",
    "    coherence = np.max(Cxy)\n",
    "\n",
    "    # Frequency of max coherence\n",
    "    f_max = f[np.argmax(Cxy)]\n",
    "        \n",
    "    #################################################### Cross-correlation\n",
    "    lag_seconds = 0.3\n",
    "    lag_points = int(lag_seconds * fs)\n",
    "\n",
    "    # Create a range of lags to examine\n",
    "    lags = np.arange(-lag_points, lag_points + 1)\n",
    "\n",
    "    # calc cross-cor\n",
    "    cc = [crosscorr(pd.Series(motion_ts), pd.Series(sound_ts), lag) for lag in lags]\n",
    "\n",
    "    # Calculate cross-correlation\n",
    "    crosscorrdf = pd.DataFrame({\n",
    "        'scene': name,\n",
    "        'lags': lags*(1/fs),\n",
    "        'crosscorr': cc,\n",
    "    })\n",
    "\n",
    "    ########## Phase locking value\n",
    "    # Compute analytic signal (using Hilbert transform)\n",
    "    motion_analytic = signal.hilbert(motion_ts)\n",
    "    sound_analytic = signal.hilbert(sound_ts)\n",
    "\n",
    "    # Extract instantaneous phase\n",
    "    motion_phase = np.angle(motion_analytic)\n",
    "    sound_phase = np.angle(sound_analytic)\n",
    "\n",
    "    # Compute phase difference\n",
    "    phase_diff = motion_phase - sound_phase\n",
    "\n",
    "    # compute the plv\n",
    "    plv = np.abs(np.mean(np.exp(1j * phase_diff)))\n",
    "    \n",
    "    # make phase_diff a regular list not a numpy array\n",
    "    try:\n",
    "        motion_phase = motion_phase.tolist()[0] if hasattr(motion_phase, 'tolist') else motion_phase[0]\n",
    "        phase_diff = phase_diff.tolist()[0] if hasattr(phase_diff, 'tolist') else phase_diff[0]\n",
    "    except:\n",
    "        motion_phase = np.mean(motion_phase)\n",
    "        phase_diff = np.mean(phase_diff)\n",
    "\n",
    "    return crosscorrdf, coherence, f_max, max_mi, phase_diff, plv, optimal_lag\n",
    "\n",
    "def calculate_p1_p2_coupling_stats(merged_folder='../merged_filteredtimeseries/', output_file='p1_p2_coupling_statistics.csv'):\n",
    "    \"\"\"\n",
    "    Loop through merged time series files and calculate coupling statistics between P1 and P2\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find all merged CSV files\n",
    "    csv_files = glob.glob(os.path.join(merged_folder, \"*.csv\"))\n",
    "    print(f\"Found {len(csv_files)} files to process\")\n",
    "    \n",
    "    # Define P1-P2 variable pairs to analyze\n",
    "    p1_modalities = ['Amplitude_Envelope_P1', 'heart_rate_P1', 'Filtered_Respiration_P1', 'Filtered_EMG_Bicep_P1', 'Filtered_EMG_Tricep_P1', 'right_index_x_P1', 'right_index_y_P1', 'right_index_z_P1']\n",
    "    p2_modalities = ['Amplitude_Envelope_P2', 'heart_rate_P2', 'Filtered_Respiration_P2', 'Filtered_EMG_Bicep_P2', 'Filtered_EMG_Tricep_P2', 'right_index_x_P2', 'right_index_y_P2', 'right_index_z_P2']\n",
    "\n",
    "    variable_pairs = []\n",
    "    # Add same-participant, same-modality (if needed for matrix)\n",
    "    for i in range(len(p1_modalities)):\n",
    "        p1_var = p1_modalities[i]\n",
    "        p2_var = p2_modalities[i] # Assumes corresponding P1/P2 vars are at same index\n",
    "        if p1_var.replace('_P1', '') == p2_var.replace('_P2', ''): # Only if same modality\n",
    "            variable_pairs.append((p1_var, p2_var))\n",
    "\n",
    "    # Add ALL cross-participant pairs (same and cross-modality)\n",
    "    for p1_var in p1_modalities:\n",
    "        for p2_var in p2_modalities:\n",
    "            if (p1_var.replace('_P1', '') == p2_var.replace('_P2', '')) and (p1_var.replace('_P1', '') == 'Amplitude_Envelope'):\n",
    "                # This is the P1-P2 envelope, which is handled separately in plotting\n",
    "                # You might want to exclude it here if you only want to compute it once for the scatter plots\n",
    "                pass\n",
    "            else:\n",
    "                variable_pairs.append((p1_var, p2_var))\n",
    "    \n",
    "    # Initialize results list\n",
    "    results = []\n",
    "    \n",
    "    # Loop through each file\n",
    "    for file_path in csv_files:\n",
    "        print(f\"\\nProcessing: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        try:\n",
    "            # Load the data\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Extract metadata from filename and dataframe\n",
    "            filename = os.path.basename(file_path)\n",
    "            \n",
    "            # Try to extract condition information\n",
    "                # if filename has NoVision or NoMovement, set to 'NoVision' or 'NoMovement'\n",
    "            condition_vision = 'Vision' if 'NoVision' not in filename else 'NoVision'\n",
    "            condition_movement = 'Movement' if 'NoMovement' not in filename else 'NoMovement'\n",
    "            trial = df['Trial'].iloc[0] if 'Trial' in df.columns else 'Unknown'\n",
    "            \n",
    "            # Get time vector\n",
    "            time = df['Time'].values\n",
    "            \n",
    "            # Check if we have enough data (at least 3 seconds)\n",
    "            if time.max() - time.min() < 5.0:\n",
    "                print(f\"  Skipping {filename}: insufficient data duration ({time.max() - time.min():.2f}s)\")\n",
    "                continue\n",
    "            \n",
    "            # Set up sliding window analysis\n",
    "            window_duration = 5.0  # seconds\n",
    "            step_size = 1.0  # seconds\n",
    "            n_windows = int((time.max() - time.min() - window_duration) / step_size) + 1\n",
    "            \n",
    "            print(f\"  Analyzing {n_windows} windows of {window_duration}s each\")\n",
    "            \n",
    "            # Loop through each variable pair\n",
    "            for var1, var2 in variable_pairs:\n",
    "                if var1 not in df.columns or var2 not in df.columns:\n",
    "                    continue\n",
    "                    \n",
    "                print(f\"    Processing {var1} vs {var2}\")\n",
    "                \n",
    "                # Loop through sliding windows\n",
    "                for window_idx in range(n_windows):\n",
    "                    window_start = time.min() + window_idx * step_size\n",
    "                    window_end = window_start + window_duration\n",
    "                    \n",
    "                    # Extract window data\n",
    "                    window_mask = (time >= window_start) & (time <= window_end)\n",
    "                    time_window = time[window_mask]\n",
    "                    var1_window = df[var1].values[window_mask]\n",
    "                    var2_window = df[var2].values[window_mask]\n",
    "                    \n",
    "                    # Skip if not enough data in window or too many NaNs\n",
    "                    if len(time_window) < 100 or np.sum(~np.isnan(var1_window)) < 50 or np.sum(~np.isnan(var2_window)) < 50:\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        # Calculate coupling statistics\n",
    "                        crosscorrdf, coherence, f_max, max_mi, phase_diff, plv, optimal_lag = \\\n",
    "                            compute_coupling_statistics(filename, var1_window, var2_window, time_window)\n",
    "                        \n",
    "                        # Extract max cross-correlation\n",
    "                        max_crosscorr = crosscorrdf['crosscorr'].abs().max() if not crosscorrdf.empty else np.nan\n",
    "                        lag_at_max_crosscorr = crosscorrdf.loc[crosscorrdf['crosscorr'].abs().idxmax(), 'lags'] if not crosscorrdf.empty else np.nan\n",
    "                        \n",
    "                        # Store results\n",
    "                        result = {\n",
    "                            'filename': filename,\n",
    "                            'condition_vision': condition_vision,\n",
    "                            'condition_movement': condition_movement,\n",
    "                            'trial': trial,\n",
    "                            'window_idx': window_idx,\n",
    "                            'window_start': window_start,\n",
    "                            'window_end': window_end,\n",
    "                            'var1': var1,\n",
    "                            'var2': var2,\n",
    "                            'variable_pair_type': classify_variable_pair(var1, var2),\n",
    "                            'max_crosscorr': max_crosscorr,\n",
    "                            'lag_at_max_crosscorr': lag_at_max_crosscorr,\n",
    "                            'max_coherence': coherence,\n",
    "                            'freq_at_max_coherence': f_max,\n",
    "                            'max_mutual_info': max_mi,\n",
    "                            'optimal_lag_mi': optimal_lag,\n",
    "                            'phase_locking_value': plv,\n",
    "                            'mean_phase_diff': phase_diff,\n",
    "                            'n_samples': len(time_window),\n",
    "                            'sampling_rate': 1/np.mean(np.diff(time_window))\n",
    "                        }\n",
    "                        \n",
    "                        results.append(result)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"      Error in window {window_idx}: {e}\")\n",
    "                        continue\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    if results:\n",
    "        results_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Save to CSV\n",
    "        results_df.to_csv(output_file, index=False)\n",
    "        print(f\"\\n✓ Saved {len(results_df)} coupling statistics to {output_file}\")\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(f\"\\nSummary:\")\n",
    "        print(f\"  Files processed: {results_df['filename'].nunique()}\")\n",
    "        print(f\"  Variable pairs analyzed: {results_df['variable_pair_type'].nunique()}\")\n",
    "        print(f\"  Total windows analyzed: {len(results_df)}\")\n",
    "        print(f\"  Conditions: {results_df['condition_vision'].unique()} x {results_df['condition_movement'].unique()}\")\n",
    "        \n",
    "        return results_df\n",
    "    else:\n",
    "        print(\"No results generated - check your data files and variable names\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def classify_variable_pair(var1, var2):\n",
    "    \"\"\"\n",
    "    Classify the type of variable pair for easier analysis\n",
    "    \"\"\"\n",
    "    # Extract modality information\n",
    "    modalities = []\n",
    "    participants = []\n",
    "    \n",
    "    for var in [var1, var2]:\n",
    "        if 'Amplitude_Envelope' in var:\n",
    "            modalities.append('Audio')\n",
    "        elif 'heart_rate' in var:\n",
    "            modalities.append('ECG')\n",
    "        elif 'Respiration' in var:\n",
    "            modalities.append('Respiration')\n",
    "        elif 'EMG' in var:\n",
    "            modalities.append('EMG')\n",
    "        elif 'right_index' in var:\n",
    "            modalities.append('Motion')\n",
    "        else:\n",
    "            modalities.append('Other')\n",
    "            \n",
    "        if '_P1' in var:\n",
    "            participants.append('P1')\n",
    "        elif '_P2' in var:\n",
    "            participants.append('P2')\n",
    "        else:\n",
    "            participants.append('Unknown')\n",
    "    \n",
    "    # Classify pair type\n",
    "    if participants[0] == participants[1]:\n",
    "        if participants[0] == 'P1':\n",
    "            pair_type = 'Within_P1'\n",
    "        else:\n",
    "            pair_type = 'Within_P2'\n",
    "    else:\n",
    "        pair_type = 'Between_Participants'\n",
    "    \n",
    "    if modalities[0] == modalities[1]:\n",
    "        modality_type = f\"Same_{modalities[0]}\"\n",
    "    else:\n",
    "        modality_type = f\"Cross_{modalities[0]}_{modalities[1]}\"\n",
    "    \n",
    "    return f\"{pair_type}_{modality_type}\"\n",
    "\n",
    "\n",
    "def create_complete_coupling_plots(results_df, output_folder='coupling_plots/'):\n",
    "    \"\"\"\n",
    "    Create comprehensive coupling analysis plots including:\n",
    "    1. Envelope overview with proper cross-correlation lines and consistent colors\n",
    "    2. Separate cross-modality P1-P2 matrix for each condition with proper scaling\n",
    "    3. Separate scatter plots for audio P1-P2 vs each other modality P1-P2 pair PER CONDITION\n",
    "    4. Phase plots separated per condition\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    \n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    plt.style.use('seaborn-white')\n",
    "    \n",
    "    # Define consistent color scheme for conditions\n",
    "    CONDITION_COLORS = {\n",
    "        'NoVision x Movement': '#e41a1c',      # Red\n",
    "        'NoVision x NoMovement': '#377eb8',    # Blue  \n",
    "        'Vision x Movement': '#4daf4a',        # Green\n",
    "        'Vision x NoMovement': '#984ea3'       # Purple\n",
    "    }\n",
    "    \n",
    "    # Print available variables to debug\n",
    "    print(\"\\n=== Data Analysis ===\")\n",
    "    print(f\"Data shape: {results_df.shape}\")\n",
    "    \n",
    "    # Get all unique P1 and P2 variables\n",
    "    p1_vars = sorted([v for v in results_df['var1'].unique() if '_P1' in v])\n",
    "    p2_vars = sorted([v for v in results_df['var2'].unique() if '_P2' in v])\n",
    "    \n",
    "    print(f\"\\nP1 variables found:\")\n",
    "    for v in p1_vars:\n",
    "        print(f\"  - {v}\")\n",
    "    \n",
    "    print(f\"\\nP2 variables found:\")\n",
    "    for v in p2_vars:\n",
    "        print(f\"  - {v}\")\n",
    "    \n",
    "    # Updated modality extraction function\n",
    "    def get_modality_from_var(var_name):\n",
    "        if 'Amplitude_Envelope' in var_name:\n",
    "            return 'Audio'\n",
    "        elif 'heart_rate' in var_name:\n",
    "            return 'Heart Rate'\n",
    "        elif 'Filtered_ECG' in var_name:\n",
    "            return 'Heart Rate'\n",
    "        elif 'Filtered_Respiration' in var_name:\n",
    "            return 'Respiration'\n",
    "        elif 'Filtered_EMG_Bicep' in var_name:\n",
    "            return 'EMG Bicep'\n",
    "        elif 'Filtered_EMG_Tricep' in var_name:\n",
    "            return 'EMG Tricep'\n",
    "        elif 'right_index_x' in var_name:\n",
    "            return 'Motion X'\n",
    "        elif 'right_index_y' in var_name:\n",
    "            return 'Motion Y'\n",
    "        elif 'right_index_z' in var_name:\n",
    "            return 'Motion Z'\n",
    "        else:\n",
    "            return 'Unknown'\n",
    "    \n",
    "    # ============================================\n",
    "    # 1. ENVELOPE COUPLING OVERVIEW (CONSISTENT COLORS + SEPARATE PHASE PLOTS)\n",
    "    # ============================================\n",
    "    \n",
    "    print(\"\\n=== Creating Envelope Overview ===\")\n",
    "    \n",
    "    envelope_data = results_df[\n",
    "        (results_df['var1'] == 'Amplitude_Envelope_P1') & \n",
    "        (results_df['var2'] == 'Amplitude_Envelope_P2')\n",
    "    ].copy()\n",
    "    \n",
    "    print(f\"Envelope data shape: {envelope_data.shape}\")\n",
    "    \n",
    "    if len(envelope_data) > 0:\n",
    "        envelope_data['condition'] = envelope_data['condition_vision'].astype(str) + ' x ' + envelope_data['condition_movement'].astype(str)\n",
    "        conditions = sorted(envelope_data['condition'].unique())\n",
    "        \n",
    "        # Create main figure with updated layout for phase subplots\n",
    "        fig = plt.figure(figsize=(24, 20))\n",
    "        \n",
    "        # Panel 1: Mutual Information\n",
    "        ax1 = plt.subplot(3, 3, 1)\n",
    "        data_by_condition = [envelope_data[envelope_data['condition'] == cond]['max_mutual_info'].dropna().values \n",
    "                            for cond in conditions]\n",
    "        \n",
    "        if all(len(d) > 0 for d in data_by_condition):\n",
    "            parts = ax1.violinplot(data_by_condition, positions=range(len(conditions)),\n",
    "                                  showmeans=False, showmedians=True, showextrema=False)\n",
    "            \n",
    "            for pc in parts['bodies']:\n",
    "                pc.set_facecolor('lightcoral')\n",
    "                pc.set_alpha(0.7)\n",
    "            \n",
    "            for i, cond in enumerate(conditions):\n",
    "                cond_data = data_by_condition[i]\n",
    "                x = np.random.normal(i, 0.04, size=len(cond_data))\n",
    "                color = CONDITION_COLORS.get(cond, 'gray')\n",
    "                ax1.scatter(x, cond_data, alpha=0.7, s=40, color=color)\n",
    "        \n",
    "        ax1.set_xticks(range(len(conditions)))\n",
    "        ax1.set_xticklabels(conditions, rotation=45, ha='right', fontsize=16, fontweight='bold')\n",
    "        ax1.set_ylabel('Mutual Information', fontsize=18, fontweight='bold')\n",
    "        ax1.set_title('Mutual information for Audio Envelope P1-P2', fontsize=20, fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.tick_params(axis='both', which='major', labelsize=16)\n",
    "        \n",
    "        # Panel 2: Cross-correlation AS LINES (consistent colors)\n",
    "        ax2 = plt.subplot(3, 3, 2)\n",
    "        \n",
    "        # Create lag bins for averaging\n",
    "        lag_bins = np.linspace(-0.3, 0.3, 13)\n",
    "        lag_centers = (lag_bins[:-1] + lag_bins[1:]) / 2\n",
    "        \n",
    "        for i, cond in enumerate(conditions):\n",
    "            cond_data = envelope_data[envelope_data['condition'] == cond]\n",
    "            color = CONDITION_COLORS.get(cond, 'gray')\n",
    "            \n",
    "            if len(cond_data) > 0:\n",
    "                # Bin the data\n",
    "                mean_corrs = []\n",
    "                std_corrs = []\n",
    "                \n",
    "                for j in range(len(lag_bins)-1):\n",
    "                    mask = (cond_data['lag_at_max_crosscorr'] >= lag_bins[j]) & \\\n",
    "                           (cond_data['lag_at_max_crosscorr'] < lag_bins[j+1])\n",
    "                    \n",
    "                    bin_corrs = cond_data.loc[mask, 'max_crosscorr'].values\n",
    "                    if len(bin_corrs) > 0:\n",
    "                        mean_corrs.append(np.mean(bin_corrs))\n",
    "                        std_corrs.append(np.std(bin_corrs) / np.sqrt(len(bin_corrs)))\n",
    "                    else:\n",
    "                        mean_corrs.append(np.nan)\n",
    "                        std_corrs.append(np.nan)\n",
    "                \n",
    "                # Plot line\n",
    "                mean_corrs = np.array(mean_corrs)\n",
    "                std_corrs = np.array(std_corrs)\n",
    "                valid = ~np.isnan(mean_corrs)\n",
    "                \n",
    "                if np.sum(valid) > 1:\n",
    "                    ax2.plot(lag_centers[valid], mean_corrs[valid], \n",
    "                            'o-', color=color, linewidth=4, markersize=10,\n",
    "                            label=cond)\n",
    "                    \n",
    "                    # Add error bands\n",
    "                    ax2.fill_between(lag_centers[valid], \n",
    "                                    mean_corrs[valid] - std_corrs[valid],\n",
    "                                    mean_corrs[valid] + std_corrs[valid],\n",
    "                                    alpha=0.2, color=color)\n",
    "        \n",
    "        ax2.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "        ax2.axvline(x=0, color='black', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "        ax2.set_xlabel('Lag (s)', fontsize=18, fontweight='bold')\n",
    "        ax2.set_ylabel('Cross-correlation', fontsize=18, fontweight='bold')\n",
    "        ax2.set_title('Cross-correlation for Audio Envelope P1-P2', fontsize=20, fontweight='bold')\n",
    "        ax2.legend(loc='best', fontsize=14)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.set_xlim(-0.35, 0.35)\n",
    "        ax2.tick_params(axis='both', which='major', labelsize=16)\n",
    "        \n",
    "        # Panel 3: Phase Locking Value\n",
    "        ax3 = plt.subplot(3, 3, 3)\n",
    "        plv_data = [envelope_data[envelope_data['condition'] == cond]['phase_locking_value'].dropna().values \n",
    "                    for cond in conditions]\n",
    "        \n",
    "        if all(len(d) > 0 for d in plv_data):\n",
    "            parts = ax3.violinplot(plv_data, positions=range(len(conditions)),\n",
    "                                  showmeans=False, showmedians=True, showextrema=False)\n",
    "            \n",
    "            for pc in parts['bodies']:\n",
    "                pc.set_facecolor('lightblue')\n",
    "                pc.set_alpha(0.7)\n",
    "            \n",
    "            for i, cond in enumerate(conditions):\n",
    "                cond_data = plv_data[i]\n",
    "                x = np.random.normal(i, 0.04, size=len(cond_data))\n",
    "                color = CONDITION_COLORS.get(cond, 'gray')\n",
    "                ax3.scatter(x, cond_data, alpha=0.7, s=40, color=color)\n",
    "        \n",
    "        ax3.set_xticks(range(len(conditions)))\n",
    "        ax3.set_xticklabels(conditions, rotation=45, ha='right', fontsize=16, fontweight='bold')\n",
    "        ax3.set_ylabel('Phase Locking Value', fontsize=18, fontweight='bold')\n",
    "        ax3.set_title('Phase locking value for Audio Envelope P1-P2', fontsize=20, fontweight='bold')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.tick_params(axis='both', which='major', labelsize=16)\n",
    "        \n",
    "        # Panels 4-7: Phase Distribution per condition (separate polar plots)\n",
    "        phase_positions = [(3, 3, 4), (3, 3, 5), (3, 3, 7), (3, 3, 8)]  # Skip middle position\n",
    "        \n",
    "        for i, cond in enumerate(conditions):\n",
    "            if i >= len(phase_positions):\n",
    "                break\n",
    "                \n",
    "            ax_phase = plt.subplot(*phase_positions[i], projection='polar')\n",
    "            color = CONDITION_COLORS.get(cond, 'gray')\n",
    "            \n",
    "            cond_data = envelope_data[envelope_data['condition'] == cond]\n",
    "            if 'mean_phase_diff' in cond_data.columns:\n",
    "                phases = cond_data['mean_phase_diff'].dropna().values\n",
    "                \n",
    "                if len(phases) > 0:\n",
    "                    bins = np.linspace(-np.pi, np.pi, 36)\n",
    "                    hist, _ = np.histogram(phases, bins=bins)\n",
    "                    hist = hist / (len(phases) * (bins[1] - bins[0]))  # Density\n",
    "                    \n",
    "                    theta = (bins[:-1] + bins[1:]) / 2\n",
    "                    ax_phase.bar(theta, hist, width=bins[1]-bins[0], \n",
    "                               alpha=0.7, color=color, edgecolor='black', linewidth=0.5)\n",
    "                    \n",
    "                    # Add mean direction arrow\n",
    "                    mean_angle = np.angle(np.mean(np.exp(1j * phases)))\n",
    "                    mean_length = np.abs(np.mean(np.exp(1j * phases)))\n",
    "                    ax_phase.arrow(mean_angle, 0, 0, mean_length * max(hist) * 0.8, \n",
    "                                 head_width=0.1, head_length=max(hist)*0.1, \n",
    "                                 fc='red', ec='red', linewidth=2)\n",
    "            \n",
    "            ax_phase.set_theta_zero_location('N')\n",
    "            ax_phase.set_title(f'{cond}\\nPhase Distribution', pad=20, fontsize=18, fontweight='bold')\n",
    "            ax_phase.grid(True, alpha=0.3)\n",
    "            ax_phase.tick_params(axis='both', which='major', labelsize=14)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_folder, 'envelope_coupling_overview.png'), \n",
    "                   dpi=300, bbox_inches='tight', facecolor='white')\n",
    "        plt.close()\n",
    "    \n",
    "    # ============================================\n",
    "    # 2. SEPARATE CROSS-MODALITY P1-P2 MATRIX FOR EACH CONDITION\n",
    "    # ============================================\n",
    "    \n",
    "    print(\"\\n=== Creating Separate Cross-Modality Matrices ===\")\n",
    "    \n",
    "    # Get all P1-P2 pairs\n",
    "    p1_p2_data = results_df[\n",
    "        (results_df['var1'].str.contains('_P1')) &\n",
    "        (results_df['var2'].str.contains('_P2'))\n",
    "    ].copy()\n",
    "    \n",
    "    if len(p1_p2_data) > 0:\n",
    "        # Add modality columns\n",
    "        p1_p2_data['modality1'] = p1_p2_data['var1'].apply(get_modality_from_var)\n",
    "        p1_p2_data['modality2'] = p1_p2_data['var2'].apply(get_modality_from_var)\n",
    "        \n",
    "        # Get all unique modalities (excluding Unknown)\n",
    "        all_modalities = sorted(list(set(p1_p2_data['modality1'].unique()) | \n",
    "                                    set(p1_p2_data['modality2'].unique())))\n",
    "        all_modalities = [m for m in all_modalities if m != 'Unknown']\n",
    "        \n",
    "        print(f\"Modalities found: {all_modalities}\")\n",
    "        \n",
    "        # Get conditions\n",
    "        conditions = p1_p2_data.groupby(['condition_vision', 'condition_movement']).size().reset_index()[['condition_vision', 'condition_movement']]\n",
    "        \n",
    "        # Calculate global min/max for consistent scaling across conditions\n",
    "        all_values = []\n",
    "        for _, cond_row in conditions.iterrows():\n",
    "            vision = cond_row['condition_vision']\n",
    "            movement = cond_row['condition_movement']\n",
    "            cond_data = p1_p2_data[\n",
    "                (p1_p2_data['condition_vision'] == vision) & \n",
    "                (p1_p2_data['condition_movement'] == movement)\n",
    "            ]\n",
    "            if len(cond_data) > 0:\n",
    "                all_values.extend(cond_data['max_mutual_info'].dropna().values)\n",
    "        \n",
    "        global_vmin = 0\n",
    "        global_vmax = np.percentile(all_values, 95) if len(all_values) > 0 else 2.0\n",
    "        \n",
    "        print(f\"Using global scale: {global_vmin:.3f} to {global_vmax:.3f}\")\n",
    "        \n",
    "        # Create separate plot for each condition\n",
    "        for _, cond_row in conditions.iterrows():\n",
    "            vision = cond_row['condition_vision']\n",
    "            movement = cond_row['condition_movement']\n",
    "            cond_name = f\"{vision} x {movement}\"\n",
    "            \n",
    "            print(f\"  Creating matrix for: {cond_name}\")\n",
    "            \n",
    "            # Create individual figure for this condition - MUCH LARGER\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(20, 18))\n",
    "            \n",
    "            # Get data for this condition\n",
    "            cond_data = p1_p2_data[\n",
    "                (p1_p2_data['condition_vision'] == vision) & \n",
    "                (p1_p2_data['condition_movement'] == movement)\n",
    "            ]\n",
    "            \n",
    "            # Create matrix\n",
    "            matrix = np.full((len(all_modalities), len(all_modalities)), np.nan)\n",
    "            \n",
    "            for i, p2_mod in enumerate(all_modalities):\n",
    "                for j, p1_mod in enumerate(all_modalities):\n",
    "                    pair_data = cond_data[\n",
    "                        (cond_data['modality1'] == p1_mod) & \n",
    "                        (cond_data['modality2'] == p2_mod)\n",
    "                    ]\n",
    "                    \n",
    "                    if len(pair_data) > 0:\n",
    "                        matrix[i, j] = pair_data['max_mutual_info'].mean()\n",
    "            \n",
    "            # Plot heatmap with proper scaling\n",
    "            mask = np.isnan(matrix)\n",
    "            \n",
    "            # Use a more contrastive colormap\n",
    "            cmap = plt.cm.viridis  # High contrast colormap\n",
    "            \n",
    "            # Calculate annotation font size based on matrix size\n",
    "            n_modalities = len(all_modalities)\n",
    "            if n_modalities <= 5:\n",
    "                annot_fontsize = 24\n",
    "            elif n_modalities <= 7:\n",
    "                annot_fontsize = 20\n",
    "            else:\n",
    "                annot_fontsize = 16\n",
    "            \n",
    "            sns.heatmap(matrix, annot=True, fmt='.3f', cmap=cmap, \n",
    "                       mask=mask, \n",
    "                       cbar_kws={'label': 'Mutual Information', 'shrink': 0.6},\n",
    "                       xticklabels=all_modalities, yticklabels=all_modalities,\n",
    "                       ax=ax, square=True, \n",
    "                       vmin=global_vmin, vmax=global_vmax,\n",
    "                       annot_kws={'fontsize': annot_fontsize, 'fontweight': 'bold'}, \n",
    "                       linewidths=2.0, linecolor='white')\n",
    "            # size font of matrix labels\n",
    "            \n",
    "            # MUCH larger fonts for labels and title\n",
    "            ax.set_xlabel('P1 Modality', fontsize=32, fontweight='bold', labelpad=25)\n",
    "            ax.set_ylabel('P2 Modality', fontsize=32, fontweight='bold', labelpad=25) \n",
    "            ax.set_title(f'P1-P2 Cross-Modality Coupling - {cond_name}', \n",
    "                        fontsize=36, fontweight='bold', pad=80)\n",
    "            \n",
    "            # Larger tick labels with proper spacing\n",
    "            ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right', \n",
    "                             fontsize=26, fontweight='bold')\n",
    "            ax.set_yticklabels(ax.get_yticklabels(), rotation=0, \n",
    "                             fontsize=26, fontweight='bold')\n",
    "            \n",
    "            # Customize colorbar with larger fonts\n",
    "            cbar = ax.collections[0].colorbar\n",
    "            cbar.ax.tick_params(labelsize=24)\n",
    "            cbar.set_label('Mutual Information', fontsize=28, fontweight='bold')\n",
    "            \n",
    "            # Add extra padding to prevent cutoff\n",
    "            fig.subplots_adjust(top=0.88)\n",
    "            \n",
    "            # Save individual condition plot\n",
    "            safe_condition = cond_name.replace(' ', '_').replace('x', 'vs')\n",
    "            plt.savefig(os.path.join(output_folder, f'cross_modality_matrix_{safe_condition}.png'), \n",
    "                       dpi=300, facecolor='white', pad_inches=1.5 )\n",
    "            plt.close()\n",
    "    \n",
    "    # ============================================\n",
    "    # 3. SEPARATE AUDIO P1-P2 vs EACH OTHER MODALITY P1-P2 SCATTER PLOTS PER CONDITION\n",
    "    # ============================================\n",
    "    \n",
    "    print(\"\\n=== Creating Individual Audio vs Modality Scatter Plots Per Condition ===\")\n",
    "    \n",
    "    # Get envelope coupling data\n",
    "    envelope_coupling = results_df[\n",
    "        (results_df['var1'] == 'Amplitude_Envelope_P1') & \n",
    "        (results_df['var2'] == 'Amplitude_Envelope_P2')\n",
    "    ].copy()\n",
    "    \n",
    "    if len(envelope_coupling) == 0:\n",
    "        print(\"No envelope coupling data found!\")\n",
    "        return\n",
    "    \n",
    "    # Average per trial/condition/window\n",
    "    envelope_avg = envelope_coupling.groupby(\n",
    "        ['trial', 'condition_vision', 'condition_movement', 'window_idx']\n",
    "    )['max_mutual_info'].mean().reset_index()\n",
    "    \n",
    "    # Find all P1-P2 pairs (excluding audio)\n",
    "    all_p1_p2_pairs = []\n",
    "    \n",
    "    print(\"\\nChecking for P1-P2 pairs:\")\n",
    "    \n",
    "    # Method 1: Look for exact P1-P2 matches\n",
    "    for p1_var in p1_vars:\n",
    "        if 'Amplitude_Envelope' in p1_var:\n",
    "            continue\n",
    "            \n",
    "        # Find matching P2 variable\n",
    "        p1_base = p1_var.replace('_P1', '')\n",
    "        p2_var = p1_base + '_P2'\n",
    "        \n",
    "        if p2_var in p2_vars:\n",
    "            # Check if data exists\n",
    "            pair_exists = len(results_df[\n",
    "                (results_df['var1'] == p1_var) & \n",
    "                (results_df['var2'] == p2_var)\n",
    "            ]) > 0\n",
    "            \n",
    "            if pair_exists:\n",
    "                modality = get_modality_from_var(p1_var)\n",
    "                all_p1_p2_pairs.append((p1_var, p2_var, modality))\n",
    "                print(f\"  ✓ Found: {p1_var} → {p2_var} ({modality})\")\n",
    "    \n",
    "    # Get all condition combinations\n",
    "    all_conditions = envelope_avg.groupby(['condition_vision', 'condition_movement']).size().reset_index()[['condition_vision', 'condition_movement']]\n",
    "    \n",
    "    print(f\"\\nCreating separate scatter plots for envelope coupling P1-P2 versus coupling {len(all_p1_p2_pairs)} modalities x {len(all_conditions)} conditions:\")\n",
    "    \n",
    "    # Create separate plots for P1-P2 MI envelope vs each modality P1-P2 pair per condition\n",
    "    for p1_var, p2_var, modality in all_p1_p2_pairs:\n",
    "        for _, cond_row in all_conditions.iterrows():\n",
    "            vision = cond_row['condition_vision']\n",
    "            movement = cond_row['condition_movement']\n",
    "            cond_name = f\"{vision} x {movement}\"\n",
    "            \n",
    "            print(f\"  Creating plot for: {modality} - {cond_name}\")\n",
    "            \n",
    "            # Create individual figure for this modality and condition\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(7, 10))\n",
    "            # set the size excplittly to make it square\n",
    "            fig.set_size_inches(7, 7)\n",
    "            \n",
    "            # Get modality data\n",
    "            mod_data = results_df[\n",
    "                (results_df['var1'] == p1_var) & \n",
    "                (results_df['var2'] == p2_var) &\n",
    "                (results_df['condition_vision'] == vision) &\n",
    "                (results_df['condition_movement'] == movement)\n",
    "            ].copy()\n",
    "            \n",
    "            if len(mod_data) > 0:\n",
    "                # Average per trial/window\n",
    "                mod_avg = mod_data.groupby(\n",
    "                    ['trial', 'window_idx']\n",
    "                )['max_mutual_info'].mean().reset_index()\n",
    "                \n",
    "                # Get corresponding envelope data for this condition\n",
    "                env_cond = envelope_avg[\n",
    "                    (envelope_avg['condition_vision'] == vision) &\n",
    "                    (envelope_avg['condition_movement'] == movement)\n",
    "                ]\n",
    "                \n",
    "                # Merge with envelope\n",
    "                merged = pd.merge(\n",
    "                    env_cond,\n",
    "                    mod_avg,\n",
    "                    on=['trial', 'window_idx'],\n",
    "                    suffixes=('_env', '_mod')\n",
    "                )\n",
    "                \n",
    "                if len(merged) > 0:\n",
    "                    x = merged['max_mutual_info_env'].values\n",
    "                    y = merged['max_mutual_info_mod'].values\n",
    "                    \n",
    "                    # Remove NaN\n",
    "                    mask = ~(np.isnan(x) | np.isnan(y))\n",
    "                    x = x[mask]\n",
    "                    y = y[mask]\n",
    "                    \n",
    "                    if len(x) > 2:\n",
    "                        # Plot with condition color\n",
    "                        color = CONDITION_COLORS.get(cond_name, 'gray')\n",
    "                        ax.scatter(x, y, alpha=0.7, s=120, color=color, \n",
    "                                 edgecolors='black', linewidth=1.0, label=cond_name)\n",
    "                        \n",
    "                        # Add regression line\n",
    "                        slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "                        line_x = np.array([x.min(), x.max()])\n",
    "                        line_y = slope * line_x + intercept\n",
    "                        ax.plot(line_x, line_y, 'k--', linewidth=4, alpha=0.8)\n",
    "                        \n",
    "                        # Add statistics with larger font\n",
    "                        ax.text(0.05, 0.95, f'r = {r_value:.3f}\\np = {p_value:.3f}\\nn = {len(x)}',\n",
    "                               transform=ax.transAxes, verticalalignment='top',\n",
    "                               fontsize=14, fontweight='bold',\n",
    "                               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "                        \n",
    "                        ax.legend(fontsize=20, loc='upper right')\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, f'Insufficient data (n={len(x)})', \n",
    "                               ha='center', va='center', transform=ax.transAxes, \n",
    "                               fontsize=14, fontweight='bold')\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, 'No matched data', \n",
    "                           ha='center', va='center', transform=ax.transAxes, \n",
    "                           fontsize=14, fontweight='bold')\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, f'No {modality} data for {cond_name}', \n",
    "                       ha='center', va='center', transform=ax.transAxes, \n",
    "                       fontsize=14, fontweight='bold')\n",
    "            \n",
    "            ax.set_xlabel('MI (Audio Envelope P1-P2)', fontsize=28, fontweight='bold')\n",
    "            ax.set_ylabel(f'MI ({modality} P1-P2)', fontsize=28, fontweight='bold')\n",
    "            ax.set_title(f'{cond_name}', \n",
    "                        fontsize=32, fontweight='bold')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Increase tick label sizes\n",
    "            ax.tick_params(axis='both', which='major', labelsize=24)\n",
    "            \n",
    "            # Set equal aspect ratio\n",
    "            #ax.set_aspect('equal', adjustable='box')\n",
    "            \n",
    "            plt.tight_layout(pad=2.0)\n",
    "            \n",
    "            # Save individual plot\n",
    "            safe_modality = modality.replace(' ', '_').replace('/', '_')\n",
    "            safe_condition = cond_name.replace(' ', '_').replace('x', 'vs')\n",
    "            plt.savefig(os.path.join(output_folder, f'audio_vs_{safe_modality}_{safe_condition}_scatter_MI.png'), \n",
    "                       dpi=300, bbox_inches='tight', facecolor='white', pad_inches=1)\n",
    "            plt.close()\n",
    "    \n",
    "    print(\"\\n✓ All plots saved successfully!\")\n",
    "    print(f\"  - Envelope overview with consistent colors and separate phase plots\")\n",
    "    print(f\"  - {len(all_conditions)} separate cross-modality matrices with proper scaling\")\n",
    "    print(f\"  - {len(all_p1_p2_pairs) * len(all_conditions)} separate scatter plots for each modality x condition combination\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b45a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b907cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_folder = '../4a_PROCESSED/merged_filteredtimeseries/'  # Update this path\n",
    "output_file = './p1_p2_coupling_statistics.csv'\n",
    "\n",
    "# Calculate coupling statistics\n",
    "overwrite = False\n",
    "# check if already exist and overwrite = False\n",
    "if not overwrite and os.path.exists(output_file):\n",
    "    print(f\"File {output_file} already exists. Set overwrite=True to recalculate.\")\n",
    "    results_df = calculate_p1_p2_coupling_stats(merged_folder, output_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96c4ddf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Analysis ===\n",
      "Data shape: (8512, 20)\n",
      "\n",
      "P1 variables found:\n",
      "  - Amplitude_Envelope_P1\n",
      "  - Filtered_EMG_Bicep_P1\n",
      "  - Filtered_EMG_Tricep_P1\n",
      "  - Filtered_Respiration_P1\n",
      "  - right_index_x_P1\n",
      "  - right_index_y_P1\n",
      "  - right_index_z_P1\n",
      "\n",
      "P2 variables found:\n",
      "  - Amplitude_Envelope_P2\n",
      "  - Filtered_EMG_Bicep_P2\n",
      "  - Filtered_EMG_Tricep_P2\n",
      "  - Filtered_Respiration_P2\n",
      "  - right_index_x_P2\n",
      "  - right_index_y_P2\n",
      "  - right_index_z_P2\n",
      "\n",
      "=== Creating Envelope Overview ===\n",
      "Envelope data shape: (160, 20)\n",
      "\n",
      "=== Creating Separate Cross-Modality Matrices ===\n",
      "Modalities found: ['Audio', 'EMG Bicep', 'EMG Tricep', 'Motion X', 'Motion Y', 'Motion Z', 'Respiration']\n",
      "Using global scale: 0.000 to 0.924\n",
      "  Creating matrix for: NoVision x Movement\n",
      "  Creating matrix for: NoVision x NoMovement\n",
      "  Creating matrix for: Vision x Movement\n",
      "  Creating matrix for: Vision x NoMovement\n",
      "\n",
      "=== Creating Individual Audio vs Modality Scatter Plots Per Condition ===\n",
      "\n",
      "Checking for P1-P2 pairs:\n",
      "  ✓ Found: Filtered_EMG_Bicep_P1 → Filtered_EMG_Bicep_P2 (EMG Bicep)\n",
      "  ✓ Found: Filtered_EMG_Tricep_P1 → Filtered_EMG_Tricep_P2 (EMG Tricep)\n",
      "  ✓ Found: Filtered_Respiration_P1 → Filtered_Respiration_P2 (Respiration)\n",
      "  ✓ Found: right_index_x_P1 → right_index_x_P2 (Motion X)\n",
      "  ✓ Found: right_index_y_P1 → right_index_y_P2 (Motion Y)\n",
      "  ✓ Found: right_index_z_P1 → right_index_z_P2 (Motion Z)\n",
      "\n",
      "Creating separate scatter plots for envelope coupling P1-P2 versus coupling 6 modalities x 4 conditions:\n",
      "  Creating plot for: EMG Bicep - NoVision x Movement\n",
      "  Creating plot for: EMG Bicep - NoVision x NoMovement\n",
      "  Creating plot for: EMG Bicep - Vision x Movement\n",
      "  Creating plot for: EMG Bicep - Vision x NoMovement\n",
      "  Creating plot for: EMG Tricep - NoVision x Movement\n",
      "  Creating plot for: EMG Tricep - NoVision x NoMovement\n",
      "  Creating plot for: EMG Tricep - Vision x Movement\n",
      "  Creating plot for: EMG Tricep - Vision x NoMovement\n",
      "  Creating plot for: Respiration - NoVision x Movement\n",
      "  Creating plot for: Respiration - NoVision x NoMovement\n",
      "  Creating plot for: Respiration - Vision x Movement\n",
      "  Creating plot for: Respiration - Vision x NoMovement\n",
      "  Creating plot for: Motion X - NoVision x Movement\n",
      "  Creating plot for: Motion X - NoVision x NoMovement\n",
      "  Creating plot for: Motion X - Vision x Movement\n",
      "  Creating plot for: Motion X - Vision x NoMovement\n",
      "  Creating plot for: Motion Y - NoVision x Movement\n",
      "  Creating plot for: Motion Y - NoVision x NoMovement\n",
      "  Creating plot for: Motion Y - Vision x Movement\n",
      "  Creating plot for: Motion Y - Vision x NoMovement\n",
      "  Creating plot for: Motion Z - NoVision x Movement\n",
      "  Creating plot for: Motion Z - NoVision x NoMovement\n",
      "  Creating plot for: Motion Z - Vision x Movement\n",
      "  Creating plot for: Motion Z - Vision x NoMovement\n",
      "\n",
      "✓ All plots saved successfully!\n",
      "  - Envelope overview with consistent colors and separate phase plots\n",
      "  - 4 separate cross-modality matrices with proper scaling\n",
      "  - 24 separate scatter plots for each modality x condition combination\n",
      "\n",
      "Example results:\n",
      "                      filename condition_vision condition_movement  trial  \\\n",
      "0  NoVisionMovement_Trial0.csv         NoVision           Movement      0   \n",
      "1  NoVisionMovement_Trial0.csv         NoVision           Movement      0   \n",
      "2  NoVisionMovement_Trial0.csv         NoVision           Movement      0   \n",
      "3  NoVisionMovement_Trial0.csv         NoVision           Movement      0   \n",
      "4  NoVisionMovement_Trial0.csv         NoVision           Movement      0   \n",
      "\n",
      "   window_idx  window_start  window_end                   var1  \\\n",
      "0           0           0.0         5.0  Amplitude_Envelope_P1   \n",
      "1           1           1.0         6.0  Amplitude_Envelope_P1   \n",
      "2           2           2.0         7.0  Amplitude_Envelope_P1   \n",
      "3           3           3.0         8.0  Amplitude_Envelope_P1   \n",
      "4           4           4.0         9.0  Amplitude_Envelope_P1   \n",
      "\n",
      "                    var2               variable_pair_type  max_crosscorr  \\\n",
      "0  Amplitude_Envelope_P2  Between_Participants_Same_Audio       0.581964   \n",
      "1  Amplitude_Envelope_P2  Between_Participants_Same_Audio       0.502136   \n",
      "2  Amplitude_Envelope_P2  Between_Participants_Same_Audio       0.415748   \n",
      "3  Amplitude_Envelope_P2  Between_Participants_Same_Audio       0.335404   \n",
      "4  Amplitude_Envelope_P2  Between_Participants_Same_Audio       0.725810   \n",
      "\n",
      "   lag_at_max_crosscorr  max_coherence  freq_at_max_coherence  \\\n",
      "0                -0.108       0.106550                3.90625   \n",
      "1                -0.300       0.199333                0.00000   \n",
      "2                -0.300       0.473383                0.00000   \n",
      "3                 0.300       0.327099                0.00000   \n",
      "4                 0.008       0.392418                3.90625   \n",
      "\n",
      "   max_mutual_info  optimal_lag_mi  phase_locking_value  mean_phase_diff  \\\n",
      "0         0.580699             0.0             0.795875         0.541839   \n",
      "1         0.484273             0.0             0.735015        -3.303022   \n",
      "2         0.435175             0.0             0.620146         0.466865   \n",
      "3         0.312685             0.0             0.367146         0.515458   \n",
      "4         0.620897             0.0             0.533911         0.003797   \n",
      "\n",
      "   n_samples  sampling_rate  \n",
      "0       5001         1000.0  \n",
      "1       5001         1000.0  \n",
      "2       5001         1000.0  \n",
      "3       5001         1000.0  \n",
      "4       5001         1000.0  \n",
      "\n",
      "Variable pair types found:\n",
      "Between_Participants_Same_Motion                 1824\n",
      "Between_Participants_Same_EMG                     960\n",
      "Between_Participants_Cross_EMG_Motion             912\n",
      "Between_Participants_Cross_Motion_EMG             912\n",
      "Between_Participants_Cross_Audio_Motion           456\n",
      "Between_Participants_Cross_Respiration_Motion     456\n",
      "Between_Participants_Cross_Motion_Audio           456\n",
      "Between_Participants_Cross_Motion_Respiration     456\n",
      "Between_Participants_Same_Respiration             320\n",
      "Between_Participants_Cross_Audio_EMG              320\n",
      "Between_Participants_Cross_Respiration_EMG        320\n",
      "Between_Participants_Cross_EMG_Audio              320\n",
      "Between_Participants_Cross_EMG_Respiration        320\n",
      "Between_Participants_Same_Audio                   160\n",
      "Between_Participants_Cross_Audio_Respiration      160\n",
      "Between_Participants_Cross_Respiration_Audio      160\n",
      "Name: variable_pair_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create summary plots if results were generated\n",
    "output_file = './p1_p2_coupling_statistics.csv'\n",
    "results_df = pd.read_csv(output_file)\n",
    "if not results_df.empty:\n",
    "    #create_plots(results_df, output_folder='coupling_plots/')\n",
    "    create_complete_coupling_plots(results_df, output_folder='coupling_plots/')\n",
    "   \n",
    "    \n",
    "    # Display some example results\n",
    "    print(\"\\nExample results:\")\n",
    "    print(results_df.head())\n",
    "    \n",
    "    print(\"\\nVariable pair types found:\")\n",
    "    print(results_df['variable_pair_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb654a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
